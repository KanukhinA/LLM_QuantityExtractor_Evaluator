"""
–ì–ª–∞–≤–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–µ–π
"""
import os
import sys
from datetime import datetime
from model_evaluator import ModelEvaluator
import model_loaders as ml
from gemini_analyzer import analyze_errors_with_gemini, check_gemini_api
from config import DATASET_PATH, GROUND_TRUTH_PATH, OUTPUT_DIR, GEMINI_API_KEY


def run_evaluation(model_config: dict, use_gemini: bool = True):
    """
    –ó–∞–ø—É—Å–∫–∞–µ—Ç –æ—Ü–µ–Ω–∫—É –º–æ–¥–µ–ª–∏
    
    Args:
        model_config: —Å–ª–æ–≤–∞—Ä—å —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π –º–æ–¥–µ–ª–∏:
            - name: –Ω–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
            - load_func: —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏
            - generate_func: —Ñ—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            - hyperparameters: –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        use_gemini: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ Gemini API
    """
    evaluator = ModelEvaluator(
        dataset_path=DATASET_PATH,
        ground_truth_path=GROUND_TRUTH_PATH,
        output_dir=OUTPUT_DIR
    )
    
    # –û—á–∏—â–∞–µ–º –ø–∞–º—è—Ç—å –ø–µ—Ä–µ–¥ –∑–∞–≥—Ä—É–∑–∫–æ–π –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏
    evaluator.clear_memory()
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –æ—Ü–µ–Ω–∫—É
    result = evaluator.evaluate_model(
        model_name=model_config["name"],
        load_model_func=model_config["load_func"],
        generate_func=model_config["generate_func"],
        hyperparameters=model_config["hyperparameters"]
    )
    
    if result.get("status") == "error":
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ü–µ–Ω–∫–µ –º–æ–¥–µ–ª–∏: {result.get('error')}")
        return result
    
    # –ê–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ Gemini (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω)
    if use_gemini:
        print(f"\n{'='*80}")
        print(f"–ê–ù–ê–õ–ò–ó –û–®–ò–ë–û–ö –ß–ï–†–ï–ó GEMINI API")
        print(f"{'='*80}")
        
        parsing_errors = result.get("parsing_errors", [])
        quality_metrics = result.get("quality_metrics", {})
        hyperparameters = result.get("hyperparameters", {})
        
        print(f"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:")
        print(f"   ‚Ä¢ –û—à–∏–±–æ–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞: {len(parsing_errors)}")
        if quality_metrics:
            mass_errors = len(quality_metrics.get('–º–∞—Å—Å–æ–≤–∞—è –¥–æ–ª—è', {}).get('–æ—à–∏–±–∫–∏', []))
            prochee_errors = len(quality_metrics.get('–ø—Ä–æ—á–µ–µ', {}).get('–æ—à–∏–±–∫–∏', []))
            print(f"   ‚Ä¢ –û—à–∏–±–æ–∫ –∫–∞—á–µ—Å—Ç–≤–∞ '–º–∞—Å—Å–æ–≤–∞—è –¥–æ–ª—è': {mass_errors}")
            print(f"   ‚Ä¢ –û—à–∏–±–æ–∫ –∫–∞—á–µ—Å—Ç–≤–∞ '–ø—Ä–æ—á–µ–µ': {prochee_errors}")
        print(f"   ‚Ä¢ –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {len(hyperparameters)} –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")
        print()
        
        if not GEMINI_API_KEY:
            print("GEMINI_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ Gemini")
        else:
            print("–û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ Gemini...")
            prompt_full_text = result.get("prompt_full_text")
            gemini_analysis = analyze_errors_with_gemini(
                model_name=model_config["name"],
                parsing_errors=parsing_errors,
                quality_metrics=quality_metrics or {},
                hyperparameters=hyperparameters,
                prompt_full_text=prompt_full_text,
                gemini_api_key=GEMINI_API_KEY
            )
            
            if gemini_analysis.get("status") == "success":
                print("–ê–Ω–∞–ª–∏–∑ –æ—Ç Gemini –ø–æ–ª—É—á–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
                print(f"\n{'‚îÄ'*80}")
                print("üìù –ê–ù–ê–õ–ò–ó –ò –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
                print(f"{'‚îÄ'*80}")
                analysis_text = gemini_analysis.get("analysis", "")
                print(analysis_text)
                print(f"{'‚îÄ'*80}\n")
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑ –≤ JSON
                timestamp = result.get("timestamp", datetime.now().strftime("%Y%m%d_%H%M%S"))
                model_name_safe = model_config["name"].replace("/", "_").replace("\\", "_")
                analysis_path = os.path.join(OUTPUT_DIR, f"gemini_analysis_{model_name_safe}_{timestamp}.json")
                
                analysis_data = {
                    "model_name": model_config["name"],
                    "timestamp": timestamp,
                    "analysis": analysis_text,
                    "model_used": gemini_analysis.get("model_used", "gemini-2.5-flash"),
                    "parsing_errors_count": len(parsing_errors),
                    "quality_metrics_summary": {
                        "–º–∞—Å—Å–æ–≤–∞—è –¥–æ–ª—è": {
                            "precision": quality_metrics.get('–º–∞—Å—Å–æ–≤–∞—è –¥–æ–ª—è', {}).get('precision', 0) if quality_metrics else 0,
                            "recall": quality_metrics.get('–º–∞—Å—Å–æ–≤–∞—è –¥–æ–ª—è', {}).get('recall', 0) if quality_metrics else 0,
                            "f1": quality_metrics.get('–º–∞—Å—Å–æ–≤–∞—è –¥–æ–ª—è', {}).get('f1', 0) if quality_metrics else 0
                        },
                        "–ø—Ä–æ—á–µ–µ": {
                            "precision": quality_metrics.get('–ø—Ä–æ—á–µ–µ', {}).get('precision', 0) if quality_metrics else 0,
                            "recall": quality_metrics.get('–ø—Ä–æ—á–µ–µ', {}).get('recall', 0) if quality_metrics else 0,
                            "f1": quality_metrics.get('–ø—Ä–æ—á–µ–µ', {}).get('f1', 0) if quality_metrics else 0
                        }
                    } if quality_metrics else None
                }
                
                import json
                with open(analysis_path, 'w', encoding='utf-8') as f:
                    json.dump(analysis_data, f, ensure_ascii=False, indent=2)
                print(f"–ê–Ω–∞–ª–∏–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ JSON: {analysis_path}\n")
            else:
                print(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∞–Ω–∞–ª–∏–∑ –æ—Ç Gemini")
                print(f"   –ü—Ä–∏—á–∏–Ω–∞: {gemini_analysis.get('message', 'Unknown error')}\n")
    else:
        print(f"\n–ê–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ Gemini API –ø—Ä–æ–ø—É—â–µ–Ω (API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –∏–ª–∏ –æ—Ç–∫–ª—é—á–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º)\n")
    
    return result


# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–µ–π
MODEL_CONFIGS = {
    "gemma-2-2b": {
        "name": "google/gemma-2-2b-it",
        "load_func": ml.load_gemma_2_2b,
        "generate_func": ml.generate_standard,
        "hyperparameters": {
            "max_new_tokens": 512,
            "do_sample": False,
            "torch_dtype": "bfloat16"
        }
    },
    "qwen-2.5-1.5b": {
        "name": "Qwen/Qwen2.5-1.5B-Instruct",
        "load_func": ml.load_qwen_2_5_1_5b,
        "generate_func": ml.generate_qwen,
        "hyperparameters": {
            "max_new_tokens": 512,
            "do_sample": False,
            "torch_dtype": "bfloat16"
        }
    },
    "qwen-2.5-3b": {
        "name": "Qwen/Qwen2.5-3B-Instruct",
        "load_func": ml.load_qwen_2_5_3b,
        "generate_func": ml.generate_qwen,
        "hyperparameters": {
            "max_new_tokens": 1024,
            "do_sample": False,
            "dtype": "bfloat16"
        }
    },
    "qwen-2.5-4b": {
        "name": "Qwen/Qwen2.5-4B-Instruct",
        "load_func": ml.load_qwen_2_5_4b,
        "generate_func": ml.generate_qwen,
        "hyperparameters": {
            "max_new_tokens": 512,
            "do_sample": False,
            "dtype": "bfloat16"
        }
    },
    "gemma-3-4b": {
        "name": "google/gemma-3-4b-it",
        "load_func": ml.load_gemma_3_4b,
        "generate_func": ml.generate_gemma,
        "hyperparameters": {
            "max_new_tokens": 512,
            "do_sample": False,
            "torch_dtype": "bfloat16"
        }
    },
    "Ministral-3-3B-Reasoning-2512": {
        "name": "mistralai/Ministral-3-3B-Reasoning-2512",
        "load_func": ml.load_ministral_3_3b_reasoning_2512,
        "generate_func": ml.generate_standard,
        "hyperparameters": {
            "max_new_tokens": 512,
            "do_sample": False,
            "torch_dtype": "bfloat16"
        }
    },
    "Ministral-3-3B-Instruct-2512": {
        "name": "mistralai/Ministral-3-3B-Instruct-2512",
        "load_func": ml.load_ministral_3_3b_instruct_2512,
        "generate_func": ml.generate_standard,
        "hyperparameters": {
            "max_new_tokens": 512,
            "do_sample": False,
            "torch_dtype": "bfloat16"
        }
    },
    "CHEMLLM-2b-1_5": {
        "name": "AI4Chem/CHEMLLM-2b-1_5",
        "load_func": ml.load_chemllm_2b_1_5,
        "generate_func": ml.generate_standard,
        "hyperparameters": {
            "max_new_tokens": 1024,
            "do_sample": False,
            "torch_dtype": "bfloat16"
        }
    },
    "Phi-3.5-mini-instruct": {
        "name": "microsoft/Phi-3.5-mini-instruct",
        "load_func": ml.load_phi_3_5_mini_instruct,
        "generate_func": ml.generate_standard,
        "hyperparameters": {
            "max_new_tokens": 1024,
            "do_sample": False,
            "torch_dtype": "bfloat16"
        }
    },
    "phi-4-mini-instruct": {
        "name": "microsoft/Phi-4-mini-instruct",
        "load_func": ml.load_phi_4_mini_instruct,
        "generate_func": ml.generate_standard,
        "hyperparameters": {
            "max_new_tokens": 1024,
            "do_sample": False,
            "dtype": "bfloat16"
        }
    },
    "mistral-7b-v0.3-bnb-4bit": {
        "name": "unsloth/mistral-7b-v0.3-bnb-4bit",
        "load_func": ml.load_mistral_7b_v0_3_bnb_4bit,
        "generate_func": ml.generate_standard,
        "hyperparameters": {
            "max_new_tokens": 1024,
            "do_sample": False,
            "quantization": "4-bit (pre-quantized)"
        }
    }
}


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å Gemini API –≤ —Å–∞–º–æ–º –Ω–∞—á–∞–ª–µ
    print(f"\n{'='*80}")
    print(f"–ü–†–û–í–ï–†–ö–ê –°–ò–°–¢–ï–ú–´")
    print(f"{'='*80}")
    # GEMINI_API_KEY –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –∏–∑ config.py (–∫–æ—Ç–æ—Ä—ã–π –±–µ—Ä–µ—Ç –µ–≥–æ –∏–∑ config_secrets.py –∏–ª–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è)
    
    if GEMINI_API_KEY:
        print(f"–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ Gemini API...")
        gemini_working, gemini_message = check_gemini_api(GEMINI_API_KEY)
        print(f"   {gemini_message}\n")
    else:
        print(f"GEMINI_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É API")
        gemini_working = False
        print()
    
    use_gemini = True
    if not gemini_working:
        print(f"{'='*80}")
        print(f"–í–ù–ò–ú–ê–ù–ò–ï: Gemini API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        print(f"{'='*80}")
        print(f"–û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ –±—É–¥–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∞, –Ω–æ –∞–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫ —á–µ—Ä–µ–∑ Gemini –±—É–¥–µ—Ç –ø—Ä–æ–ø—É—â–µ–Ω.")
        print(f"–í—ã –º–æ–∂–µ—Ç–µ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å –±–µ–∑ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ –æ—à–∏–±–æ–∫ –∏–ª–∏ –∏—Å–ø—Ä–∞–≤–∏—Ç—å –ø—Ä–æ–±–ª–µ–º—É –∏ –∑–∞–ø—É—Å—Ç–∏—Ç—å –∑–∞–Ω–æ–≤–æ.\n")
        
        while True:
            response = input("–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –±–µ–∑ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ –æ—à–∏–±–æ–∫? (y/n): ").strip().lower()
            if response in ['y', 'yes', '–¥–∞', '–¥']:
                use_gemini = False
                print("–ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ –æ—à–∏–±–æ–∫...\n")
                break
            elif response in ['n', 'no', '–Ω–µ—Ç', '–Ω']:
                print("–ó–∞–ø—É—Å–∫ –æ—Ç–º–µ–Ω—ë–Ω. –ò—Å–ø—Ä–∞–≤—å—Ç–µ –ø—Ä–æ–±–ª–µ–º—É —Å Gemini API –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.")
                return
            else:
                print("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ 'y' (–¥–∞) –∏–ª–∏ 'n' (–Ω–µ—Ç)")
    
    # –¢–µ–ø–µ—Ä—å –ø—Ä–æ–≤–µ—Ä—è–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    if len(sys.argv) < 2:
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python main.py <model_name>")
        print("\n–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏:")
        for key in MODEL_CONFIGS.keys():
            print(f"  - {key}")
        return
    
    model_key = sys.argv[1]
    
    if model_key not in MODEL_CONFIGS:
        print(f"–ú–æ–¥–µ–ª—å '{model_key}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")
        print("–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏:", ", ".join(MODEL_CONFIGS.keys()))
        return
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞
    if not os.path.exists(DATASET_PATH):
        print(f"–î–∞—Ç–∞—Å–µ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω: {DATASET_PATH}")
        print("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª results_var3.xlsx –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –ø–∞–ø–∫–µ data/")
        return
    
    print(f"\n{'='*80}")
    print(f"–ó–ê–ü–£–°–ö –û–¶–ï–ù–ö–ò –ú–û–î–ï–õ–ò")
    print(f"{'='*80}")
    print(f"üìå –ú–æ–¥–µ–ª—å: {model_key}")
    print(f"üìå –ü–æ–ª–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ: {MODEL_CONFIGS[model_key]['name']}")
    print(f"üìÅ –î–∞—Ç–∞—Å–µ—Ç: {DATASET_PATH}")
    print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã: {OUTPUT_DIR}")
    print(f"üìÖ –í—Ä–µ–º—è –∑–∞–ø—É—Å–∫–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"{'='*80}\n")
    
    config = MODEL_CONFIGS[model_key]
    result = run_evaluation(config, use_gemini=use_gemini)
    
    if result.get("status") != "error":
        print(f"\n{'='*80}")
        print(f"üéâ –§–ò–ù–ê–õ–¨–ù–ê–Ø –°–í–û–î–ö–ê")
        print(f"{'='*80}")
        print(f"–û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ '{model_key}' –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
        print(f"\n–û—Å–Ω–æ–≤–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
        print(f"   ‚Ä¢ –ú–æ–¥–µ–ª—å: {result.get('model_name', 'N/A')}")
        print(f"   ‚Ä¢ –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {result.get('average_response_time_seconds', 0) * result.get('total_samples', 0) / 60:.2f} –º–∏–Ω—É—Ç")
        print(f"   ‚Ä¢ –°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å: {result.get('average_response_time_seconds', 0):.3f} —Å–µ–∫/–æ—Ç–≤–µ—Ç")
        print(f"   ‚Ä¢ –û—à–∏–±–∫–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞: {result.get('parsing_error_rate', 0):.2%} ({result.get('invalid_json_count', 0)}/{result.get('total_samples', 0)})")
        print(f"   ‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏: {result.get('gpu_memory_during_inference_gb', 0):.2f} GB")
        
        quality = result.get('quality_metrics')
        if quality:
            print(f"\nüéØ –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞:")
            mass = quality.get('–º–∞—Å—Å–æ–≤–∞—è –¥–æ–ª—è', {})
            prochee = quality.get('–ø—Ä–æ—á–µ–µ', {})
            print(f"   ‚Ä¢ '–º–∞—Å—Å–æ–≤–∞—è –¥–æ–ª—è':")
            print(f"     - Accuracy: {mass.get('—Å—Ä–µ–¥–Ω—è—è_—Ç–æ—á–Ω–æ—Å—Ç—å', 0):.2%}")
            print(f"     - Precision: {mass.get('precision', 0):.2%}, Recall: {mass.get('recall', 0):.2%}, F1: {mass.get('f1', 0):.2%}")
            print(f"   ‚Ä¢ '–ø—Ä–æ—á–µ–µ':")
            print(f"     - Accuracy: {prochee.get('—Å—Ä–µ–¥–Ω—è—è_—Ç–æ—á–Ω–æ—Å—Ç—å', 0):.2%}")
            print(f"     - Precision: {prochee.get('precision', 0):.2%}, Recall: {prochee.get('recall', 0):.2%}, F1: {prochee.get('f1', 0):.2%}")
        
        print(f"\nüìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {OUTPUT_DIR}")
        print(f"{'='*80}\n")


if __name__ == "__main__":
    main()

