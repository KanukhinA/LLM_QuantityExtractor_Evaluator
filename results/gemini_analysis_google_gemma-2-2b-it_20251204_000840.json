{
  "model_name": "google/gemma-2-2b-it",
  "timestamp": "20251204_000840",
  "analysis": "Как эксперт по оценке качества работы языковых моделей, я проанализировал представленные результаты тестирования модели `google/gemma-2-2b-it` и готов предоставить детальный анализ и рекомендации.\n\n**Общая оценка:**\nМодель демонстрирует крайне низкие метрики качества (F1-score ~11% для \"массовой доли\" и ~21% для \"прочего\"). Это указывает на то, что модель не справляется с поставленной задачей извлечения информации. Основные проблемы связаны как с генерацией корректного JSON-формата, так и с точностью и полнотой извлечения самих данных.\n\n---\n\n### 1. Характерные ошибки модели\n\n1.  **Проблемы с JSON-форматом:** Это наиболее критичная проблема. Значительная часть ответов является невалидным JSON (22 примера из неизвестного общего количества, но это высокий процент). Это делает результаты неиспользуемыми без дополнительной пост-обработки.\n    *   **Обрезка (Truncation):** Ответы часто обрываются, что видно по `...` и неполным JSON-структурам.\n    *   **Некорректная структура:** Модель генерирует частичные объекты, пустые ответы, повторяющиеся фразы вместо JSON, или пытается использовать синтаксис markdown (` ``` `) некорректно.\n    *   **Лишний текст:** В некоторых случаях модель добавляет нерелевантный или повторяющийся текст перед, внутри или после JSON.\n\n2.  **Низкая точность извлечения (\"Precision\"):**\n    *   **Галлюцинации/Переизбыточное извлечение:** Модель предсказывает параметры и значения, которых нет в исходном тексте (например, `NH4+` с предсказанным `[None, 2.0]`, несуществующие \"масса брутто\", \"масса нетто\", \"объем нетто единицы\"). Это сильно снижает Precision.\n    *   **Некорректное распознавание параметров:** Предсказывает \"марка: n7-p20-k30-s3\", хотя такого параметра в истинных данных нет, возможно, неверно интерпретируя часть маркировки как отдельный параметр.\n\n3.  **Низкая полнота извлечения (\"Recall\"):**\n    *   **Пропуск сущностей:** Низкий Recall (особенно 15.09% для массовой доли) означает, что модель пропускает значительное количество параметров, которые должна была извлечь.\n\n4.  **Ошибки в значениях и форматах:**\n    *   **Некорректная обработка диапазонов:** Вместо `[29.0, 31.0]` предсказывается `30.0`. Это указывает на неспособность модели распознавать и правильно форматировать диапазоны, даже когда они явно указаны.\n    *   **Неточность в диапазонах:** Предсказанные диапазоны могут быть близки, но не совпадать с истинными (например, `[20.0, 22.0]` вместо `[19.0, 21.0]`).\n    *   **Проблемы с `не менее`/`не более`:** Предсказывает `[2.0, 2.0]` вместо `[2.0, None]`, указывая на то, что модель не всегда правильно интерпретирует открытые диапазоны или воспринимает их как закрытые.\n\n---\n\n### 2. Причины ошибок парсинга JSON\n\nОсновной причиной является недостаточная способность маленькой модели `gemma-2-2b-it` (2 миллиарда параметров) следовать сложным и строгим инструкциям по форматированию вывода, особенно в формате JSON.\n1.  **Ограниченная мощность модели:** Маленькие модели часто испытывают трудности с генерацией сложной, вложенной и длинной JSON-структуры. Они могут \"забывать\" правила форматирования по ходу генерации.\n2.  **Недостаточный `max_new_tokens`:** Судя по обрывкам JSON (`...`), значение `max_new_tokens: 512` является слишком малым для многих ответов. Модель просто не успевает сгенерировать полный и валидный JSON.\n3.  **Проблемы с инструкциями:** Хотя промпт очень подробный, для небольшой модели это может быть перегруз. Множество мелких правил (\"точку в качестве разделителя\", \"маленькие буквы\", \"замена K на K2O\", \"диапазоны\") конкурируют за \"внимание\" модели.\n4.  **Репетативная генерация:** В примере \"НАСЫПЬ. НАСЫПЬ.\" модель \"застряла\" в цикле, генерируя бессмысленный повторяющийся текст, полностью игнорируя задачу извлечения и JSON-форматирования. Это частый \"режим отказа\" у небольших моделей.\n5.  **Наличие лишних символов/маркдауна:** В некоторых случаях модели могут добавлять обратные кавычки (` ``` `) или другие символы, которые ломают парсинг JSON, пытаясь сформировать блок кода.\n\n---\n\n### 3. Причины ошибок в извлечении данных\n\n1.  **Сложность предметной области:** Химические термины, их сокращения, специфические метрики (P2O5, K2O) требуют глубокого понимания контекста. Маленькой модели трудно это освоить без специализированного файнтюнинга.\n2.  **Недостаточное понимание контекста:** Модель может путать разные численные значения или неправильно связывать их с единицами измерения/параметрами. Например, она могла видеть число 2.0 в тексте и случайно связать его с NH4+, хотя в тексте это не было явной массовой долей.\n3.  **Ambiguity в промпте/тексте:** Несмотря на детализацию промпта, для модели могут оставаться неясности, например, когда извлекать \"марку\" как отдельный параметр, а когда нет, или какие числа считаются \"массовой долей\", а какие - \"прочим\".\n4.  **Отсутствие негативных примеров:** Промпт в основном сосредоточен на том, *что* извлекать, но мало говорит о том, *чего не следует* извлекать. Это приводит к переизбыточному извлечению и галлюцинациям.\n\n---\n\n### 4. Рекомендации по улучшению промпта\n\nПромпт очень подробный, но его можно оптимизировать для лучшей работы с LLM, особенно с небольшими:\n\n1.  **Упростить и стабилизировать JSON-структуру:**\n    *   **Избегать слишком глубокой вложенности:** Вместо `{\"массовая доля\": [{\"вещество\": \"N\", \"массовая доля\": [13, 15]}, ...]}` лучше сделать более плоскую структуру. Например, список объектов, где каждый объект – это один извлеченный признак:\n        ```json\n        [\n          {\"название признака\": \"массовая доля N\", \"значение\": [13, 15], \"единица измерения\": \"%\"},\n          {\"название признака\": \"массовая доля P2O5\", \"значение\": [40, 42], \"единица измерения\": \"%\"},\n          {\"название признака\": \"массовая доля K2O\", \"значение\": 13, \"единица измерения\": \"%\"},\n          {\"название признака\": \"стандарт\", \"значение\": \"ГОСТ 12345-2023\", \"единица измерения\": null}\n        ]\n        ```\n    *   **Явное указание схемы:** В начале промпта всегда давайте **конкретный пример ожидаемого JSON** с placeholder'ами, а затем объясняйте, как заполнять каждое поле.\n\n2.  **Приоритизировать и повторить ключевые инструкции:**\n    *   Самые важные правила (вывод *только* JSON, работа с диапазонами, `null`, десятичные разделители) должны быть в начале и, возможно, кратко повторены в конце.\n    *   \"Твой ответ должен быть **СТРОГО** JSON-массивом (списком объектов). **НЕ ДОБАВЛЯЙ НИКАКОГО ДРУГОГО ТЕКСТА, КОММЕНТАРИЕВ ИЛИ ФОРМАТИРОВАНИЯ (например, ```json).**\"\n\n3.  **Уточнить обработку диапазонов и `null`:**\n    *   Четко прописать примеры для `не менее` (`[min, null]`) и `не более` (`[null, max]`).\n    *   Особо подчеркнуть, что `null` должен использоваться, когда значение неизвестно или не применимо.\n    *   Для единичных значений (не диапазонов), использовать просто число, а не `[число, число]` (как сейчас, кажется, и ожидается, но модель иногда выдаёт `[2.0, 2.0]` вместо `2.0` или `[2.0, null]`).\n\n4.  **Добавить \"анти-инструкции\" (негативные примеры):**\n    *   Явно указать, что **не** следует извлекать, если это не соответствует критериям. Например: \"Не извлекай 'масса брутто' или 'масса нетто', если они не сопровождаются конкретным числовым значением в явном виде для *товара*.\"\n    *   \"Не извлекай химический элемент как 'массовую долю', если он является частью общей маркировки и нет отдельного числового значения.\"\n\n5.  **Разбить сложную логику:** Для маленькой модели может быть полезно \"имитировать\" цепь рассуждений:\n    *   \"Шаг 1: Сначала найди все численные данные и связанные с ними названия.\n    *   Шаг 2: Затем для каждого найденного элемента определи точное значение, единицу измерения и примени правила форматирования (диапазоны, `null`).\n    *   Шаг 3: Наконец, объедини все в валидный JSON-массив согласно приведенному примеру.\" (Хотя модель не будет выводить шаги, такое структурирование промпта может помочь ей \"подумать\" последовательно).\n\n---\n\n### 5. Рекомендации по настройке гиперпараметров\n\n1.  **`max_new_tokens` - Увеличить значительно:** Это **критично** для решения проблем с обрезкой JSON. 512 токенов явно недостаточно для многих ответов. Рекомендуется установить `max_new_tokens` на 1024, 2048 или даже выше (например, 4096), чтобы модель могла сгенерировать полный JSON.\n2.  **`do_sample: false` - Сохранить:** Для задач извлечения информации важна детерминированность и повторяемость результатов, поэтому отключение сэмплирования (`do_sample=false`) является правильным выбором. Не стоит менять этот параметр.\n3.  **`temperature`, `top_p`, `top_k`:** Эти параметры неактивны при `do_sample=false`, поэтому их изменение не повлияет на результат.\n\n---\n\n### 6. Общие рекомендации по улучшению качества\n\n1.  **Выбор модели - Главный фактор:**\n    *   Модель `gemma-2-2b-it` (2 миллиарда параметров) является слишком маленькой для такой сложной и точной задачи. Для извлечения структурированных данных с соблюдением многих правил требуется более мощная модель.\n    *   **Рекомендуется использовать более крупные и способные модели**, такие как:\n        *   **Llama 3 8B-IT** или 70B-IT.\n        *   **Mixtral 8x7B-Instruct-v0.1**.\n        *   Более крупные версии Gemma, если они доступны и лучше настроены.\n        *   В коммерческих целях, API-модели (GPT-4, Claude 3 Opus/Sonnet), которые гораздо лучше справляются со следованием инструкциям и генерацией JSON.\n\n2.  **Файнтюнинг (Fine-tuning):**\n    *   Если вы ограничены в выборе модели и должны использовать `gemma-2-2b-it`, **файнтюнинг (LoRA/QLoRA) на большом и разнообразном наборе данных** является *единственным* способом значительно улучшить качество.\n    *   **Создайте обучающий датасет**, который включает:\n        *   Разнообразные тексты о химических веществах и удобрениях.\n        *   **Идеально отформатированный JSON** для каждого текста, который точно соответствует вашим правилам.\n        *   **Покройте все краевые случаи**: диапазоны, `не менее`/`не более`, пропуски, разные единицы, различные марки, стандарты.\n        *   **Включите негативные примеры:** Тексты, где *нет* данных для извлечения, или тексты с \"отвлекающими\" числами, которые не должны быть извлечены.\n\n3.  **Пост-обработка (Post-processing):**\n    *   Внедрите надежный парсер JSON с обработкой ошибок. Если модель выдает невалидный JSON, попробуйте \"починить\" его (например, добавить недостающие скобки, удалить лишние запятые, обрезать лишний текст).\n    *   Напишите скрипты для проверки и коррекции извлеченных значений (например, если диапазон `[Y, X]` и `Y > X`, поменяйте их местами; если предсказано `[2.0, 2.0]` для единичного значения, превратите в `2.0`).\n\n4.  **Итеративная разработка:**\n    *   Изменения в промпте и гиперпараметрах должны тестироваться итеративно. Вносите одно изменение за раз, чтобы оценить его влияние.\n\nПрименение этих рекомендаций, особенно переход на более мощную модель или файнтюнинг, должно значительно улучшить качество извлечения и снизить количество ошибок парсинга JSON.",
  "model_used": "gemini-2.5-flash",
  "parsing_errors_count": 22,
  "quality_metrics_summary": {
    "массовая доля": {
      "precision": 0.08664259927797834,
      "recall": 0.1509433962264151,
      "f1": 0.11009174311926606
    },
    "прочее": {
      "precision": 0.15538847117794485,
      "recall": 0.3583815028901734,
      "f1": 0.21678321678321674
    }
  }
}