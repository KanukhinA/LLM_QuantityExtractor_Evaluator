{
  "model_name": "gemma-3-27b-it",
  "timestamp": "20260125_142702",
  "analysis": "Привет! Как эксперт по оценке качества работы языковых моделей, я проанализировал предоставленные результаты тестирования модели `gemma-3-27b-it` по задаче извлечения численных и количественных характеристик из текстов о химических веществах и удобрениях.\n\n---\n### Анализ результатов тестирования `gemma-3-27b-it`\n\n**Метрики качества:**\n*   **Массовая доля:** Accuracy: 85.17%, Precision: 88.85%, Recall: 75.87%, F1: 81.85%\n*   **Прочее:** Accuracy: 54.05%, Precision: 70.26%, Recall: 60.35%, F1: 64.93%\n\n**Пример ошибки:**\n*   **Исходный текст:** Длинный текст с множеством продуктов и их характеристик.\n*   **Ответ модели:** `{\"вещество\": \"Mg\", \"массовая доля`\n\n**Гиперпараметры:**\n*   `max_new_tokens`: 512\n*   `model_name`: \"gemma-3-27b-it\"\n\n---\n\n#### 1. Характерные ошибки модели\n\n1.  **Обрезание (Truncation) вывода:** Наиболее очевидная и критичная ошибка. Ответ модели обрывается на полуслове (`\"массовая доля`), что делает JSON невалидным и непригодным для парсинга. Это прямое следствие ограничения `max_new_tokens`.\n2.  **Неправильная структура JSON на корневом уровне:** Даже до обрезания модель начинает генерировать JSON с некорректной структурой. Вместо ожидаемых `{ \"массовая доля\": [...], \"прочее\": [...] }`, она начинает с `{\"вещество\": \"Mg\", \"массовая доля`. Это указывает на фундаментальное непонимание или игнорирование предписанной корневой структуры JSON.\n3.  **Низкий Recall для категории \"Прочее\":** F1-score 64.93% и Recall 60.35% для \"Прочее\" показывают, что модель пропускает значительную часть информации из этой категории. Это может быть связано с тем, что \"прочие\" признаки более разнообразны и менее стандартизированы, чем массовые доли, а также с большим объемом правил в промпте.\n4.  **Сложность обработки множественных сущностей:** Исходный текст в примере ошибки содержит описания *нескольких* удобрений, каждое со своим набором массовых долей. Текущая структура JSON предполагает агрегирование или извлечение одного набора. Модель могла запутаться, какой набор данных извлекать, или как агрегировать их, если это подразумевалось.\n\n#### 2. Причины ошибок парсинга JSON\n\n1.  **Недостаточный `max_new_tokens`:** Это основная причина невалидного JSON. Модель не успевает сгенерировать полный и корректно закрытый JSON-объект. Пример JSON в промпте сам по себе занимает более 250 символов, а реальные данные могут быть намного длиннее.\n2.  **Несоблюдение заданной JSON схемы:** Модель не следует явно указанной корневой структуре JSON. Даже если бы `max_new_tokens` был достаточен, начальная строка вывода `{\"вещество\": \"Mg\", \"массовая доля` говорит о том, что она попыталась поместить элементы `вещество` и `массовая доля` непосредственно в корневой объект, а не внутри массива `массовая доля`, как показано в примере.\n\n#### 3. Причины ошибок в извлечении данных\n\n1.  **Высокая когнитивная нагрузка от промпта:** Промпт очень длинный (3768 символов) и содержит множество детализированных правил и исключений. Gemma-3-27b-it, хотя и большая модель, может испытывать трудности с одновременным удержанием всех этих инструкций и применением их к объемному входному тексту. Модель могла уделить больше внимания извлечению самих значений, чем строгому соблюдению JSON-структуры.\n2.  **Длинный входной текст:** Пример входного текста также довольно большой. Сочетание длинного промпта и длинного входного текста может приводить к \"давлению на контекстное окно\", когда модель начинает игнорировать или плохо применять часть инструкций.\n3.  **Сложность классификации \"Прочее\":** Из-за разнообразия \"прочих\" характеристик и специфических правил для них (например, про массу нетто/брутто, стандарты, марки) модели сложнее их единообразно распознавать и правильно форматировать, что объясняет низкий Recall.\n4.  **Конфликт между правилом и примером JSON:**\n    *   Пункт 2 \"Единицу измерения (%, кг, т, шт, п/э меш, вагон, или пусто для стандарта)\" намекает, что единица должна быть для всех численных признаков.\n    *   НО, пример JSON **не** содержит `единица: \"%\"` для элементов в массиве `\"массовая доля\"`. Он содержит `единица` только для \"прочих\" параметров (кроме стандарта и марки). Эта незначительная нестыковка может вызывать путаницу у модели.\n\n#### 4. Рекомендации по улучшению промпта\n\n1.  **Уточнить обработку множественных продуктов:**\n    *   Текущий пример JSON предполагает единый набор массовых долей и прочих параметров. Если в тексте встречаются описания *нескольких* разных продуктов (как в примере ошибки), необходимо явно указать, что делать:\n        *   Извлекать *все* продукты в виде массива объектов (например, `[{\"продукт 1\": {\"массовая доля\": [...], \"прочее\": [...]}}, {\"продукт 2\": {...}}]`)\n        *   Игнорировать все, кроме первого/последнего.\n        *   Агрегировать все данные в единый список, если это логично.\n    *   **Предлагаемое изменение:** Если требуется извлекать данные по каждому отдельному продукту, то JSON-структура должна быть изменена, например, на массив объектов, где каждый объект представляет один продукт и содержит в себе \"массовую долю\" и \"прочее\".\n\n2.  **Повторное акцентирование корневой JSON структуры:**\n    *   Несмотря на пример, модель неверно начала JSON. Можно добавить более явное и, возможно, визуально выделенное напоминание о том, как должен начинаться JSON. Например:\n        ```\n        ОБРАТИТЕ ВНИМАНИЕ: JSON должен начинаться с:\n        {\n          \"массовая доля\": [...],\n          \"прочее\": [...]\n        }\n        ```\n\n3.  **Согласование правил и примера JSON:**\n    *   Устранить расхождение относительно `единица` для массовых долей. Если в примере JSON `единица: \"%\"` не указывается для массовых долей, то и в пункте 2 (про определение единиц измерения) явно указать, что для массовых долей она **не** извлекается в JSON (подразумевается, что это всегда %).\n\n4.  **Возможное сокращение/перефразирование промпта:**\n    *   Хотя подробность важна, можно попробовать перефразировать некоторые \"особые указания\" более сжато, если это не приведет к потере ясности. Некоторые правила, возможно, можно объединить.\n\n#### 5. Рекомендации по настройке гиперпараметров\n\n1.  **Увеличить `max_new_tokens`:** Это самая срочная и важная рекомендация. Текущие 512 токенов явно недостаточны. Для сложных экстракций и объемных входных текстов рекомендуется установить значение от **2048 до 4096** токенов, в зависимости от ожидаемой длины вывода. Это напрямую решит проблему обрезания JSON.\n\n#### 6. Общие рекомендации по улучшению качества\n\n1.  **Использование Post-processing для валидации JSON:** Внедрить на стороне приложения логику для проверки валидности JSON. Если JSON невалиден (например, обрезан), можно либо повторить запрос, либо попытаться восстановить его (что сложнее, если структура нарушена).\n2.  **Fine-tuning (тонкая настройка модели):** Если задача является критичной и имеет большой объем данных для обучения, тонкая настройка модели на специфическом датасете (пар \"промпт + входной текст\" -> \"корректный JSON-выход\") значительно улучшит точность и следование JSON-схеме.\n3.  **Разбиение задачи (Task Decomposition):** Если модель продолжает испытывать трудности с извлечением всех типов данных и формированием JSON за один проход:\n    *   Можно разделить задачу на этапы:\n        1.  Извлечь все массовые доли в простом формате.\n        2.  Извлечь все \"прочие\" признаки в простом формате.\n        3.  Затем с помощью другого запроса или программно скомпоновать эти данные в нужный JSON-формат.\n    *   Или, если текст содержит множественные сущности, сначала извлечь отдельные блоки информации по каждому продукту, а затем обрабатывать каждый блок.\n4.  **Эксперименты с другими моделями:** Возможно, другие модели (например, Claude, Llama 3, или более новые версии Gemma, если доступны) лучше справляются с длинными инструкциями и генерацией сложного JSON.\n5.  **Добавление \"Guardrails\" в промпт:** Добавить в промпт явные инструкции по обработке ошибок или неполной информации, например: \"Если ты не можешь извлечь какое-либо значение, не включай соответствующий ключ в JSON\" (хотя это уже отчасти есть), или \"Убедись, что JSON всегда валиден и закрыт\".\n\nНачать стоит с увеличения `max_new_tokens` и уточнения корневой структуры JSON в промпте. Это должно значительно улучшить базовую работоспособность системы.",
  "model_used": "gemini-2.5-flash",
  "parsing_errors_count": 1,
  "hyperparameters": {
    "max_new_tokens": 512,
    "model_name": "gemma-3-27b-it",
    "api_model": true
  },
  "system_info": {
    "api_model": true,
    "multi_agent_mode": null,
    "gpu_info": {
      "api": true
    },
    "gpu_memory_during_inference_gb": 0.0,
    "average_response_time_seconds": 10.923278722763062
  },
  "quality_metrics_summary": {
    "массовая доля": {
      "accuracy": 0.8517464295659785,
      "precision": 0.8884758364312267,
      "recall": 0.7587301587301587,
      "f1": 0.8184931506849316
    },
    "прочее": {
      "accuracy": 0.540504403004403,
      "precision": 0.7025641025641025,
      "recall": 0.6035242290748899,
      "f1": 0.6492890995260664
    }
  }
}