{
  "model_name": "Qwen_Qwen2.5-1.5B-Instruct_20251204",
  "timestamp": "20251224_013948",
  "reevaluated_from": "results/results_Qwen_Qwen2.5-1.5B-Instruct_20251204_011804.csv",
  "analysis": "Как эксперт по оценке качества работы языковых моделей, я провел анализ представленных результатов тестирования модели Qwen_Qwen2.5-1.5B-Instruct.\n\n**Резюме и общая оценка:**\nМодель демонстрирует крайне низкое качество выполнения задачи. Метрики F1 менее 3% для категории \"массовая доля\" и около 12.6% для \"прочее\" указывают на фундаментальные проблемы как с извлечением информации, так и с генерацией выходного формата. Значительное количество ошибок парсинга JSON и галлюцинации данных подтверждают это. Модель Qwen 1.5B, будучи относительно небольшой, часто испытывает трудности с соблюдением строгих структурных требований и точным извлечением без специализированного дообучения.\n\n---\n\n### 1. Характерные ошибки модели\n\n*   **Крайне низкая точность извлечения:** Метрики Precision, Recall и F1 в обеих категориях (особенно в \"массовой доле\") находятся на уровне случайного угадывания или даже ниже. Это означает, что модель либо почти ничего не извлекает, либо извлекает много неверного, либо и то, и другое.\n*   **Галлюцинации (ложные срабатывания):** Примеры ошибок качества (\"предсказано [значение], истина отсутствует\") явно показывают, что модель генерирует данные, которых нет во входном тексте. Эти \"предсказания\" часто выглядят как правдоподобные, но произвольные значения (например, атомные массы или округленные числа).\n*   **Повторения и зацикливание:** В примерах JSON-ошибок (Текст #86, #41, #93, #48) модель явно зацикливается, повторяя одни и те же фразы или фрагменты текста много раз. Это признак того, что модель \"застряла\" в генерации и не может найти подходящий выход.\n*   **Проблемы с JSON-форматом:** Модель либо вообще не генерирует JSON (как в примерах с повторениями), либо генерирует неполный/невалидный JSON (Текст #65). В этом примере она пытается начать JSON, но обрывается, и даже те части, что есть, выглядят как шаблон или общие данные, а не извлеченные из конкретного текста.\n*   **Смешение форматов:** В некоторых ответах модель генерирует обычный текст перед попыткой формирования JSON, что указывает на недостаточно строгое следование инструкциям по формату вывода.\n*   **Непонимание задачи извлечения:** Судя по галлюцинациям, модель, по-видимому, не понимает, что ее задача — *извлекать* информацию из предоставленного текста, а не *генерировать* правдоподобные значения на основе общего контекста или знаний о предметной области.\n\n### 2. Причины ошибок парсинга JSON\n\n*   **Недостаточная тренировка на строгих JSON-форматах:** Для небольших моделей (1.5B) требуется либо очень точный и подробный промпт, либо дообучение на большом количестве примеров с требуемой JSON-структурой. Без этого модель может не усвоить строгие правила синтаксиса (кавычки, скобки, запятые, типы данных).\n*   **Ограниченная способность к длинным и структурированным ответам:** Небольшие модели часто испытывают трудности с поддержанием целостности сложной структуры на протяжении всего ответа. Они могут \"терять\" контекст середины генерации JSON, что приводит к неполным ответам или синтаксическим ошибкам.\n*   **Проблемы с генерацией закрывающих элементов:** Модель часто не может завершить объекты или массивы, оставляя JSON неполным (как в примере #65).\n*   **Нечеткий промпт (предположительно):** Если промпт не содержит очень строгих инструкций по формату \"ТОЛЬКО JSON\", модель может отклоняться от него.\n*   **\"Застревание\" в генерации:** Повторяющиеся фрагменты текста, не являющиеся JSON, возникают, когда модель не может найти подходящий токен для продолжения или завершения ответа и входит в цикл.\n\n### 3. Причины ошибок в извлечении данных\n\n*   **Непонимание контекста и предметной области:** Хотя модель является \"instruct\", без дообучения на конкретных данных она может плохо понимать специфические термины и числовые значения в контексте промышленной документации или химических анализов.\n*   **Низкая точность определения сущностей (NER):** Модель не способна точно идентифицировать, что является \"веществом\", \"массовой долей\", \"массой нетто\" и т.д., и где их значения находятся в тексте.\n*   **Галлюцинации вместо извлечения:** Вместо того чтобы искать данные в тексте, модель, столкнувшись с незнакомой или сложной задачей, может генерировать правдоподобные, но вымышленные данные, используя свои общие знания. Это особенно характерно для небольших моделей, когда промпт недостаточно специфичен.\n*   **Недостаток примеров (Few-shot learning):** Если промпт не содержит достаточно демонстрационных примеров (few-shot examples), модель не получает достаточно \"подсказок\" о том, как именно извлекать и форматировать данные.\n\n### 4. Рекомендации по улучшению промпта (если промпт предоставлен)\n\n*   **1. Строгое указание формата JSON:**\n    *   Начать промпт с фразы: \"Ты — эксперт по извлечению структурированных данных. Твоя задача — проанализировать текст и извлечь указанную информацию, отвечая **СТРОГО в формате JSON**.\"\n    *   Явно указать, что **ничего, кроме JSON, не должно быть в ответе**. \"Ответ должен содержать **ТОЛЬКО** JSON-объект, без вводных фраз, пояснений или других символов.\"\n*   **2. Детальное описание JSON-схемы:**\n    *   Предоставить полную и чёткую JSON-схему с описанием каждого поля, его типа данных (строка, число, массив) и ожидаемого формата.\n    *   Пример:\n        ```json\n        {\n          \"массовая доля\": [\n            {\n              \"вещество\": \"строка (например, 'N', 'K2O')\",\n              \"массовая доля\": \"[число_от, число_до] или число (например, [20, 22] или 20.5)\"\n            }\n          ],\n          \"прочее\": {\n            \"параметр_1\": \"значение_1 (тип данных)\",\n            \"параметр_2\": \"значение_2 (тип данных)\"\n          }\n        }\n        ```\n*   **3. Примеры (Few-shot learning):**\n    *   Это **критически важно** для данной модели. Включите 1-3 (или больше, если возможно) полных примера: \"Входной текст: [пример текста] -> Ожидаемый JSON: [корректный JSON для этого текста]\".\n    *   Примеры должны охватывать различные сценарии: наличие всех данных, отсутствие некоторых данных (с `null` или отсутствующим полем).\n*   **4. Инструкция по обработке отсутствующих данных:**\n    *   \"Если какой-либо параметр или вещество не найдены в тексте, соответствующее поле должно быть либо **опущено**, либо его значение должно быть `null`.\" (Предпочтительнее опускать поле, чтобы избежать галлюцинаций `null`).\n    *   \"Модель не должна генерировать значения, которых нет во входном тексте.\"\n*   **5. Конкретизация извлечения:**\n    *   \"Извлекай **только** числовые значения и соответствующий текст, явно указанные в предоставленном тексте.\"\n    *   \"Если массовая доля указана как диапазон, извлекай оба значения. Если как одно число, используй его.\"\n*   **6. Использование системной роли (если поддерживается):**\n    *   Для моделей Qwen часто эффективно использовать `system` промпт для установки общих инструкций и формата, а `user` промпт для передачи конкретного текста на обработку.\n\n### 5. Рекомендации по настройке гиперпараметров\n\nГиперпараметр `reevaluated: true` не дает информации для настройки. Для улучшения качества необходимо работать со следующими:\n\n*   **Temperature (Температура):** **Уменьшить до 0.1 - 0.3.** Низкая температура делает ответы модели более детерминированными и менее склонными к галлюцинациям и творчеству, что критично для задачи извлечения.\n*   **Top-P / Top-K:** **Установить более низкие значения (например, `top_p=0.9`, `top_k=50` или ниже).** Это ограничивает словарный запас, из которого модель может выбирать следующее слово, снижая вероятность генерации случайных или несвязанных токенов.\n*   **Max New Tokens (Максимальное количество новых токенов):** Установите разумное ограничение, чтобы избежать бесконечных повторений, но достаточное для генерации полного JSON-объекта. Например, 512 или 1024 токена, в зависимости от ожидаемой сложности JSON.\n*   **Repetition Penalty (Штраф за повторения):** **Увеличить (например, до 1.1 - 1.3).** Это поможет бороться с зацикливанием и повторяющимися фрагментами текста, которые мы видели в ошибках парсинга.\n\n### 6. Общие рекомендации по улучшению качества\n\n1.  **Дообучение (Fine-tuning):** Это **самый эффективный** способ значительного улучшения качества для данной специфической задачи.\n    *   **Создайте размеченный датасет:** Пары (входной текст, ожидаемый корректный JSON-вывод). Чем больше таких примеров, тем лучше. Даже несколько сотен или тысяч хорошо размеченных примеров могут дать огромный прирост.\n    *   **Специализация:** Дообучение модели на ваших данных поможет ей лучше понимать терминологию, контекст и требуемый формат вывода.\n2.  **Использование более крупной модели:**\n    *   Модель Qwen 1.5B является относительно небольшой. Для сложных задач извлечения со строгими требованиями к формату более крупные модели (например, Qwen2-7B-Instruct, Llama-3-8B-Instruct или другие) обычно показывают значительно лучшие результаты, поскольку обладают большей способностью к рассуждению, пониманию инструкций и поддержанию структуры.\n3.  **Постобработка (Post-processing):**\n    *   Внедрите скрипты для проверки валидности JSON и исправления типичных ошибок (например, добавление закрывающих скобок, удаление повторяющихся фрагментов текста перед JSON).\n    *   Используйте библиотеки для парсинга JSON, чтобы убедиться, что вывод корректен. Если парсинг не удался, можно предпринять попытки восстановления или пометить ответ как ошибочный.\n4.  **Chain-of-Thought (CoT) или Multistep Prompting:**\n    *   Для очень сложных текстов можно попробовать разбить задачу для модели на несколько шагов в промпте. Например:\n        1.  \"Сначала извлеки все числовые значения и связанные с ними единицы/категории.\"\n        2.  \"Затем сопоставь их с требуемыми полями JSON-схемы.\"\n        3.  \"Наконец, сформируй JSON-объект.\"\n    *   Это может помочь модели последовательно выполнять задачу, но увеличит длину промпта и ответа.\n5.  **Улучшение качества входных данных:**\n    *   Убедитесь, что входные тексты максимально чистые, без лишнего шума или артефактов, которые могут сбивать модель.\n    *   Если есть вариации в написании одних и тех же параметров, попробуйте стандартизировать их на этапе предобработки или явно указать в промпте, какие варианты допустимы.\n\nНа основе текущих результатов, основной упор следует сделать на дообучение модели или переход на более мощную модель, а также на значительном улучшении промпта с включением подробных few-shot примеров.",
  "model_used": "gemini-2.5-flash",
  "parsing_errors_count": 31,
  "quality_metrics_summary": {
    "массовая доля": {
      "accuracy": 0.016069295101553166,
      "precision": 0.027237354085603113,
      "recall": 0.0330188679245283,
      "f1": 0.029850746268656716
    },
    "прочее": {
      "accuracy": 0.053826994518483884,
      "precision": 0.0918918918918919,
      "recall": 0.2,
      "f1": 0.12592592592592594
    }
  }
}