{
  "model_name": "google/gemma-3-1b-it",
  "timestamp": "20251221_180657",
  "analysis": "Отлично, давайте проведем глубокий анализ результатов тестирования модели `google/gemma-3-1b-it` для задачи извлечения численных и количественных характеристик из текстов о химических веществах.\n\n**Общий вывод:** Модель демонстрирует крайне низкое качество выполнения задачи, особенно в части соблюдения формата вывода JSON и корректности извлечения данных. Метрики 0% по \"массовой доле\" и очень низкие по \"прочему\" (F1 12.80%) говорят о системной проблеме.\n\n---\n\n### 1. Характерные ошибки модели\n\n1.  **Катастрофические ошибки JSON-парсинга:** Это самая серьезная проблема. Модель абсолютно неспособна генерировать валидный JSON в большинстве случаев. Это приводит к тому, что даже потенциально корректно извлеченные данные не могут быть обработаны.\n2.  **Глубокое непонимание структуры JSON:** В некоторых случаях модель проявляет \"рекурсивное\" поведение (пример Текст #54), пытаясь вложить объект `\"массовая доля\"` внутрь значения поля `\"массовая доля\"`, что указывает на полное отсутствие понимания требуемой иерархии данных.\n3.  **Несоответствие типов данных в JSON:** Модель путает массивы объектов с просто массивами или отдельными значениями, некорректно закрывает скобки, добавляет лишние `null` значения.\n4.  **Галюцинации (False Positives):** Модель предсказывает наличие веществ/параметров и их значений, которые отсутствуют в исходном тексте (примеры \"Кальций\", \"Сернокислый\", \"количество мешков\", \"объем нетто единицы\").\n5.  **Пропуски (False Negatives):** Модель не извлекает существующие в тексте данные (примеры \"N\" и \"P2O5\" в группе \"массовая доля\", где \"истина [7.0, 9.0]\" и \"истина [19.0, 21.0]\" соответственно).\n6.  **Неверная интерпретация типов параметров:** Модель присваивает числовые значения нечисловым параметрам (например, \"ТУ 20.15.52-089-05785164-2022: предсказано 1.0\", \"МИНЕРАЛЬНОЕ УДОБРЕНИЕ: предсказано 1.0\"), что говорит о непонимании природы извлекаемой информации.\n7.  **Неполные ответы:** Некоторые ответы обрываются (пример Текст #10, #54), что может быть связано как с `max_new_tokens`, так и с общим сбоем модели.\n\n---\n\n### 2. Причины ошибок парсинга JSON\n\n1.  **Отсутствие явного примера JSON-схемы в промпте:** Самая критичная причина. Хотя промпт детально описывает *что* извлекать и *как* форматировать отдельные поля, он не предоставляет **целостного, валидного примера JSON-структуры**. Модель вынуждена \"угадывать\" синтаксис, в результате чего возникают ошибки.\n2.  **Относительно небольшой размер модели (3.1B) для сложной задачи:** `gemma-3-1b-it` — это компактная модель. Малые модели часто плохо справляются со строгим следованием сложным инструкциям форматирования, особенно если они не были специально дообучены на подобные задачи с JSON-выводом.\n3.  **Длинный и детализированный промпт без четкой структуры JSON:** Чем больше текста в промпте, тем сложнее для модели низкого размера удерживать всю информацию в контексте. Отсутствие четкой визуальной структуры (например, отдельного блока с примером JSON) усугубляет проблему.\n4.  **Недостаточное количество примеров в промпте (Few-shot learning):** Если бы в промпте было несколько пар \"входной текст -> желаемый JSON-вывод\", модель могла бы лучше понять паттерны.\n5.  **Возможно, ограничение `max_new_tokens` (512):** Хотя 512 токенов обычно достаточно для средних JSON-объектов, если модель начинает галюцинировать или рекурсивно генерировать структуру, она может достичь этого лимита до завершения валидного JSON.\n\n---\n\n### 3. Причины ошибок в извлечении данных\n\n1.  **Невозможность парсинга JSON:** Если JSON невалиден, система оценки не может извлечь данные, что автоматически приводит к нулевым метрикам. Это маскирует потенциальные успехи в *поиске* информации.\n2.  **Недостаточное понимание предметной области:** Модель, похоже, плохо понимает контекст химических веществ и удобрений, путая названия (Сернокислый, Нефлинвое сырье), или неправильно классифицируя параметры (Минеральное удобрение как количественный показатель).\n3.  **Нечеткие или противоречивые инструкции:** Хотя промпт довольно детален, мелкие нюансы могут быть упущены. Например, модель может не до конца понимать разницу между `\"массовая доля N\"` и просто `\"азот\"`, или как обрабатывать стандарты (их номер – это значение, а не число).\n4.  **Галюцинации:** Это базовая проблема многих LLM, особенно небольших. При неуверенности модель может просто \"придумывать\" правдоподобные, но ложные данные.\n5.  **Недостаточная обученность на извлечение специфических сущностей:** Модель могла быть обучена на общие задачи, но не на тонкости извлечения химических формул, диапазонов, или конкретных типов измерений из такого рода текстов.\n\n---\n\n### 4. Рекомендации по улучшению промпта\n\nПромпт требует значительной переработки для обеспечения валидного JSON и повышения точности извлечения.\n\n1.  **Включить полный, валидный пример JSON-схемы:** Это самый важный шаг. Модель должна *видеть*, как выглядит правильный вывод. Разместите его в начале промпта, явно обозначив как пример.\n    ```json\n    {\n      \"массовая_доля\": [\n        {\"название\": \"N\", \"значение\": [8.0, 10.0], \"единица\": \"%\"},\n        {\"название\": \"P2O5\", \"значение\": 20.0, \"единица\": \"%\"},\n        {\"название\": \"K2O\", \"значение\": [null, 30.0], \"единица\": \"%\"}\n      ],\n      \"прочее\": [\n        {\"название\": \"масса нетто единицы\", \"значение\": 1000, \"единица\": \"кг\"},\n        {\"название\": \"стандарт\", \"значение\": \"ГОСТ 33333-2023\", \"единица\": \"\"},\n        {\"название\": \"количество вагонов\", \"значение\": 5, \"единица\": \"шт\"}\n      ]\n    }\n    ```\n    *   **Изменить ключи для ясности:** Например, `\"массовая доля\"` как родительский ключ и `\"название\"` внутри него для вещества. Это устранит неоднозначность и рекурсивность (как в Тексте #54).\n    *   **Унифицировать ключ для значения:** Использовать `\"значение\"` для всех численных/текстовых показателей, а не `\"масса\"`, `\"количество\"`, `\"объем\"`.\n\n2.  **Добавить несколько примеров (Few-shot learning):** Если промпт позволяет по длине, добавьте 1-3 пары \"входной текст + правильный JSON-выход\". Это значительно улучшит способность модели следовать формату.\n\n3.  **Четко указать действие при отсутствии данных:** \"Если для категории 'массовая_доля' или 'прочее' не найдено ни одного элемента, верните пустой массив: `[]`\".\n\n4.  **Упростить и структурировать инструкции:**\n    *   Выделить ключевые требования жирным шрифтом или отдельными блоками.\n    *   Переместить инструкции, касающиеся формата JSON (например, `[min, max]`, `[min, null]`, `[null, max]`, `.` для десятичных) ближе к примеру JSON или объединить их.\n\n5.  **Уточнить правила для `null`:** \"Для диапазонов 'не менее X' используй `[X, null]`, для 'не более Y' используй `[null, Y]`. Если точное число, используй `число` (не массив), или `[число, число]`.\" (Ваш промпт уже включает это, но нужно убедиться, что модель это понимает в контексте JSON).\n\n6.  **Уточнить правила для названий признаков:** \"Используй только обозначения химических элементов (N, P, K, Ca, S), а не полные названия. Все названия признаков с маленькой буквы. Например: `массовая доля N`, `массовая доля K2O`.\"\n\n7.  **Явно запретить рекурсию:** \"Категории `массовая_доля` и `прочее` не должны вкладываться сами в себя или в свои значения.\"\n\n---\n\n### 5. Рекомендации по настройке гиперпараметров\n\n1.  **`max_new_tokens`:** Текущие 512 токенов могут быть недостаточными, если модель генерирует много текста (даже ошибочного). Увеличьте `max_new_tokens` до **1024 или 2048**. Это позволит модели завершить свой вывод, даже если он некорректен, и даст больше информации для анализа ошибок. Не ждите, что это решит проблему качества, но поможет с полным выводом.\n2.  **`do_sample`:** `false` — это правильный выбор для задач извлечения информации, где требуется детерминированный и точный вывод, а не креативность. Оставьте его как есть.\n3.  **`torch_dtype`:** `bfloat16` — это стандартная и эффективная опция. Оставьте ее.\n\n---\n\n### 6. Общие рекомендации по улучшению качества\n\n1.  **Использование более крупной и мощной модели:** `gemma-3-1b-it` — довольно маленькая модель. Модели большего размера (например, Gemma 7B, Llama 3 8B/70B, Mixtral 8x7B) значительно лучше справляются со сложными инструкциями, следованием JSON-схемам и минимизацией галюцинаций. **Это самый быстрый и эффективный способ добиться существенного улучшения без дообучения.**\n2.  **Дообучение (Fine-tuning):** Если целевая модель должна быть именно `gemma-3-1b-it` из-за ограничений на ресурсы, то дообучение (fine-tuning) на **большом и разнообразном датасете** (состоящем из пар \"текст о веществе -> корректный JSON-вывод\") является обязательным. Это научит модель специфике предметной области и строгому соблюдению формата JSON.\n3.  **Инструменты для принудительного структурированного вывода:** Рассмотрите использование библиотек, таких как `Instructor` (для Python), которые интегрируются с LLM и позволяют описывать желаемый JSON-выход с помощью Pydantic-схем. Эти инструменты используют функцию вызова (function calling) или другие продвинутые методы промптинга, чтобы *гарантировать* валидный JSON-вывод.\n4.  **Валидация JSON после генерации:** Внедрите в свой пайплайн этап валидации сгенерированного JSON по заранее определенной схеме. Если вывод невалиден, его можно отклонить, повторить попытку или передать для ручного анализа. Это поможет отфильтровывать мусорные ответы и сосредоточиться на улучшении качества извлечения.\n5.  **Разделение задачи (если возможно):** Если модель продолжает бороться с одной большой задачей, можно попробовать разбить ее на более мелкие этапы (например, сначала извлечь все численные значения, затем классифицировать их, затем отформатировать). Однако для LLM с сильным промптингом часто лучше работают комплексные задачи.\n6.  **Уточнение сущностей и их границ:** Убедитесь, что модель четко понимает, какие \"вещества\" нужно извлекать, а какие — нет. Возможно, нужна более строгая формулировка, чтобы избежать галюцинаций (например, \"Извлекай только вещества, явно упомянутые в тексте с их массовой долей\").\n\n---\n\n**Итог:** Модель `gemma-3-1b-it` в текущей конфигурации совершенно не справляется с задачей. Основная причина — неспособность генерировать валидный JSON-формат и, как следствие, низкое качество извлечения данных. Наиболее критичным шагом является предоставление **четкого, полного JSON-примера в промпте** и рассмотрение использования **более мощной модели** или **дообучения**.",
  "model_used": "gemini-2.5-flash",
  "parsing_errors_count": 6,
  "quality_metrics_summary": {
    "массовая доля": {
      "precision": 0.0,
      "recall": 0.0,
      "f1": 0.0
    },
    "прочее": {
      "precision": 0.08285163776493257,
      "recall": 0.28104575163398693,
      "f1": 0.1279761904761905
    }
  }
}