{
  "model_name": "Qwen2.5-3B-Instruct",
  "timestamp": "20251224_013216",
  "reevaluated_from": "results/results_Qwen_Qwen2.5-3B-Instruct_20251204_025606.csv",
  "analysis": "Проанализируем результаты тестирования модели Qwen2.5-3B-Instruct.\n\n---\n\n### Анализ качества работы модели Qwen2.5-3B-Instruct\n\n**Общая оценка:**\nМодель демонстрирует крайне низкое качество работы по всем метрикам. Средняя точность находится в пределах 5-8%, а F1-мера не превышает 14%, что свидетельствует о практически полном отсутствии способности к извлечению запрашиваемой информации в требуемом формате. Большое количество ошибок парсинга JSON (70 из, предположительно, общего количества тестовых примеров) является критическим показателем, указывающим на фундаментальные проблемы с соблюдением формата вывода.\n\n---\n\n### 1. Характерные ошибки модели\n\n1.  **Критическое несоблюдение формата JSON:** 70 ошибок парсинга JSON указывают на то, что модель часто вообще не генерирует валидный JSON, либо генерирует его частично и с ошибками.\n2.  **Низкий Recall (Отзыв):** Модель систематически пропускает существующую информацию (много примеров из \"массовой доли\" и \"прочего\", где предсказано \"отсутствует\", а истинные значения есть). Это основной вклад в низкую F1-меру.\n3.  **Некоторые False Positives (Ложные срабатывания):** Модель предсказывает наличие информации, когда ее нет (\"масса нетто единицы: предсказано 1000.0, истина отсутствует\", \"марка: предсказано n7-p20-k30-s3, истина отсутствует\"). Это говорит о том, что модель может \"галлюцинировать\" данные.\n4.  **Генерация повторяющегося текста:** Во многих примерах ошибок JSON модель генерирует один и тот же текст многократно (Текст #44, #46, #29), что является признаком \"зацикливания\" или проблем с параметрами генерации.\n5.  **Преждевременное обрезание вывода:** В некоторых случаях (например, Текст #83) модель обрывает вывод JSON на полуслове, что может быть связано с ограничением на максимальное количество токенов.\n6.  **Плохое понимание инструкций:** Модель, по-видимому, не способна эффективно следовать сложным инструкциям по извлечению и структурированию данных в JSON.\n\n---\n\n### 2. Причины ошибок парсинга JSON\n\n1.  **Ограниченные возможности модели (Qwen2.5-3B-Instruct):** Модели с 3 миллиардами параметров являются относительно небольшими. Они часто испытывают трудности с выполнением сложных инструкций, особенно когда требуется строгий формат вывода (JSON).\n2.  **Недостаточная тренировка на задачах форматирования:** Вероятно, модель недостаточно fine-tuned на задачах, требующих строгого вывода в формате JSON, особенно для извлечения информации из неструктурированного текста.\n3.  **Проблемы с параметрами генерации:**\n    *   **`max_new_tokens`:** Если этот параметр установлен слишком низко, модель может обрезать JSON до завершения.\n    *   **`temperature` / `top_k` / `top_p`:** Неправильные значения могут приводить к более \"креативным\" и менее структурированным ответам, уводящим от требуемого формата.\n    *   **`repetition_penalty`:** Низкое значение этого параметра может способствовать зацикливанию и генерации повторяющегося текста вместо структурированного JSON.\n4.  **Сложность JSON-схемы:** Если целевая JSON-схема является сложной или многоуровневой, маленькой модели будет особенно трудно ее освоить без специфического fine-tuning.\n5.  **Нечеткие инструкции в промпте (предположительно):** Если промпт недостаточно явно указывает на необходимость строгого JSON-формата, модель может его игнорировать.\n\n---\n\n### 3. Причины ошибок в извлечении данных\n\n1.  **Ограниченное понимание контекста и предметной области:** Модель, вероятно, плохо \"понимает\" семантику текста, связанного с химическими веществами, стандартами и характеристиками продуктов. Она не может reliably идентифицировать ключевые сущности и их числовые значения в различных формулировках.\n2.  **Вариативность формулировок:** Исходный текст, скорее всего, содержит информацию о \"массовой доле\" и \"прочих\" параметрах в разнообразных и нестандартных формах. Модель плохо обобщает эти вариации.\n3.  **Отсутствие специфического fine-tuning:** Для такой специализированной задачи, как извлечение данных из текстов, описывающих удобрения или химические продукты, требуется дообучение на очень специфических данных, что, возможно, не было сделано.\n4.  **Проблемы с извлечением числовых значений и диапазонов:** Модель испытывает трудности с точным извлечением чисел, особенно когда они представлены как диапазоны (e.g., `[29.0, 31.0]`) или с дополнительными символами.\n5.  **Низкая уверенность (confidence):** Модель не имеет достаточной уверенности в найденных данных, что приводит к пропускам (низкий Recall) или к попыткам \"угадать\" (False Positives), когда информация отсутствует.\n\n---\n\n### 4. Рекомендации по улучшению промпта\n\nПоскольку промпт не предоставлен, рекомендации основаны на предположении о его существовании и типичных проблемах:\n\n1.  **Максимальная четкость и однозначность:**\n    *   Явно укажите, что модель должна возвращать **только** валидный JSON.\n    *   Подчеркните: \"НЕ включай никаких пояснений или текста вне JSON.\"\n    *   Укажите кодировку (например, UTF-8, если это требуется).\n2.  **Примеры Few-shot:** Включите 2-3 высококачественных примера (input-output), где output является *идеальным* валидным JSON, соответствующим целевой схеме. Это критически важно для малых моделей.\n3.  **Определение схемы JSON:** Четко опишите ожидаемую JSON-схему (ключи, типы значений, ожидаемые форматы для чисел, строк, массивов).\n4.  **Инструкции по обработке отсутствующей информации:**\n    *   Явно укажите, что делать, если какой-либо параметр не найден (например, устанавливать его значение в `null`, опускать ключ, или возвращать пустой массив). Это поможет уменьшить галлюцинации.\n    *   Например: \"Если вещество или параметр не найдены, соответствующий объект или ключ должен быть опущен, или его значение должно быть `null`.\"\n5.  **Используйте системные роли и форматирование:** Если API модели поддерживает системные роли, используйте `system` промпт для общих инструкций по форматированию, а `user` промпт для конкретного запроса на извлечение данных.\n6.  **Уточнение извлекаемых данных:** Перечислите все вещества и параметры, которые модель должна искать, чтобы она не \"забывала\" о них.\n\n**Пример структуры промпта (концептуально):**\n\n```\n[SYSTEM]\nТы — эксперт по извлечению информации из текста о химических продуктах и удобрениях. Твоя задача — извлечь значения \"массовой доли\" веществ и \"прочие\" параметры, строго следуя представленной JSON-схеме.\nОбязательно:\n1. Вывод должен быть ТОЛЬКО в формате JSON. Не добавляй никаких пояснений, комментариев или другого текста до или после JSON.\n2. Все числовые значения должны быть представлены как float или массив float.\n3. Если параметр или вещество не найдены в тексте, соответствующий ключ должен быть ОПУЩЕН ИЛИ его значение установлено в null. Не галлюцинируй данные.\n\n[USER]\nИзвлеки следующую информацию из текста ниже.\nJSON-схема:\n{\n  \"массовая доля\": [\n    {\"вещество\": \"N\", \"массовая доля\": [float/null, float/null]},\n    {\"вещество\": \"P2O5\", \"массовая доля\": [float/null, float/null]},\n    // ... другие вещества\n  ],\n  \"прочее\": [\n    {\"параметр\": \"стандарт\", \"значение\": \"string/null\"},\n    {\"параметр\": \"марка\", \"значение\": \"string/null\"},\n    // ... другие параметры\n  ]\n}\n\nПример 1 (Few-shot):\nТекст: \"Удобрение NPK 10:20:10. Массовая доля азота 10%, фосфора (P2O5) 20%, калия (K2O) 10%. ТУ 123-2022.\"\nОжидаемый JSON:\n```json\n{\n  \"массовая доля\": [\n    {\"вещество\": \"N\", \"массовая доля\": [10.0, 10.0]},\n    {\"вещество\": \"P2O5\", \"массовая доля\": [20.0, 20.0]},\n    {\"вещество\": \"K2O\", \"массовая доля\": [10.0, 10.0]}\n  ],\n  \"прочее\": [\n    {\"параметр\": \"стандарт\", \"значение\": \"ТУ 123-2022\"}\n  ]\n}\n```\n\nТекст для анализа:\n[ВСТАВИТЬ ТЕКСТ ДЛЯ АНАЛИЗА]\n```\n\n---\n\n### 5. Рекомендации по настройке гиперпараметров\n\nС учетом наблюдаемых ошибок:\n\n1.  **`max_new_tokens`:** **Обязательно увеличьте этот параметр.** Ошибки обрезания JSON и повторяющийся текст часто свидетельствуют о том, что модель достигает лимита токенов до завершения ответа. Установите значение, заведомо превышающее максимальный ожидаемый размер JSON.\n2.  **`temperature`:** **Снизьте `temperature`** (например, до 0.1-0.5). Более низкая температура делает генерацию более детерминированной и менее склонной к \"отклонениям\" от инструкций и форматирования.\n3.  **`repetition_penalty`:** **Увеличьте `repetition_penalty`** (например, до 1.2-1.5). Это поможет бороться с зацикливанием и генерацией повторяющегося текста, что наблюдается в примерах ошибок JSON.\n4.  **`top_k` / `top_p`:** Поэкспериментируйте с понижением этих параметров (например, `top_k=20`, `top_p=0.9`). Это может сделать вывод более сфокусированным и менее склонным к галлюцинациям, хотя может немного снизить разнообразие.\n5.  **`num_beams` (если доступно и приемлемо по производительности):** Если модель поддерживает beam search, использование `num_beams` > 1 (например, 2-5) может помочь найти более оптимальную последовательность токенов, что может улучшить соблюдение JSON-формата, но увеличит время генерации.\n\n---\n\n### 6. Общие рекомендации по улучшению качества\n\nУчитывая текущую производительность, требуются значительные шаги:\n\n1.  **Fine-tuning (Дообучение) на целевом датасете:**\n    *   **Создайте высококачественный датасет:** Соберите большой и разнообразный набор текстов, аналогичных тем, что используются в тесте, и вручную разметьте их, создав *идеально валидные* JSON-ответы.\n    *   **Разнообразие данных:** Включите примеры со всеми возможными вариациями написания, синтаксиса, пропусками данных и т.д.\n    *   **Отрицательные примеры:** Включите примеры, где некоторые параметры отсутствуют, и убедитесь, что JSON это отражает (например, пропуская ключ или указывая `null`).\n    *   **Объем данных:** Для эффективного дообучения Qwen2.5-3B потребуются сотни, а лучше тысячи хорошо размеченных примеров.\n2.  **Использование более крупной и мощной модели:**\n    *   Qwen2.5-3B является относительно небольшой моделью. Рассмотрите возможность использования более крупных моделей из той же серии (например, Qwen2-7B-Instruct, Qwen2-14B-Instruct) или других state-of-the-art открытых моделей. Большие модели значительно лучше справляются с instruction following, форматированием и сложными задачами извлечения.\n3.  **Разделение задачи (если возможно):**\n    *   Если тексты очень длинные и содержат много информации, можно попробовать сначала выделить релевантные фрагменты текста, а затем подавать их в модель для извлечения конкретных данных.\n4.  **Пост-обработка вывода:**\n    *   Внедрите надежный механизм пост-обработки для проверки валидности JSON. Если JSON невалиден, можно попробовать восстановить его (например, с помощью библиотеки `json_repair`), логировать ошибку или даже запросить у модели повторную генерацию.\n    *   Проверяйте извлеченные значения на разумность (например, массовая доля не может быть отрицательной или больше 100%).\n5.  **Итеративный подход:**\n    *   Продолжайте собирать ошибки, анализировать их и использовать для улучшения промпта, дообучающих данных или архитектуры решения.\n\n---\n\n**Вывод:**\nТекущая производительность модели Qwen2.5-3B-Instruct для данной задачи является неприемлемой. Наиболее критичными проблемами являются полное отсутствие соблюдения JSON-формата и крайне низкий отзыв. Для достижения приемлемого качества необходимы серьезные изменения, включая тщательное fine-tuning на специфическом датасете, агрессивную настройку гиперпараметров генерации и, возможно, переход на более крупную и мощную модель.",
  "model_used": "gemini-2.5-flash",
  "parsing_errors_count": 70,
  "quality_metrics_summary": {
    "массовая доля": {
      "accuracy": 0.07797619047619048,
      "precision": 0.2987012987012987,
      "recall": 0.0888030888030888,
      "f1": 0.13690476190476192
    },
    "прочее": {
      "accuracy": 0.05179443572300715,
      "precision": 0.18691588785046728,
      "recall": 0.09803921568627451,
      "f1": 0.12861736334405144
    }
  }
}