{
  "model_name": "gemma-3-27b-it",
  "timestamp": "20260125_145840",
  "analysis": "Как эксперт по оценке качества работы языковых моделей, я провел анализ предоставленных результатов тестирования модели `gemma-3-27b-it` с учетом заданного промпта, гиперпараметров и метрик качества.\n\n---\n\n### Анализ результатов тестирования `gemma-3-27b-it`\n\n**Общая оценка:**\nМодель демонстрирует умеренные результаты для извлечения \"массовой доли\", но значительно хуже справляется с категорией \"прочее\". Критический недостаток заключается в крайне плохом соблюдении заданного формата JSON, что видно на примере ошибки.\n\n**Метрики качества:**\n*   **\"Массовая доля\":**\n    *   `Accuracy: 86.31%`, `Precision: 89.18%`, `Recall: 79.40%`, `F1: 84.01%`\n    *   **Оценка:** Это довольно хорошие показатели, особенно для такой сложной задачи. Высокая Precision (89.18%) говорит о том, что то, что модель извлекает в этой категории, чаще всего корректно. Однако Recall (79.40%) ниже, что указывает на то, что модель **пропускает часть релевантных сущностей** из этой категории.\n*   **\"Прочее\":**\n    *   `Accuracy: 55.48%`, `Precision: 70.26%`, `Recall: 64.62%`, `F1: 67.32%`\n    *   **Оценка:** Значительно хуже, чем для \"массовой доли\". F1-мера в 67% является неудовлетворительной для задачи структурированного извлечения. Это говорит о серьезных проблемах как с точностью (модель извлекает неверные сущности или неправильно), так и с полнотой (много пропускает) для этого разнообразного типа данных.\n\n**Пример ошибки с исходным текстом:**\n\n*   **Исходный текст:** Очень длинный и насыщенный информацией текст с множеством массовых долей и других параметров (масса брутто, объем, масса нетто).\n*   **Ответ модели:** `{\"вещество\": \"Mg\", \"массовая доля`\n*   **Критическая ошибка:**\n    1.  **Неполный и невалидный JSON:** Модель выдала лишь фрагмент JSON, который не является завершенным и синтаксически верным. Это полностью блокирует автоматическое использование результата.\n    2.  **Нарушение структуры JSON:** Даже если бы фрагмент был завершен, он не соответствует требуемой структуре для \"массовой доли\". Согласно промпту, `массовая доля` должна быть массивом объектов, а не прямым ключом, следующим за `\"вещество\"`. Модель пыталась создать `{\"вещество\": \"Mg\", \"массовая доля\": ...}` вместо ожидаемого `{\"массовая доля\": [{\"вещество\": \"Mg\", \"массовая доля\": ...}]}`.\n    3.  **Неспособность обработать объемный текст:** Модель не смогла извлечь *все* многочисленные сущности из такого длинного и сложного текста, остановившись на одном из первых обнаруженных элементов.\n\n---\n\n### 1. Характерные ошибки модели\n\n1.  **Катастрофическое нарушение формата JSON:** Самая серьезная проблема. Модель неспособна стабильно генерировать полный и синтаксически правильный JSON, соответствующий заданной схеме.\n2.  **Несоблюдение структуры JSON:** Помимо незавершенности, модель неверно интерпретирует вложенность и типы данных (например, ожидает массив объектов для \"массовой доли\", а пытается создать прямой ключ-значение).\n3.  **Проблемы с обработкой длинных и сложных текстов:** На примере ошибки видно, что модель \"сдается\" или путается при анализе очень объемного текста с множеством похожих сущностей, не доходя до полного извлечения.\n4.  **Низкая полнота извлечения для категории \"Прочее\":** F1-мера 67% говорит о том, что модель часто пропускает или неверно определяет сущности, не относящиеся к массовым долям. Эта категория является более разнообразной и, возможно, требует больше конкретики или примеров.\n5.  **Потенциальное \"забывание\" инструкций:** Длинный и детализированный промпт может приводить к тому, что модель не удерживает в памяти все нюансы или приоритеты инструкций, особенно те, что находятся в середине или конце промпта.\n\n---\n\n### 2. Причины ошибок парсинга JSON\n\n1.  **Длина промпта и его сложность:** Промпт очень длинный (3768 символов) и содержит много деталей. Модель может испытывать \"эффект длинного контекста\", когда последние или самые тонкие инструкции теряются, особенно те, что касаются точного формата вывода.\n2.  **Сложность требуемой JSON-схемы:** Схема не является плоской; она включает вложенные массивы объектов (например, `\"массовая доля\": [...]` с объектами внутри). Это сложнее для генерации, чем простой JSON `{ \"key\": \"value\" }`.\n3.  **Отсутствие Few-Shot примеров:** Промпт предоставляет *один* пример JSON-схемы, но не предоставляет *конкретный пример* входного текста и соответствующего ему JSON-вывода. Few-shot примеры значительно улучшают способность модели к форматированному выводу.\n4.  **Ограничение `max_new_tokens`:** Хотя в данном примере ошибки вывод был очень коротким, для полного извлечения из такого длинного текста мог потребоваться очень большой JSON. `max_new_tokens: 512` может быть недостаточным, что приводило бы к обрыву JSON на половине.\n5.  **Внутренние ограничения модели:** Некоторые модели, несмотря на свой размер, могут быть менее стабильны в генерации сложного, строгого JSON по сравнению с другими, особенно без использования специальных режимов JSON (если таковые доступны в API).\n\n---\n\n### 3. Причины ошибок в извлечении данных\n\n1.  **Перегрузка информацией:** Как упоминалось, очень длинный и плотный входной текст может перегружать модель, заставляя ее пропускать сущности или давать сбой в середине обработки.\n2.  **Разнообразие категории \"Прочее\":** Эта категория охватывает широкий спектр численных и количественных характеристик (масса, объем, стандарты, марки, количество). Каждая из них может иметь свою специфику в тексте, что усложняет универсальное извлечение.\n3.  **Нюансы формулировок:** Даже для \"массовой доли\" могли быть пропущены значения из-за необычных формулировок, сокращений или контекста, которые модель не смогла ассоциировать с требуемым признаком.\n4.  **Недостаточная \"инструктивность\" для \"Прочее\":** Хотя промпт дает примеры, возможно, для \"прочего\" нужно больше конкретных примеров, как обрабатывать \"МЕШКИ ПО 50 КГ\" (масса нетто) или \"ПО 1000 КГ+5%\" (масса брутто).\n\n---\n\n### 4. Рекомендации по улучшению промпта\n\n1.  **Внедрение Few-Shot примеров:** Это **самая важная** рекомендация. Добавьте в промпт 2-3 **конкретных примера** входного текста (коротких, но репрезентативных) и соответствующих им **идеальных JSON-выводов**. Это научит модель желаемому поведению гораздо эффективнее, чем абстрактные правила. Например:\n    ```\n    Пример 1:\n    Текст: В упаковке 500 МЛ. АЗОТ 7%, ФОСФОР 3%.\n    ОТВЕТ:\n    ```json\n    {\n      \"массовая доля\": [\n        {\"вещество\": \"N\", \"массовая доля\": 7},\n        {\"вещество\": \"P2O5\", \"массовая доля\": 3}\n      ],\n      \"прочее\": [\n        {\"параметр\": \"объем нетто единицы\", \"объем\": 500, \"единица\": \"мл\"}\n      ]\n    }\n    ```\n    ```\n    Пример 2:\n    Текст: Селитра ГОСТ 32323-2015. Мешок 25 кг.\n    ОТВЕТ:\n    ```json\n    {\n      \"массовая доля\": [],\n      \"прочее\": [\n        {\"параметр\": \"стандарт\", \"значение\": \"ГОСТ 32323-2015\"},\n        {\"параметр\": \"масса нетто единицы\", \"масса\": 25, \"единица\": \"кг\"}\n      ]\n    }\n    ```\n\n2.  **Упрощение и структурирование промпта:**\n    *   Разбейте промпт на более короткие, четко обозначенные разделы.\n    *   Используйте списки и жирный шрифт для выделения ключевых требований.\n    *   Удалите избыточные или повторяющиеся формулировки.\n    *   Переместите наиболее важные инструкции (например, о JSON-формате) ближе к началу промпта, а менее критичные детали — ближе к концу.\n\n3.  **Акцент на JSON-структуру:**\n    *   Прямо перед примером JSON добавьте фразу типа: \"**Строго соблюдай следующую JSON-структуру. Это критически важно!**\"\n    *   Убедитесь, что текстовые описания признаков и их соответствие JSON-схеме абсолютно однозначны (например, чтобы модель не путала `массовая доля N` как название признака с ключом `массовая доля` внутри объекта).\n\n4.  **Улучшение формулировок для \"Прочее\":**\n    *   Для сложных правил типа \"масса нетто\" vs \"масса брутто\" можно добавить микро-примеры прямо в тексте промпта (если позволяют символы).\n    *   Рассмотреть возможность сокращения общего количества правил, если некоторые из них редко встречаются или незначительны.\n\n5.  **Удаление избыточности:** Правило \"Если один и тот же параметр встречается дважды...\" важно, но его можно сформулировать более кратко.\n\n---\n\n### 5. Рекомендации по настройке гиперпараметров\n\n1.  **Увеличение `max_new_tokens`:** `512` токенов практически гарантированно недостаточно для генерации полного JSON из длинного и сложного текста, подобного примеру. Увеличьте этот параметр до `1024`, `2048` или даже больше, в зависимости от максимально ожидаемой длины JSON. Для `gemma-3-27b-it` контекстное окно достаточно велико, чтобы поддерживать больший вывод.\n2.  **Понижение `temperature`:** Для задач структурированного извлечения данных, где важна точность и детерминированность, а не креативность, рекомендуется использовать низкое значение `temperature` (например, `0.1` - `0.3`). Это делает модель менее \"рисковой\" в выборе токенов и более склонной к следованию инструкциям.\n3.  **Настройка `top_p` / `top_k`:** Если `temperature` уже низкое, эти параметры имеют меньшее влияние, но для максимальной детерминированности можно установить `top_p` на низкое значение (например, `0.9` или ниже) и `top_k` на `0`.\n4.  **Использование `response_format` (если API поддерживает):** Если API, через которое вы обращаетесь к `gemma-3-27b-it`, поддерживает параметр `response_format=\"json\"` (как, например, в OpenAI API), **обязательно используйте его**. Это принуждает модель генерировать только валидный JSON и значительно сокращает количество ошибок парсинга.\n\n---\n\n### 6. Общие рекомендации по улучшению качества\n\n1.  **Пост-обработка JSON:** Внедрите в свой код надежную пост-обработку для валидации полученного JSON. Если JSON невалиден, попытайтесь его исправить (например, добавить недостающие скобки, если это простая ошибка обрыва) или залогируйте как ошибку. Это не улучшит качество модели, но сделает систему более отказоустойчивой.\n2.  **Итеративное тестирование и анализ ошибок:** Продолжайте собирать примеры ошибок и анализировать их, чтобы выявлять новые шаблоны проблем и соответствующим образом дорабатывать промпт или стратегию.\n3.  **Разделение сложных задач (если применимо):** Если модель продолжает \"захлебываться\" на очень длинных текстах, можно рассмотреть стратегию разделения текста на более мелкие фрагменты, обработку каждого отдельно, а затем агрегацию результатов. Однако для извлечения сущностей, которые могут охватывать границы фрагментов, это может быть неэффективно.\n4.  **Механизм \"повторной попытки\" (Retry Mechanism):** Если модель выдает невалидный JSON, можно настроить механизм, который повторит запрос, возможно, с немного измененным промптом (например, явно запросив \"только JSON, без лишних слов, иначе получишь штраф\").\n5.  **Обучение на конкретных данных (Fine-tuning):** В долгосрочной перспективе, если проблема сохраняется, а качество должно быть очень высоким, сбор большого и разнообразного набора данных и дообучение модели на нем даст наилучшие результаты для специфической задачи.\n\n---\n\nПриоритет следует отдать **внедрению Few-Shot примеров** и **корректировке гиперпараметров** (`max_new_tokens`, `temperature`). Это должно оказать наиболее значимое и быстрое влияние на улучшение как качества извлечения, так и, что критично, на соблюдение JSON-формата.",
  "model_used": "gemini-2.5-flash",
  "parsing_errors_count": 1,
  "hyperparameters": {
    "max_new_tokens": 512,
    "model_name": "gemma-3-27b-it",
    "api_model": true
  },
  "system_info": {
    "api_model": true,
    "multi_agent_mode": null,
    "gpu_info": {
      "api": true
    },
    "gpu_memory_during_inference_gb": 0.0,
    "average_response_time_seconds": 10.114898509979248
  },
  "quality_metrics_summary": {
    "массовая доля": {
      "accuracy": 0.8630763416477701,
      "precision": 0.8917910447761194,
      "recall": 0.7940199335548173,
      "f1": 0.8400702987697714
    },
    "прочее": {
      "accuracy": 0.5548150923150923,
      "precision": 0.7025641025641025,
      "recall": 0.6462264150943396,
      "f1": 0.6732186732186732
    }
  }
}