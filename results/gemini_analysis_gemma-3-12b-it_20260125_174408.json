{
  "model_name": "gemma-3-12b-it",
  "timestamp": "20260125_174408",
  "analysis": "Как эксперт по оценке качества работы языковых моделей, я проанализировал представленные результаты тестирования модели `gemma-3-12b-it` с учетом заданного промпта, гиперпараметров и метрик качества.\n\nМодель демонстрирует среднюю производительность в извлечении массовых долей и низкую производительность в извлечении прочих численных характеристик. Это говорит о значительных возможностях для улучшения.\n\n---\n\n### Анализ результатов тестирования `gemma-3-12b-it`\n\n#### 1. Характерные ошибки модели\n\n*   **Низкий Recall для категории \"Прочее\" (39.81%)**: Модель пропускает более 60% всех релевантных сущностей из категории \"прочее\". Это указывает на трудности в распознавании разнообразных паттернов для этой категории (количества, объемы, специфические массы, другие идентификаторы, помимо стандарта и марки).\n*   **Низкий F1-score для обеих категорий (66.79% для \"Массовая доля\", 44.09% для \"Прочее\")**: Общая сбалансированная оценка качества показывает, что модель далека от желаемой производительности.\n*   **Проблемы с обработкой диапазонов и операторов**:\n    *   **Пример 1 (не более/не менее)**: Текст \"АММОНИЙНОГО АЗОТА НЕ БОЛЕЕ 0,5%, КАЛЬЦИЯ НЕ МЕНЕЕ 32%\". Модель, вероятно, не всегда корректно преобразует эти операторы в формат `[null, max]` или `[min, null]` или может полностью игнорировать оператор, извлекая только число.\n    *   **Пример 3 (+/-)**: Текст \"Р2О5 - 52+/-1%, К2О - 34+/-1%\". Модель, возможно, не преобразует `X+/-Y` в `[X-Y, X+Y]`.\n*   **Сложности с применением правил к группам (Пример 2)**: Фраза \"МАССОВАЯ ДОЛЯ, НЕ МЕНЕЕ: ОБЩЕГО АЗОТА - 16%; ОБЩИХ ФОСФАТОВ - 16%; КАЛИЯ В ПЕРЕСЧЁТЕ НА К2О - 16%.\" указывает на то, что оператор \"не менее\" относится ко всем последующим значениям. Модель может не распространять оператор на весь список.\n*   **Неточное именование или пропуск специфичных \"прочих\" параметров**:\n    *   В Примере 1: \"ВЕС РЕКВИЗИТА КРЕПЛЕНИЯ 1584 КГ\". Модель могла пропустить этот параметр или некорректно его назвать.\n    *   В Примере 3: \"РАСФАСОВАНО В МЕШКАХ ПО 25 КГ\", \"40 МЕШКОВ НА 1 ПОДДОН\", \"480 МЕШКОВ НА 12 ПОДДОНАХ\". Здесь много детальной информации о количестве и весе, которую модель должна была извлечь, но, судя по низкому Recall, она этого не делает.\n*   **Неполное или некорректное преобразование химических названий**: Несмотря на правило \"Если в названии признака есть название химического элемента (например Кальций) - замени его на обозначение химического элемента - Ca.\", а также пример \"МАССОВАЯ ДОЛЯ K В ПЕРЕСЧЕТЕ НА К2О\" -> \"массовая доля K2O\", модель могла не справиться с \"ОБЩЕГО АЗОТА\" -> \"N\", \"ОБЩИХ ФОСФАТОВ\" -> \"P2O5\", \"КАЛЬЦИЯ\" -> \"Ca\".\n*   **Пропуск контекста или неспособность связать данные**: Модель может не всегда связывать числовые значения с их единицами измерения или параметрами, если они не находятся в непосредственной близости.\n\n#### 2. Причины ошибок парсинга JSON\n\nХотя прямого показателя ошибок парсинга JSON нет, низкий F1-score может быть связан с тем, что невалидный JSON мог быть отброшен на этапе оценки. Возможные причины:\n*   **Несоблюдение строгой структуры**: Модель может добавлять лишние поля, изменять порядок ключей, использовать неверные типы данных (например, число как строку, объект вместо массива).\n*   **Отсутствие или некорректное форматирование пустых списков**: Если данных нет, модель должна выводить пустой массив `[]` (например, `{\"массовая доля\": []}`). Модель может либо опускать этот ключ, либо выводить пустой объект `{}`, что может быть расценено как ошибка.\n*   **Лишний текст до или после JSON**: Промпт явно требует вывода JSON \"только после слова ОТВЕТ:\". Модель может игнорировать это требование, добавляя вводные фразы или объяснения, что делает вывод невалидным JSON для автоматического парсера.\n\n#### 3. Причины ошибок в извлечении данных\n\n*   **Сложность промпта для модели данного размера**: Gemma-3-12b-it, хотя и достаточно большая, может испытывать трудности с одновременным запоминанием и применением всех 15+ детализированных правил и примеров, особенно когда они касаются сложных трансформаций и различных форматов вывода.\n*   **Ограниченная способность к обобщению**: Модель может быть неспособна обобщать правила на новые, слегка отличающиеся паттерны в тексте. Например, \"МАССОВАЯ ДОЛЯ K В ПЕРЕСЧЕТЕ НА К2О\" -> \"K2O\" легко, но \"ОБЩИХ ФОСФАТОВ\" -> \"P2O5\" может быть сложнее, если прямо не указано.\n*   **\"Attention span\" и смещение контекста**: При большом промпте и длинном входном тексте модель может \"терять\" фокус на некоторых деталях или частях промпта.\n*   **Низкая \"robustness\" к вариациям фраз**: Незначительные изменения в формулировках (например, \"вес реквизита крепления\" вместо \"масса реквизита\") могут сбивать модель.\n*   **Недостаток специализированных знаний**: Хотя модель общего назначения, извлечение химических/промышленных данных требует специфического понимания терминологии и контекста, что не всегда легко достигается через промпт.\n\n#### 4. Рекомендации по улучшению промпта\n\nПромпт уже очень подробный, что является хорошей базой. Для улучшения:\n\n*   **Уточнить правила для химических преобразований**:\n    *   **Для фосфатов**: Явно добавить правило: \"Если указано 'общие фосфаты' или 'фосфор', извлекай 'P2O5'.\"\n    *   **Полный список элементов**: Вместо общего правила, можно дать явный список преобразований для всех ожидаемых химических элементов и их оксидов: \"Всегда заменяй полные названия химических элементов и их производных на их стандартные обозначения: 'Азот' -> 'N', 'Фосфор' -> 'P' (но в пересчете на оксид 'P2O5'), 'Калий' -> 'K' (но в пересчете на оксид 'K2O'), 'Кальций' -> 'Ca', 'Сера' -> 'S', 'Магний' -> 'Mg', 'Цинк' -> 'Zn', и их оксиды: 'P2O5', 'K2O', 'CaO', 'MgO', 'SO3'.\"\n*   **Пример JSON для \"не менее/не более\"**: В разделе \"Особые указания\" добавить явный пример, как обрабатывать \"не менее\" и \"не более\" в структуре `{\"массовая доля\": [min, null]}` или `[null, max]`, чтобы укрепить этот шаблон.\n*   **Больше примеров для \"прочее\"**: В разделе \"Пример ответа\" добавить больше вариаций для \"прочих\" параметров, особенно тех, что модель пропускает (например, \"вес реквизита крепления\", если он должен быть извлечен).\n*   **Уточнить именование параметров для \"прочее\"**: В пункте 2 \"Название признака\" расширить список примеров, включив все ожидаемые уникальные названия параметров (например, \"масса реквизита крепления\", \"количество мешков на поддоне\", \"масса нетто единицы\").\n*   **Подчеркнуть важность `[]` для отсутствующих данных**: Явно указать, что если в категории `массовая доля` или `прочее` нет соответствующих данных, соответствующий *массив должен быть пустым*. Например, \"Если в тексте нет признаков 'массовая доля', выведи `\\\"массовая доля\\\": []`. Если нет признаков 'прочее', выведи `\\\"прочее\\\": []`.\"\n*   **Усилить требование к строгости JSON**: В конце промпта, перед \"ОТВЕТ:\", можно добавить фразу: \"Твой ответ должен быть *строго* валидным JSON, без любых посторонних символов, комментариев или текста, кроме самого JSON и обязательного слова ОТВЕТ:.\"\n\n#### 5. Рекомендации по настройке гиперпараметров\n\n*   **`max_new_tokens` (512)**: Для данного типа задач, с потенциально длинными списками извлеченных сущностей в JSON, 512 токенов может быть лимитирующим фактором в более сложных случаях. Если наблюдаются обрезанные JSON-ответы, рекомендуется увеличить это значение (например, до 1024 или 2048), чтобы убедиться, что модель имеет достаточно пространства для полного вывода. В текущем \"Тексте для анализа\" это не является проблемой, но в более сложных текстах может проявиться.\n\n#### 6. Общие рекомендации по улучшению качества\n\n*   **Файн-тюнинг (Fine-tuning)**: Это наиболее эффективный метод для значительного улучшения качества в такой специализированной задаче. Подготовьте большой и разнообразный датасет, включающий множество примеров текстов с правильными JSON-выводами, охватывающими все типы ошибок и краевые случаи:\n    *   Примеры с разными формулировками диапазонов (\"от X до Y\", \"X-Y\", \"X+/-Y\", \"не более X\", \"не менее Y\").\n    *   Примеры с различными типами \"прочих\" параметров и их единицами измерения.\n    *   Тексты с явными и неявными химическими обозначениями.\n    *   Тексты, где некоторые категории пусты.\n    *   Тексты с разной длиной и сложностью.\n*   **Пост-обработка (Post-processing)**: Разработайте скрипты для автоматической проверки и коррекции вывода модели:\n    *   **Валидация JSON**: Проверка на синтаксическую корректность.\n    *   **Валидация схемы**: Проверка на соответствие ожидаемой структуре JSON (наличие всех ключей, правильные типы данных).\n    *   **Нормализация данных**: Автоматическое исправление небольших расхождений в именовании параметров (например, если модель вывела \"вес нетто\" вместо \"масса нетто\"), преобразование числовых значений (например, если она забыла рассчитать диапазон из \"+/-\").\n    *   **Проверка логики**: Например, убедиться, что `min` в диапазоне не превышает `max`.\n*   **Iterative Prompt Engineering**: Продолжайте уточнять промпт, особенно фокусируясь на тех паттернах, где модель все еще ошибается. Попробуйте разные подходы:\n    *   **Chain-of-Thought (CoT)**: Можно попробовать добавить в промпт шаг, где модель сначала \"рассуждает\", как она будет извлекать информацию, а затем выводит JSON. Например: \"Сначала определи все массовые доли и их значения. Затем определи все прочие параметры. Затем сформируй JSON.\" (Это может увеличить количество токенов и время генерации, но иногда улучшает точность).\n    *   **Few-shot Learning**: Добавление нескольких примеров (пример текста + правильный JSON) в сам промпт, перед реальной задачей, может значительно улучшить качество модели, особенно если примеры хорошо подобраны и покрывают частые паттерны ошибок.\n\nПринятие этих рекомендаций, особенно в сочетании с файн-тюнингом и надежной пост-обработкой, должно существенно улучшить качество извлечения данных из текстов о химических веществах и удобрениях.",
  "model_used": "gemini-2.5-flash",
  "parsing_errors_count": 9,
  "hyperparameters": {
    "max_new_tokens": 512,
    "model_name": "gemma-3-12b-it",
    "api_model": true
  },
  "system_info": {
    "api_model": true,
    "multi_agent_mode": null,
    "gpu_info": {
      "api": true
    },
    "gpu_memory_during_inference_gb": 0.0,
    "average_response_time_seconds": 68.58940783500671
  },
  "quality_metrics_summary": {
    "массовая доля": {
      "accuracy": 0.59234922274695,
      "precision": 0.7011494252873564,
      "recall": 0.6376306620209059,
      "f1": 0.6678832116788321
    },
    "прочее": {
      "accuracy": 0.3510406260406261,
      "precision": 0.49411764705882355,
      "recall": 0.3981042654028436,
      "f1": 0.4409448818897638
    }
  }
}