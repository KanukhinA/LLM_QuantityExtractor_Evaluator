{
  "model_name": "gemma-3-4b-it",
  "timestamp": "20260124_151839",
  "analysis": "Привет! Как эксперт по оценке качества работы языковых моделей, я проанализировал предоставленные результаты тестирования `gemma-3-4b-it` на задаче извлечения численных характеристик из текстов о химических веществах.\n\n**Общая оценка:**\nМодель `gemma-3-4b-it` демонстрирует существенные проблемы с генерацией валидного JSON, что является критическим недостатком для данной задачи. Метрики качества по извлечению данных (особенно для категории \"Прочее\") довольно низкие, но их интерпретация затруднена из-за проблем с форматом вывода.\n\n---\n\n### 1. Характерные ошибки модели\n\nОсновная и наиболее критическая ошибка модели – это **неспособность последовательно генерировать валидный JSON-формат**. Примеры ошибок наглядно показывают:\n\n*   **Неполный или синтаксически некорректный JSON:** Модель обрезает или пропускает открывающие/закрывающие скобки и ключи верхнего уровня (`\"массовая доля\"`, `\"прочее\"`), делая JSON невалидным и непарсируемым (Пример 1).\n*   **Пустой или отсутствующий вывод:** В некоторых случаях модель вообще не генерирует никакого осмысленного ответа после инструкции (Примеры 2 и 3), что является полным провалом выполнения задачи.\n*   **Низкая точность извлечения \"Прочее\":** Даже если бы JSON был валидным, низкий F1-показатель (34.9%) для категории \"Прочее\" указывает на значительные проблемы с распознаванием и корректной структуризацией таких параметров, как стандарты, различные типы масс и их единицы.\n*   **Проблемы с соблюдением инструкции `ОТВЕТ:`:** Судя по представленным ошибкам, модель игнорирует или неверно обрабатывает инструкцию \"Выводи json результат **только после слова ОТВЕТ:**\".\n\n### 2. Причины ошибок парсинга JSON\n\n1.  **Размер и архитектура модели:** `gemma-3-4b-it` — относительно небольшая модель. Маленькие модели часто испытывают трудности с генерацией сложных, вложенных структур JSON с высокой степенью детерминизма, особенно при наличии нескольких примеров с разной степенью заполненности (пустые списки, списки с одним элементом, списки с несколькими элементами).\n2.  **Сложность и объем промпта:** Промпт очень длинный (4116 символов) и содержит много примеров. Хотя примеры полезны, для небольшой модели это может быть перегрузкой. Модель может \"забывать\" или не уделять достаточно внимания инструкциям по форматированию в начале или конце промпта, сосредотачиваясь на извлечении данных.\n3.  **Недостаточная \"интернализация\" JSON-схемы:** Модель, по-видимому, не смогла достаточно хорошо усвоить *общую структуру* JSON-схемы, что приводит к пропускам обязательных верхнеуровневых ключей (`\"массовая доля\"`, `\"прочее\"`) или другим синтаксическим ошибкам. Модель генерирует части JSON, но не может собрать их в целостную и валидную структуру.\n4.  **Отсутствие жесткого контроля генерации:** Без явного указания таких гиперпараметров как `temperature` или `top_p`, модель может быть слишком \"креативной\", что приводит к отклонениям от заданной структуры.\n\n### 3. Причины ошибок в извлечении данных\n\n1.  **Сложность расчетов и логики:** Примеры вроде `1000 КГ+5%` или `25КГ+-5%` требуют от модели выполнения арифметических операций и логической интерпретации (например, что `+5%` означает увеличение, а `+-5%` обычно берется как верхняя граница для \"масса брутто единицы\" в примерах, но может быть и нижняя граница). Малые LLM плохо справляются с математикой без явных инструментов или специализированной дообученной способности.\n2.  **Разнообразие категории \"Прочее\":** Эта категория очень широка и включает в себя стандарты (ТУ, ГОСТ), марки, идентификаторы, различные типы веса (нетто, брутто, брутто единицы). Модели сложнее обобщить и выделить корректные сущности из такого разнообразия паттернов по сравнению с более унифицированными паттернами \"массовой доли\".\n3.  **Интерпретация диапазонов:** Конструкции типа \"не более 0,5%\" или \"не менее 32%\" должны быть преобразованы в формат `[null, 0.5]` или `[32, null]`. Это требует специфической интерпретации текста и является нетривиальной задачей для модели без достаточного обучения на таких паттернах.\n\n### 4. Рекомендации по улучшению промпта\n\n1.  **Усилить акцент на валидности JSON и его структуре:**\n    *   **Явно указать обязательные верхнеуровневые ключи:** \"JSON ВСЕГДА ДОЛЖЕН содержать два ключа верхнего уровня: `\"массовая доля\"` и `\"прочее\"`, даже если их значения являются пустыми списками.\"\n    *   **Предоставить шаблон пустого JSON:** В начале промпта, после общих инструкций, добавьте: \"Твой ответ ДОЛЖЕН строго соответствовать следующему шаблону JSON (даже если списки пусты):\" и затем полный шаблон `{\"массовая доля\": [], \"прочее\": []}`.\n    *   **Перенести инструкцию `ОТВЕТ:`:** Убедитесь, что в тестовом промпте *перед* модельным выводом стоит `ОТВЕТ:`, как указано в п.3 промпта. Модель должна отвечать *после* этой фразы.\n2.  **Упростить примеры или явно описать сложную логику:**\n    *   **Для расчетов:** Либо исключите примеры с расчетами (`+5%`) на начальном этапе, если модель с ними не справляется, либо **явно укажите** необходимость выполнения расчетов: \"Если указано 'X КГ + Y%', рассчитай итоговую массу.\"\n    *   **Для диапазонов:** Явно пропишите правила: \"Если в тексте указано 'не более X%', используй `[null, X]` для значения. Если 'не менее Y%', используй `[Y, null]`.\"\n3.  **Сократить длину промпта (если возможно):** Если есть возможность немного сократить описательную часть промпта, это может помочь маленькой модели сосредоточиться на основной задаче и форматировании. Однако примеры, вероятно, являются самой важной частью.\n\n### 5. Рекомендации по настройке гиперпараметров\n\n*   **Температура (temperature):** Самая важная настройка. Для генерации структурированных данных, таких как JSON, рекомендуется установить очень низкое значение `temperature` (например, **0.1-0.3**). Это сделает ответы модели более детерминированными и менее склонными к \"галлюцинациям\" или отклонениям от заданной структуры.\n*   **Top-P / Top-K:** Также могут быть настроены на более низкие значения, чтобы уменьшить разнообразие генерируемых токенов и сфокусировать модель на наиболее вероятных (и, предположительно, корректных) токенах для JSON-структуры.\n*   `max_new_tokens`: 512, вероятно, достаточно для вывода JSON, если он не становится чрезмерно большим. Пока оставляем без изменений.\n\n### 6. Общие рекомендации по улучшению качества\n\n1.  **Пост-обработка и валидация JSON:** Вне зависимости от модели, всегда необходимо иметь слой пост-обработки, который:\n    *   Пытается исправить типовые ошибки в JSON (например, добавить отсутствующие скобки, если структура почти полная).\n    *   Валидирует полученный JSON на соответствие ожидаемой схеме.\n    *   При невалидном JSON может либо возвращать ошибку, либо пытаться извлечь данные альтернативными, более простыми методами (например, с помощью регулярных выражений для стандартов).\n2.  **Постепенное усложнение:** Если модель сильно проваливается на текущем уровне сложности, попробуйте сначала обучить ее на более простой задаче:\n    *   Сначала только на извлечении \"массовой доли\" без расчетов и диапазонов.\n    *   Затем добавить \"прочее\" без расчетов.\n    *   Потом постепенно ввести расчеты и диапазоны.\n3.  **Файн-тюнинг (Fine-tuning):** Для специализированных задач с жесткими требованиями к структуре вывода, таких как эта, **файн-тюнинг модели на большом объеме данных \"текст -> JSON\" в вашей специфической доменной области даст наибольший прирост качества и надежности**. Это позволит модели намного лучше интернализировать как формат вывода, так и специфические паттерны извлечения данных.\n4.  **Разделение задачи:** Для очень сложных случаев, где модель должна выполнить расчет и затем форматировать, можно рассмотреть разделение задачи:\n    *   **Шаг 1:** Модель извлекает *сырые* данные (например, \"масса: 1000 кг, с допуском +5%\").\n    *   **Шаг 2:** Отдельный скрипт или еще одна, более простая модель, преобразует эти сырые данные в финальный структурированный JSON, выполняя необходимые расчеты.\n5.  **Использование более крупной модели:** Если файн-тюнинг невозможен, а промпт-инжиниринг с `gemma-3-4b-it` не дает удовлетворительных результатов, рассмотрите использование более крупной модели (например, `gemma-7b-it` или другие модели с большим количеством параметров). Более крупные модели, как правило, лучше справляются со сложными инструкциями, следованием формату и многошаговыми рассуждениями.\n\nНадеюсь, эти рекомендации помогут вам значительно улучшить качество работы модели!",
  "model_used": "gemini-2.5-flash",
  "parsing_errors_count": 3,
  "hyperparameters": {
    "max_new_tokens": 512,
    "model_name": "gemma-3-4b-it",
    "api_model": true
  },
  "system_info": {
    "api_model": true,
    "multi_agent_mode": null,
    "gpu_info": {
      "api": true
    },
    "gpu_memory_during_inference_gb": 0.0,
    "average_response_time_seconds": 14.298121612071991
  },
  "quality_metrics_summary": {
    "массовая доля": {
      "accuracy": 0.3932900432900433,
      "precision": 0.4489795918367347,
      "recall": 0.6010928961748634,
      "f1": 0.5140186915887851
    },
    "прочее": {
      "accuracy": 0.2953806650865475,
      "precision": 0.3785310734463277,
      "recall": 0.32367149758454106,
      "f1": 0.3489583333333333
    }
  }
}