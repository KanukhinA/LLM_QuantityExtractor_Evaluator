{
  "model_name": "google/gemma-2-2b-it",
  "timestamp": "20260124_155321",
  "analysis": "### Анализ результатов тестирования модели `google/gemma-2-2b-it`\n\n**Общая оценка:**\nМодель `google/gemma-2-2b-it` демонстрирует крайне низкие показатели качества извлечения данных для данной задачи. F1-метрики 47.00% для \"массовой доли\" и 31.91% для \"прочего\" указывают на существенные проблемы как в точности (Precision), так и в полноте (Recall) извлечения информации. Единственным положительным моментом является отсутствие ошибок парсинга JSON, что свидетельствует о способности модели придерживаться заданного формата вывода.\n\n---\n\n#### 1. Характерные ошибки модели\n\n*   **Низкая точность (Precision) и полнота (Recall) извлечения:**\n    *   **Для \"массовой доли\":** Precision (41.80%) значительно ниже Recall (53.68%). Это означает, что модель часто извлекает некорректные значения или классифицирует другие числа как массовую долю (ложные срабатывания), а также пропускает часть действительных значений массовой доли (ложные пропуски). Вероятно, модель \"галлюцинирует\" массовые доли там, где их нет, или неверно определяет вещество/значение.\n    *   **Для \"прочего\":** Recall (27.59%) существенно ниже Precision (37.84%). Это указывает на то, что модель очень плохо распознает элементы категории \"прочее\" (стандарты, массы, количества), пропуская большинство из них. Когда же она их извлекает, вероятность корректного извлечения несколько выше, чем для \"массовой доли\", но все равно остается низкой.\n*   **Сложности с интерпретацией контекста и неявных правил:** Модель, вероятно, не справляется с преобразованием \"фосфора\" в \"P2O5\" или \"калия\" в \"K2O\", как это показано в примерах, если эти правила не прописаны очень явно.\n*   **Проблемы с распознаванием форматов \"прочих\" элементов:** Модель, судя по низкому Recall, с трудом распознает стандарты (ТУ, ГОСТ) или различные форматы указания массы/количества товара, даже если они явно присутствуют в тексте (как в \"Текст для анализа\" с \"ТУ 20.15.52-089-05785164-2022\").\n*   **Ошибки в обработке диапазонов:** Примеры `[null, 0.5]` и `[32, null]` для \"не более\" и \"не менее\" требуют точного понимания, что является сложной логической задачей для маленьких моделей. Модель может либо игнорировать такие конструкции, либо неверно формировать массив.\n\n---\n\n#### 2. Причины ошибок парсинга JSON\n\nСогласно предоставленным данным: \"Ошибок парсинга не обнаружено.\"\nЭто отличный результат, указывающий на то, что модель успешно придерживается синтаксиса JSON, указанного в промпте и примерах. Следовательно, причин для ошибок парсинга JSON нет. Проблемы кроются исключительно в семантике извлеченных данных.\n\n---\n\n#### 3. Причины ошибок в извлечении данных\n\n*   **Размер и возможности модели (gemma-2-2b-it):** Модель с 2 миллиардами параметров является относительно небольшой. Она может испытывать трудности с более сложным логическим выводом, обобщением и точным следованием множеству мелких, но важных деталей, таких как:\n    *   Преобразование названий элементов (`K` в `K2O`, `P` в `P2O5`).\n    *   Точное определение границ для диапазонов (`не более`, `не менее`).\n    *   Дифференциация между релевантными числовыми значениями и шумом в тексте.\n    *   Распознавание разнообразных форматов \"прочих\" показателей.\n*   **Длина и насыщенность промпта:** Промпт очень детализированный (4116 символов) и содержит 5 примеров. Для небольшой модели такой объем информации может быть избыточным, и она может испытывать \"забывание\" части инструкций или примеров во время генерации, особенно если эти инструкции представлены не в самом начале.\n*   **Неявные правила в промпте:** Хотя примеры хорошо иллюстрируют желаемый формат, некоторые правила (например, преобразование P -> P2O5, K -> K2O) представлены только в виде примеров, а не явных текстовых инструкций. Модель может не всегда улавливать эти неявные связи.\n*   **Отсутствие разнообразия в обучающих данных (для предобучения):** Если базовая модель не была достаточно обучена на задачах, связанных с извлечением структурированных данных из химических/технических текстов, ей будет сложно адаптироваться только по промпту.\n\n---\n\n#### 4. Рекомендации по улучшению промпта\n\n*   **Явное указание правил преобразования элементов:**\n    Добавить в раздел инструкций 1.1 (Массовую долю элементов) пункт: \"Если в тексте указан *фосфор (P)*, выводи его массовую долю в пересчете на *P2O5*. Если указан *калий (K)*, выводи его массовую долю в пересчете на *K2O*.\"\n*   **Детализация \"прочих\" численных показателей:**\n    В разделе 1.3 (Прочие численные показатели) явно перечислить ожидаемые значения для ключа `\"параметр\"`: \"Например: 'стандарт' (для ТУ, ГОСТ), 'масса нетто единицы', 'масса брутто единицы', 'масса брутто', 'количество товара', 'марка' и т.д.\" Это поможет модели лучше классифицировать извлеченные данные.\n*   **Уточнение обработки диапазонов массы/количества:**\n    Для примеров с `+-X%` (как в примере 5, где `25КГ+-5%` становится `26.25 кг`) явно прописать, как следует рассчитывать итоговое значение: \"Если масса указана с диапазоном, например 'X кг +- Y%', вычисляй максимальное значение для поля 'масса' (например, X * (1 + Y/100)).\"\n*   **Упорядочивание и акцентирование:** Попробуйте перенести наиболее критичные инструкции (формат JSON, основные категории) в начало промпта, до примеров, чтобы модель с большей вероятностью их \"запомнила\".\n*   **Дополнительные примеры (при необходимости):** Если некоторые типы ошибок повторяются, можно добавить 1-2 примера, демонстрирующих правильное извлечение именно этих сложных случаев.\n\n---\n\n#### 5. Рекомендации по настройке гиперпараметров\n\nТекущие гиперпараметры:\n*   `max_new_tokens: 512`: Адекватно для большинства JSON-ответов. Поскольку ошибок парсинга нет, это говорит о том, что модель не обрезает вывод. Изменений не требуется.\n*   `do_sample: false`: Это детерминированный режим генерации, который подходит для задач извлечения, где ожидается точный и повторяемый результат. Изменений не требуется.\n*   `torch_dtype: bfloat16`: Оптимальный тип данных для моделей Gemma на совместимом оборудовании, обеспечивает хороший баланс между производительностью и точностью. Изменений не требуется.\n\n**Вывод по гиперпараметрам:** Текущие настройки гиперпараметров являются разумными для данной задачи и, вероятно, не являются основной причиной низкого качества извлечения данных.\n\n---\n\n#### 6. Общие рекомендации по улучшению качества\n\n*   **Fine-tuning (дообучение) модели (наиболее эффективная рекомендация):** Это самый мощный метод для значительного улучшения качества. Создайте размеченный датасет из множества текстов (1000-5000+ примеров) с соответствующими JSON-ответами. Дообучение `google/gemma-2-2b-it` на этом датасете позволит модели глубоко усвоить специфику домена и форматирования.\n*   **Использование более крупной базовой модели:** Если дообучение `gemma-2-2b-it` не дает достаточного улучшения, рассмотрите возможность использования более мощной базовой модели (например, `gemma-7b-it` или аналогичной от других производителей), а затем проведите её дообучение. Более крупные модели обладают лучшими способностями к рассуждению и пониманию контекста.\n*   **Детальный анализ ошибок:** Проведите более глубокий анализ некорректных ответов модели. Классифицируйте типы ошибок (например, неверное вещество, неправильное число, отсутствие параметра, ложный параметр) и определите, какие паттерны в тексте приводят к ним. Это поможет целенаправленно улучшать промпт или создавать более эффективные данные для дообучения.\n*   **Увеличение объема и разнообразия примеров в промпте:** Хотя промпт уже длинный, возможно, стоит добавить больше разнообразных примеров, охватывающих крайние случаи и различные формулировки, если дообучение невозможно или пока не планируется. Однако, для 2B модели это может привести к еще большей \"забывчивости\".\n*   **Использование постобработки:** Внедрите этап постобработки JSON-вывода. Это может включать:\n    *   Валидацию значений (например, массовые доли должны быть в диапазоне 0-100%).\n    *   Стандартизацию названий веществ или параметров.\n    *   Применение простых регулярных выражений для корректировки мелких, но систематических ошибок, если такие будут обнаружены.",
  "model_used": "gemini-2.5-flash",
  "parsing_errors_count": 0,
  "hyperparameters": {
    "max_new_tokens": 512,
    "do_sample": false,
    "torch_dtype": "bfloat16"
  },
  "system_info": {
    "api_model": false,
    "multi_agent_mode": null,
    "gpu_info": {
      "cuda_available": true,
      "cuda_version": "12.1",
      "gpu_name": "NVIDIA GeForce RTX 4060 Laptop GPU",
      "gpu_memory_total_gb": 8.0,
      "gpu_memory_allocated_gb": 0.0,
      "gpu_memory_reserved_gb": 0.0,
      "gpu_name_detailed": "NVIDIA GeForce RTX 4060 Laptop GPU",
      "driver_version": "591.74"
    },
    "gpu_memory_during_inference_gb": 4.88,
    "average_response_time_seconds": 35.10503796815872
  },
  "quality_metrics_summary": {
    "массовая доля": {
      "accuracy": 0.36070309001343487,
      "precision": 0.4180327868852459,
      "recall": 0.5368421052631579,
      "f1": 0.4700460829493087
    },
    "прочее": {
      "accuracy": 0.25601206064169024,
      "precision": 0.3783783783783784,
      "recall": 0.27586206896551724,
      "f1": 0.3190883190883191
    }
  }
}