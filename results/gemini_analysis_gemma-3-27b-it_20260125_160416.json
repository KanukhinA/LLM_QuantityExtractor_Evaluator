{
  "model_name": "gemma-3-27b-it",
  "timestamp": "20260125_160416",
  "analysis": "Как эксперт по оценке качества работы языковых моделей, я проанализировал предоставленные результаты тестирования модели `gemma-3-27b-it` с учетом заданного промпта, гиперпараметров и метрик качества.\n\n---\n\n### Анализ результатов тестирования модели `gemma-3-27b-it`\n\n**1. Характерные ошибки модели**\n\nНа основе предоставленных метрик можно выделить следующие характерные ошибки:\n\n*   **Высокое качество извлечения \"массовая доля\" (F1: 80.28%)**: Модель достаточно хорошо справляется с извлечением массовых долей.\n    *   **Небольшие проблемы с полнотой (Recall: 77.29%)**: Модель иногда пропускает некоторые массовые доли, которые должны быть извлечены. Это может быть связано с их неявным указанием, сложной структурой предложения или вхождением в состав марок.\n    *   **Приемлемая точность (Precision: 83.52%)**: Когда модель извлекает массовую долю, она в большинстве случаев делает это корректно, что говорит о неплохом понимании этого типа признаков.\n*   **Значительно более низкое качество извлечения \"прочее\" (F1: 55.22%)**: Это ключевая область для улучшения.\n    *   **Низкая точность (Precision: 58.12%)**: Модель часто извлекает лишние или некорректные \"прочие\" признаки (ложноположительные срабатывания). Это может быть следствием галлюцинаций или неправильной классификации числовых данных, не относящихся к целевым признакам.\n    *   **Низкая полнота (Recall: 52.61%)**: Модель пропускает значительное количество \"прочих\" признаков, которые должны были быть извлечены (ложноотрицательные срабатывания). Это указывает на трудности в распознавании всех вариаций этих признаков.\n    *   **Общая низкая аккуратность (Accuracy: 45.14%)**: Для категории \"прочее\" модель совершает много ошибок как в извлечении, так и в пропуске признаков.\n*   **Отсутствие ошибок парсинга JSON**: Модель строго следует формату JSON, указанному в промпте, что является отличным результатом и облегчает дальнейшую обработку данных.\n\n**2. Причины ошибок парсинга JSON**\n\n*   Как указано в результатах, **ошибок парсинга JSON не обнаружено**. Это свидетельствует о том, что модель очень хорошо следует инструкции по форматированию вывода в JSON, включая структуру, типы данных и использование ключевого слова \"ОТВЕТ:\".\n\n**3. Причины ошибок в извлечении данных**\n\n*   **Сложность и объем промпта**: Промпт очень подробный (более 4000 символов) и содержит множество специфических правил, исключений и указаний. Чем больше и сложнее промпт, тем выше вероятность, что модель может упустить некоторые нюансы или не всегда последовательно применять все правила, особенно для менее распространенных или более сложных случаев.\n*   **Разнообразие категории \"прочее\"**: Категория \"прочее\" объединяет множество различных типов данных (масса нетто, брутто, количество, стандарты, марки, объемы). Каждый из них имеет свои паттерны извлечения и уникальные правила (например, расчет массы брутто с \"+5%\", различия между \"массой нетто единицы\" и \"массой брутто\"). Модели сложнее обобщать правила на такую разнородную категорию.\n*   **Сложные лингвистические конструкции**:\n    *   Правила, требующие арифметических операций (например, \"ПО 1000 КГ+5%\"), могут быть сложны для некоторых моделей без дополнительной тренировки.\n    *   Разграничение \"масса нетто\" от \"масса брутто\" на основе контекста (\"МЕШКИ ПО 50 КГ\" против \"МАССА БРУТТО С УПАКОВКОЙ\") требует тонкого понимания смысла, а не простого поиска ключевых слов.\n    *   Приоритизация \"конкретного значения\" над \"общим условием\" также добавляет сложности.\n*   **Недостаток примеров для \"прочее\"**: В промпте дан один общий пример, который охватывает несколько типов \"прочих\" признаков. Однако, для такой широкой категории может быть недостаточно одного примера, чтобы модель полностью усвоила все правила и их применение к разнообразным подтипам. Особенно критично отсутствие примеров для сложных или редких случаев.\n*   **Чувствительность к формулировкам в тексте**: Модель может быть чувствительна к синтаксису и формулировкам в анализируемом тексте. Нестандартные или менее частые варианты написания признаков могут приводить к их пропуску.\n*   **Модель gemma-3-27b-it**: Хотя это мощная модель, для высокоточных и специализированных задач извлечения информации с множеством правил, ей может не хватать доменно-специфических знаний или способности к идеальному следованию всем инструкциям без дополнительного файн-тюнинга на целевых данных.\n\n**4. Рекомендации по улучшению промпта**\n\nПромпт уже очень детальный и хорошо структурирован. Тем не менее, для улучшения качества \"прочего\" можно внести следующие изменения:\n\n*   **Добавить больше \"few-shot\" примеров**:\n    *   Предоставьте 2-3 **разнообразных** примера, которые иллюстрируют сложные случаи для категории \"прочее\". Например, один пример, демонстрирующий правило \"1000 КГ+5%\", другой — разницу между \"массой нетто\" и \"массой брутто\", третий — случай, где некоторые \"прочие\" признаки *отсутствуют*.\n    *   Особое внимание уделить примерам, где в тексте для анализа нет массовых долей, но есть \"прочие\" (как в вашем тестовом примере \"КАЛИЙ СЕРНОКИСЛЫЙ...\").\n*   **Эксплицировать список возможных параметров для \"прочее\"**:\n    *   Прямо укажите в промпте все возможные значения для `параметр` в категории \"прочее\" (например, \"масса нетто единицы\", \"масса брутто\", \"количество поддонов\", \"стандарт\", \"марка\", и т.д.). Это поможет модели ограничить пространство возможных ответов и снизит галлюцинации.\n*   **Повторить/акцентировать сложные правила**: Некоторые критически важные и сложные правила (вроде обработки \"1000 КГ+5%\", или различие \"масса нетто\" vs \"масса брутто\") можно выделить или повторить в более явной форме, возможно, с использованием дополнительных примеров прямо в тексте правила, а не только в основном примере.\n*   **Оптимизировать формулировки (при необходимости)**: Хотя промпт уже хорошо написан, можно попробовать немного упростить или перефразировать некоторые длинные предложения, чтобы уменьшить когнитивную нагрузку на модель.\n*   **Разделение промпта (экспериментально)**: Если модель продолжает сильно путаться в \"прочих\" признаках, можно рассмотреть подход с разделением промпта на две части: сначала извлечение массовых долей, затем (возможно, с другим промптом или вторым вызовом модели) извлечение \"прочего\". Однако, это усложнит процесс и увеличит затраты. Для начала лучше сосредоточиться на улучшении текущего промпта.\n\n**5. Рекомендации по настройке гиперпараметров**\n\n*   `max_new_tokens: 512`: Для коротких входных текстов и соответствующего JSON, 512 токенов может быть достаточно. Однако, если в реальных условиях встречаются более длинные тексты, требующие извлечения большого количества признаков, 512 токенов может стать ограничением, приводящим к обрезанию вывода.\n    *   **Рекомендация**: Проанализируйте максимальную длину JSON-ответов, которые модель *должна* генерировать для самых объемных входных текстов. Если она приближается к 512 токенам, рекомендуется увеличить `max_new_tokens` (например, до 768 или 1024), чтобы избежать обрезания вывода. Для данного тестового примера это не критично.\n*   **Temperature (температура)**: Этот гиперпараметр не указан, но он критичен для задач извлечения.\n    *   **Рекомендация**: Установите `temperature` на очень низкое значение (например, 0.1 - 0.3). Это сделает вывод модели более детерминированным и \"фактическим\", снижая вероятность \"галлюцинаций\" и повышая точность. Если `temperature` сейчас выше, его снижение должно помочь в борьбе с ложноположительными срабатываниями.\n*   **Top-P / Top-K**: Аналогично, для задач извлечения рекомендуется использовать низкие значения `top_p` (например, 0.9) и, возможно, `top_k`.\n\n**6. Общие рекомендации по улучшению качества**\n\n*   **Детальный анализ ошибок**: Проведите глубокий анализ конкретных ошибок модели для категории \"прочее\".\n    *   **False Positives (ложноположительные)**: Что именно модель извлекает, когда не должна? Какие слова или паттерны она ошибочно интерпретирует как \"прочие\" признаки?\n    *   **False Negatives (ложноотрицательные)**: Какие \"прочие\" признаки модель пропускает? Какие у них общие характеристики? Недостаточно ли они явно сформулированы в тексте или промпте?\n    *   Используйте эти инсайты для точечной доработки промпта или создания дополнительных примеров.\n*   **Файн-тюнинг модели**: Для достижения наивысшего качества в такой специализированной задаче, лучшим решением является файн-тюнинг модели (например, Gemma-2B/7B, если 27B слишком дорог или недоступен для файн-тюнинга) на большом наборе данных, состоящем из текстов о химических веществах и удобрениях с размеченными целевыми JSON-выходами. Это позволит модели \"впитать\" доменную специфику и правила гораздо глубже, чем только через промпт.\n*   **Валидация на разнообразных данных**: Убедитесь, что ваш тестовый и валидационный наборы данных охватывают все возможные сценарии: тексты разной длины, разной степени сложности, с полным и неполным набором признаков, с неоднозначными формулировками.\n*   **Гибридный подход**: Для очень сложных правил (например, с арифметикой или сложной логикой выбора), можно рассмотреть гибридный подход: LLM извлекает \"сырые\" данные, а затем отдельный скрипт обрабатывает их, применяя точные бизнес-правила и расчеты. Это может снизить нагрузку на LLM и повысить надежность. Однако, текущий промпт вполне позволяет LLM выполнять эти операции, если она обучена на достаточном количестве данных.\n\n---\n\nВ целом, модель хорошо справляется со сложным заданием по JSON-форматированию и относительно неплохо с извлечением \"массовой доли\". Основное внимание следует уделить улучшению извлечения категории \"прочее\" путем детализации промпта, добавления разнообразных примеров и, при необходимости, файн-тюнинга модели.",
  "model_used": "gemini-2.5-flash",
  "parsing_errors_count": 0,
  "hyperparameters": {
    "max_new_tokens": 512,
    "model_name": "gemma-3-27b-it",
    "api_model": true
  },
  "system_info": {
    "api_model": true,
    "multi_agent_mode": null,
    "gpu_info": {
      "api": true
    },
    "gpu_memory_during_inference_gb": 0.0,
    "average_response_time_seconds": 8.974725620746613
  },
  "quality_metrics_summary": {
    "массовая доля": {
      "accuracy": 0.8043341579055865,
      "precision": 0.8351648351648352,
      "recall": 0.7728813559322034,
      "f1": 0.8028169014084507
    },
    "прочее": {
      "accuracy": 0.45140099000858497,
      "precision": 0.581151832460733,
      "recall": 0.5260663507109005,
      "f1": 0.5522388059701493
    }
  }
}