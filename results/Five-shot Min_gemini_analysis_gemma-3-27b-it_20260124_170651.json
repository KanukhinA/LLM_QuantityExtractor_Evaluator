{
  "model_name": "gemma-3-27b-it",
  "timestamp": "20260124_170651",
  "analysis": "### Анализ результатов тестирования модели gemma-3-27b-it\n\nМодель gemma-3-27b-it демонстрирует хорошие способности к генерации структурированного JSON и неплохо справляется с извлечением массовой доли, но имеет значительные проблемы с категорией \"Прочее\" и, вероятно, с тонкостями извлечения данных (например, вычислениями).\n\n**Метрики качества:**\n\n*   **Массовая доля:** Accuracy: 76.07%, Precision: 76.69%, Recall: 84.30%, F1: 80.31%\n*   **Прочее:** Accuracy: 56.63%, Precision: 63.49%, Recall: 57.69%, F1: 60.45%\n*   Ошибок парсинга не обнаружено.\n\n---\n\n#### 1. Характерные ошибки модели\n\n*   **Категория \"Массовая доля\":**\n    *   **Низкая Precision (76.69%) при высокой Recall (84.30%):** Модель склонна к ложноположительным срабатываниям. Это означает, что она часто извлекает значения, которые *похожи* на массовую долю (например, другие проценты или числа), но не являются ею, или неправильно ассоциирует вещество со значением. Она скорее найдет что-то лишнее, чем пропустит необходимое.\n    *   **Возможные ошибки:** Неправильная идентификация вещества (например, путает \"N\" с \"NO3-\", если это не указано в примере), ошибочное включение других процентных показателей (например, влажность, чистота, если они не являются массовой долей конкретного элемента/оксида), неправильная интерпретация контекста.\n\n*   **Категория \"Прочее\":**\n    *   **Низкие все метрики (F1: 60.45%):** Эта категория является основным слабым местом модели.\n    *   **Низкий Recall (57.69%):** Модель пропускает значительную часть сущностей, которые должны быть отнесены к \"прочему\". Это может быть связано с разнообразием форматов стандартов, идентификаторов или способов указания количества.\n    *   **Относительно низкая Precision (63.49%):** Хотя Precision выше Recall, она всё равно оставляет желать лучшего. Модель не всегда правильно классифицирует данные как \"прочее\" или ошибается при извлечении самого значения (например, извлекает некорректную часть стандарта или неверно вычисляет массу).\n    *   **Особые проблемы:** Вероятно, трудности с вычислением масс на основе процентов (например, \"1000 кг + 5%\"), с распознаванием всех форматов стандартов (ТУ, ГОСТ) или с обработкой сложных текстовых описаний количества товара.\n\n---\n\n#### 2. Причины ошибок парсинга JSON\n\n**Ошибок парсинга JSON не обнаружено**, что является очень позитивным результатом. Это свидетельствует о том, что модель хорошо усвоила требуемый формат вывода и успешно генерирует синтаксически корректный JSON, следуя структуре, заданной в промпте и примерах. Это снижает необходимость в корректировке инструкций, касающихся *формата* JSON.\n\n---\n\n#### 3. Причины ошибок в извлечении данных\n\n*   **Недостаточное понимание контекста и семантики:** Модель может путать численные значения, которые похожи по формату (например, числа с процентами), но имеют разное семантическое значение (массовая доля vs. влажность).\n*   **Сложность выделения разнородных сущностей в \"Прочее\":** Категория \"прочее\" очень широка и включает в себя стандарты (разнообразные паттерны), количество товара (с разными единицами измерения и иногда требующее вычислений), и другие идентификаторы. Универсальные правила для такой разнородности могут быть сложны для модели без достаточного количества примеров.\n*   **Неспособность к точным арифметическим вычислениям:** Модели LLM по своей природе не являются калькуляторами. Примеры \"1000 КГ+5%\" -> 1050 или \"25КГ+-5%\" -> 26.25 требуют выполнения арифметических операций, с которыми LLM часто справляются неоптимально, если это не заложено в их тренировочных данных или не подкреплено очень сильными примерами.\n*   **Неполный охват типов веществ и параметров:** Возможно, промпт и примеры не охватывают все возможные варианты названий веществ, типов стандартов или описаний количества, которые встречаются в реальных текстах.\n*   **Нечеткое определение границ извлекаемых значений:** Например, при извлечении стандарта \"ТУ 20.15.52-089-05785164-2022\", модель может ошибочно захватить лишние слова или, наоборот, пропустить часть идентификатора.\n*   **Обработка диапазонов и пороговых значений:** В примере 3 показано, как \"не более 0,5%\" преобразуется в `[null, 0.5]` и \"не менее 32%\" в `[32, null]`. Это сложная логика, требующая точной интерпретации лингвистических конструкций.\n\n---\n\n#### 4. Рекомендации по улучшению промпта\n\nПоскольку ошибки парсинга отсутствуют, фокус должен быть на улучшении точности и полноты извлечения данных.\n\n1.  **Больше детализации для \"Массовой доли\":**\n    *   **Перечислить синонимы/варианты названий:** Явно указать, как модель должна маппить различные формулировки (например, \"общий азот\", \"аммонийный азот\", \"нитратный азот\") к соответствующим коротким обозначениям (\"N\", \"NH4+\", \"NO3-\").\n    *   **Уточнить исключения:** Прямо указать, какие процентные значения *не* являются массовой долей (например, \"влажность не более X%\", \"растворимость Y%\", если они не относятся к составу вещества).\n\n2.  **Значительное расширение и уточнение для \"Прочее\":**\n    *   **Разнообразить примеры стандартов:** Добавить примеры с разными форматами ГОСТ, СТО, ТУ, если они встречаются.\n    *   **Детализировать обработку количества товара:**\n        *   Явно указать, что модель должна *вычислять* конечную массу, если даны процентные отклонения (например, \"Х кг +- Y%\", \"Х кг + Y%\"). Добавить больше таких примеров.\n        *   Перечислить возможные типы единиц измерения (\"кг\", \"т\", \"мешки\", \"вагон\", \"биг-беги\") и соответствующие ключи (\"масса нетто единицы\", \"масса брутто единицы\", \"масса брутто\").\n    *   **Добавить примеры других численных показателей:** Если есть другие важные \"прочие\" числовые характеристики, добавить их в примеры.\n\n3.  **Усилить правила обработки диапазонов/неравенств:**\n    *   В секции \"2. Выведи json по аналогии с этими примерами:\" добавить более явное правило для `[null, X]` и `[X, null]`, возможно, с кратким текстовым пояснением после примера.\n\n4.  **Количество примеров (Few-shot learning):**\n    *   Увеличить количество примеров в промпте (сейчас их 5). Особенно важно добавить больше разнообразных примеров для категории \"прочее\" и для случаев, требующих вычислений или обработки диапазонов. Цель – охватить как можно больше edge-кейсов.\n\n5.  **Разделение инструкций (если промпт станет слишком большим):**\n    *   Если промпт станет слишком длинным, можно рассмотреть возможность разделения инструкций на более мелкие блоки или использования более четкой иерархии для улучшения читаемости.\n\n---\n\n#### 5. Рекомендации по настройке гиперпараметров\n\nТекущие гиперпараметры:\n`max_new_tokens`: 512 (достаточно для текущей задачи)\n`model_name`: gemma-3-27b-it\n`api_model`: true\n\n*   **Температура (temperature):**\n    *   Поскольку для \"Массовой доли\" наблюдаются ложноположительные срабатывания (Precision ниже Recall), а для \"Прочее\" низкие все метрики, рекомендуется **снизить температуру (например, до 0.1-0.3)**. Это сделает вывод модели более детерминированным и сосредоточенным на наиболее вероятных токенах, что может улучшить Precision и снизить \"галлюцинации\". Однако это может также немного снизить Recall, если модель станет слишком консервативной. Найдите оптимальный баланс через эксперименты.\n*   **Top-p / Top-k:**\n    *   Если они не установлены явно, модель использует значения по умолчанию. Для задач извлечения фактов обычно рекомендуется использовать **более низкие значения Top-p (например, 0.5-0.7) и/или Top-k (например, 20-50)**, чтобы ограничить выбор токенов и получить более точный, менее разнообразный результат.\n\n---\n\n#### 6. Общие рекомендации по улучшению качества\n\n1.  **Дообучение (Fine-tuning):** Если существующие рекомендации по промпту и гиперпараметрам не дают достаточного улучшения, наиболее эффективным методом будет дообучение модели на большом, специально размеченном датасете. Это позволит модели глубоко изучить специфические паттерны извлечения информации из текстов о химических веществах и удобрениях, включая сложные правила маппинга и вычислений.\n\n2.  **Больше качественных примеров (для Few-shot Learning):** Даже без полного дообучения, увеличение количества и разнообразия примеров в промпте (до 10-15 и более, если позволяет контекстное окно) может значительно улучшить производительность. Сосредоточьтесь на примерах, которые иллюстрируют сложные случаи:\n    *   Вычисления массы (например, \"X кг +/- Y%\").\n    *   Обработка диапазонов (`[min, max]`).\n    *   Различные форматы стандартов.\n    *   Случаи, где модель часто совершает ошибки (ложноположительные для массовой доли, пропуски для \"прочее\").\n\n3.  **Разбиение задачи (Chain-of-Thought / Task Orchestration):** Для особо сложных случаев, таких как арифметические вычисления, можно рассмотреть подход, при котором модель сначала извлекает сырые данные (например, \"1000 КГ\", \"+5%\"), а затем эти данные передаются внешнему калькулятору или скрипту для точного расчета, после чего результат возвращается модели для формирования финального JSON. Это позволяет использовать сильные стороны каждой системы.\n\n4.  **Пост-обработка и валидация:** Внедрение этапа пост-обработки для валидации извлеченных данных. Например, проверка, что массовая доля не превышает 100%, что извлеченные единицы измерения соответствуют ожидаемым, или исправление мелких ошибок форматирования.\n\n5.  **Итеративный подход:** Процесс улучшения качества LLM и промпта является итеративным. Регулярно тестируйте модель на новых данных, анализируйте ошибки и используйте эти знания для дальнейшей доработки промпта и/или настроек модели.",
  "model_used": "gemini-2.5-flash",
  "parsing_errors_count": 0,
  "hyperparameters": {
    "max_new_tokens": 512,
    "model_name": "gemma-3-27b-it",
    "api_model": true
  },
  "system_info": {
    "api_model": true,
    "multi_agent_mode": null,
    "gpu_info": {
      "api": true
    },
    "gpu_memory_during_inference_gb": 0.0,
    "average_response_time_seconds": 9.846189153194427
  },
  "quality_metrics_summary": {
    "массовая доля": {
      "accuracy": 0.7606992544492545,
      "precision": 0.7669172932330827,
      "recall": 0.8429752066115702,
      "f1": 0.8031496062992126
    },
    "прочее": {
      "accuracy": 0.5662896932127701,
      "precision": 0.6349206349206349,
      "recall": 0.5769230769230769,
      "f1": 0.6045340050377833
    }
  }
}