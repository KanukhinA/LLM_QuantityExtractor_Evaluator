{
  "model_name": "gemma-3-4b-it",
  "timestamp": "20251223_221123",
  "analysis": "## Оценка качества работы языковой модели gemma-3-4b-it\n\n### Общая оценка\n\nРезультаты тестирования модели `gemma-3-4b-it` показывают крайне низкое качество извлечения численных и количественных характеристик, особенно для категории \"массовая доля\". Метрики Precision, Recall и F1-score находятся на неприемлемо низком уровне, что свидетельствует о системных проблемах в понимании задачи, следовании инструкциям и форматировании вывода. Ошибки парсинга JSON также являются критической проблемой, делая значительную часть ответов непригодными для автоматической обработки.\n\n### 1. Характерные ошибки модели\n\n*   **Низкая точность и полнота извлечения**: Модель пропускает значительную часть целевых сущностей (низкий Recall) и извлекает много неверных или нерелевантных данных (низкий Precision), что особенно заметно в категории \"массовая доля\".\n*   **Галлюцинации и извлечение нерелевантной информации**: Модель часто генерирует данные, которых нет в исходном тексте (например, `K2O: предсказано [45.0, 55.0], истина отсутствует`) или извлекает информацию, которая не является \"численным/количественным признаком\" (например, описание `внешний вид`).\n*   **Неверная интерпретация диапазонов и логических операторов**: Модель ошибается при обработке диапазонов `[min, max]` и операторов \"не менее\" `[min, null]`, \"не более\" `[null, max]`. Например, предсказывает точечное значение вместо диапазона (`K2O: предсказано 30.0, истина [29.0, 31.0]`) или неверно формирует диапазон (`S: предсказано [1.0, 2.0], истина [2.0, None]`).\n*   **Несоблюдение форматирования значений**:\n    *   Использование полных названий химических элементов (\"азот\", \"фосфор\") вместо их символов (\"N\", \"P\"), вопреки явной инструкции.\n    *   Некорректная агрегация значений, когда для одного признака генерируется длинный массив чисел, вместо одного значения или диапазона (`Text #95`).\n*   **Нарушение JSON-структуры**: Модель систематически генерирует невалидный JSON, что делает автоматический парсинг невозможным.\n\n### 2. Причины ошибок парсинга JSON\n\nОсновной причиной ошибок парсинга JSON является **отсутствие явного и детализированного определения требуемой JSON-схемы в промпте**. Модель не понимает точную структуру, которую от нее ожидают, и пытается \"угадать\" её, что приводит к следующим проблемам:\n\n*   **Некорректное формирование пар \"ключ: значение\"**: В примерах `Text #10` и `Text #70` модель создает ключи без значений (`\"частицы менее 1 мм\"`, `\"массовая доля\"`) или нарушает синтаксис, пытаясь встроить дополнительные дескрипторы. JSON требует, чтобы каждый ключ был связан со значением.\n*   **Неправильная вложенность и агрегация данных**: В `Text #95` модель формирует нелогичный и избыточный массив значений для одного параметра \"массовая доля\", что свидетельствует о глубоком непонимании того, как должны быть представлены эти данные в JSON-объекте.\n*   **Вероятные незакрытые структуры**: Хотя не показано явно, частой причиной \"невалидного JSON\" является обрыв генерации (например, из-за `max_new_tokens` или внутренней ошибки), оставляющий незакрытые скобки.\n\n### 3. Причины ошибок в извлечении данных\n\n*   **Ограниченная мощность модели**: `gemma-3-4b-it` — относительно небольшая модель. Такие модели могут испытывать трудности с комплексным пониманием и удержанием в памяти множества сложных инструкций, особенно когда требуется точное следование формату и семантике. Их способности к \"рассуждению\" и точному следованию сложным правилам (как точная интерпретация диапазонов или извлечение из марки) ограничены.\n*   **Длинный и детализированный промпт без явных примеров**: Хотя промпт содержит много деталей, их обилие без четких *примеров* ожидаемого JSON-вывода, вероятно, перегружает модель. Модель не может эффективно сопоставить текстовые инструкции с желаемым структурированным результатом.\n*   **Недостаточная чёткость инструкций по структуре**: Промпт очень хорошо описывает *что* извлекать, но недостаточно хорошо — *как* это должно выглядеть в JSON. Например, как различать \"массовая доля\" из общего описания и \"массовая доля\" из марки.\n*   **Семантические ошибки**: Модель путает описательные характеристики с численными (`внешний вид`) или неверно интерпретирует количественные признаки.\n*   **Недостаточная адаптация к предметной области**: Модель, вероятно, не была специально дообучена на текстах о химических веществах/удобрениях с целью извлечения специфических числовых данных, что снижает её способность понимать контекст и специфическую терминологию.\n\n### 4. Рекомендации по улучшению промпта\n\n1.  **Включить явную JSON-схему и примеры (Few-shot Learning)**: Это самое критичное изменение. Добавьте 2-3 полных примера входного текста и соответствующего *идеального* JSON-вывода. Примеры должны охватывать:\n    *   Извлечение массовой доли с диапазонами `[min, max]`.\n    *   Извлечение с операторами `[min, null]` и `[null, max]`.\n    *   Извлечение различных \"прочих\" параметров (стандарт, марка, масса).\n    *   Правильное использование символов элементов (N, P2O5, K2O).\n    *   Пример извлечения массовой доли из \"марки\".\n2.  **Уточнить структуру JSON-объектов**:\n    *   Для \"массовой доли\": `{\"вещество\": \"N\", \"значение\": [10.0, 12.0], \"единица\": \"%\"}`. Избегать дублирования ключа \"массовая доля\" внутри объекта.\n    *   Для \"прочего\": `{\"название\": \"масса нетто\", \"значение\": 500, \"единица\": \"кг\"}`.\n3.  **Структурировать промпт**: Разделите его на чёткие секции: \"Роль\", \"Задача\", \"Формат вывода JSON (с примерами)\", \"Особые указания\". Используйте форматирование (жирный шрифт, списки) для выделения ключевых правил.\n4.  **Усилить правила по элементам и диапазонам**:\n    *   `Извлекай массовую долю азота как \"массовая доля N\".`\n    *   `Строго используй формат [min, max] для диапазонов, [min, null] для \"не менее\", [null, max] для \"не более\".`\n5.  **Явно указать, что извлекаются *только* численные/количественные признаки**:\n    *   `Не извлекай описательные характеристики (например, \"внешний вид\", \"цвет\"), если они не содержат числовых значений.`\n6.  **Пересмотреть правило для марки**: Текущее правило \"используй данные из марки, если нет иных данных по массовой доле вещества\" может быть сложным. Если нужно извлекать массовые доли из марки *в дополнение* к полю \"марка\", это должно быть явно показано в примерах. Если же из марки нужно извлекать *только* массовые доли, а само поле \"марка\" не нужно, то это тоже должно быть указано.\n\n### 5. Рекомендации по настройке гиперпараметров\n\n*   **`temperature` (температура)**: По умолчанию не указана. **Рекомендуется снизить `temperature` до очень низких значений (например, 0.1-0.3)**. Это сделает ответы модели более детерминированными и менее склонными к галлюцинациям, что критично для задач извлечения структурированных данных.\n*   **`top_p` / `top_k` (не указаны)**: Аналогично `temperature`, для извлечения данных обычно предпочтительны низкие значения `top_p` (например, 0.9) и `top_k` (например, 50), чтобы сосредоточить генерацию на наиболее вероятных токенах и уменьшить разнообразие.\n*   **`max_new_tokens`**: 512 токенов кажется достаточным для большинства случаев. Если после улучшения промпта и структуры JSON ответы будут по-прежнему обрываться, можно незначительно увеличить. Однако текущие проблемы, скорее всего, не связаны с этим параметром.\n\n### 6. Общие рекомендации по улучшению качества\n\n1.  **Валидация и исправление JSON на стороне клиента**: Внедрите в код, который вызывает модель, логику для валидации полученного JSON. Если JSON невалиден, можно попытаться программно исправить распространённые ошибки (например, добавить закрывающие скобки, если генерация оборвалась) или логировать проблемный ответ для дальнейшего анализа. Для критических ошибок можно рассмотреть механизм повторного запроса к модели, если она сможет исправить свою ошибку, получив в промпте сообщение о невалидности предыдущего ответа.\n2.  **Дообучение (Fine-tuning)**: Для достижения высокой точности в такой специфической задаче, как извлечение структурированных данных из химических текстов, дообучение модели `gemma-3-4b-it` (или более крупной модели) на собственном, качественно аннотированном наборе данных является наиболее эффективным путем. Это позволит модели лучше усвоить предметную область, специфические термины и требуемый формат вывода.\n3.  **Использование более мощной модели**: Если дообучение не является опцией, рассмотрите возможность использования более крупных моделей (например, `gemma-7b-it`, Llama, Mixtral). Более крупные модели, как правило, лучше справляются со сложными инструкциями, следуют заданному формату JSON и меньше склонны к галлюцинациям.\n4.  **Итеративный подход к разработке промпта**: Продолжайте тестировать и оптимизировать промпт на небольшой, но репрезентативной выборке. Каждое изменение должно быть направлено на устранение конкретной категории ошибок, выявленных в ходе тестирования.\n\nВ целом, модель `gemma-3-4b-it` не демонстрирует адекватной производительности для данной задачи без существенных доработок промпта и, возможно, дообучения. Приоритетом должно стать **внедрение в промпт четкой JSON-схемы и примеров**, а также снижение `temperature`.",
  "model_used": "gemini-2.5-flash",
  "parsing_errors_count": 3,
  "quality_metrics_summary": {
    "массовая доля": {
      "precision": 0.13071895424836602,
      "recall": 0.20725388601036268,
      "f1": 0.16032064128256512
    },
    "прочее": {
      "precision": 0.4362934362934363,
      "recall": 0.565,
      "f1": 0.4923747276688453
    }
  }
}