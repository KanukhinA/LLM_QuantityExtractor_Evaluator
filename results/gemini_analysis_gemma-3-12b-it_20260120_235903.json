{
  "model_name": "gemma-3-12b-it",
  "timestamp": "20260120_235903",
  "analysis": "## Анализ результатов тестирования модели gemma-3-12b-it\n\nМодель `gemma-3-12b-it` демонстрирует умеренную эффективность в задаче извлечения численных и количественных характеристик, особенно для категории \"Массовая доля\". Однако, существуют значительные проблемы с извлечением \"Прочих\" параметров и критические ошибки с форматированием вывода JSON.\n\n### 1. Характерные ошибки модели\n\n*   **Низкая точность и полнота для \"Прочих\" параметров:** F1-метрика 46.32% указывает на серьезные проблемы как с идентификацией всех необходимых параметров (Recall: 41.87%), так и с корректностью их извлечения или классификации (Precision: 51.83%).\n*   **Ошибки форматирования JSON:** 9 из X тестов вернули невалидный JSON, что является критической проблемой, делающей результаты модели непригодными для автоматической обработки. Это указывает на то, что модель либо не поняла, что требуется JSON, либо испытывает трудности с его генерацией.\n*   **Некорректное или неполное извлечение диапазонов/операторов:**\n    *   Модель может предсказывать `[значение, None]` для одиночных значений (`N: предсказано [17.0, None], истина 17.0`) вместо `[17.0, 17.0]` или просто `17.0` (если допускается).\n    *   Проблемы с распознаванием \"не менее/не более\" и их корректным представлением с `null` (`NH4+: предсказано отсутствует, истина [None, 0.5]`).\n*   **Семантическая путаница:**\n    *   Перепутывание похожих, но разных параметров: `Параметр масса: предсказано 1035000.0, истина отсутствует` (модель предсказала \"масса\", хотя ожидалось \"масса нетто\").\n    *   Неспособность четко различать близкие сущности: `масса нетто` vs `масса нетто единицы`.\n*   **Проблемы с распознаванием химических элементов/соединений:**\n    *   Путаница между `CI` и `Cl`.\n    *   Неспособность извлечь `NH4+` или `NH4-N` в некоторых случаях.\n*   **\"Галлюцинации\" (ложные срабатывания):** Модель извлекает сущности, которых нет в тексте (`Вещество CI: предсказано [1.0, 2.0], истина отсутствует`).\n*   **Неполное извлечение для сложных параметров:** Для параметра \"марка\" модель извлекла `npks-8`, но упустила детали `(npk 8:20:30)`, которые могли бы содержать дополнительные массовые доли.\n\n### 2. Причины ошибок парсинга JSON\n\nОсновная причина ошибок парсинга JSON, скорее всего, кроется в **отсутствии явного указания на необходимость вывода в формате JSON в промпте**. Хотя промпт детально описывает структуру извлекаемых данных (Название признака, Значение, Единица измерения), он нигде **не требует** обернуть эти данные в формат JSON, а тем более не предоставляет его структуру или пример. Модель, без такой явной инструкции, может генерировать текст в произвольной, наиболее естественной для неё форме, которая не является валидным JSON.\n\n### 3. Причины ошибок в извлечении данных\n\n*   **Недостаточная спецификация выходного формата (JSON):** Как упомянуто выше, это влияет на саму структуру ответа, не только на его содержимое.\n*   **Сложность и многослойность инструкций в промпте:** Промпт достаточно длинный и содержит множество правил, которые модель может забывать или не всегда применять последовательно:\n    *   Специфическая обработка диапазонов и операторов (`не менее`, `не более`).\n    *   Замена `Кальций` на `Ca`.\n    *   Замена `K` на `K2O`.\n    *   Приоритет данных из марки.\n    *   Использование точки как разделителя.\n    *   Маленькие буквы в названии признака.\n    Модель может испытывать трудности с одновременным учетом всех этих правил.\n*   **Ограниченная семантическая дифференциация модели:** Модель не всегда точно понимает тонкие различия между похожими терминами (`масса` vs `масса нетто`), что приводит к ошибкам классификации.\n*   **Недостаток контекстных примеров (few-shot learning):** Без демонстрации нескольких примеров \"текст -> правильный JSON-вывод\", модель хуже усваивает требуемый формат и логику извлечения.\n*   **Отсутствие штрафа за \"галлюцинации\"**: Модель генерирует сущности, которых нет в тексте, что говорит о необходимости более строгого контроля над генерацией.\n\n### 4. Рекомендации по улучшению промпта\n\n1.  **Явно укажите требование JSON-формата и предоставьте схему/пример:**\n    *   В начале или в конце промпта добавьте: \"Твой ответ должен быть **строго** в формате JSON. Используй следующий формат:\"\n    *   ```json\n        [\n          {\n            \"название_признака\": \"массовая доля N\",\n            \"значение\": [17.0, 17.0],\n            \"единица_измерения\": \"%\"\n          },\n          {\n            \"название_признака\": \"масса нетто\",\n            \"значение\": [1035000.0, 1035000.0],\n            \"единица_измерения\": \"кг\"\n          }\n          // ... другие примеры\n        ]\n        ```\n    *   Включите примеры для всех типов значений: одиночные числа, диапазоны, `[min, null]`, `[null, max]`.\n    *   Включите примеры для всех единиц измерения и \"пусто\" для стандарта.\n\n2.  **Уточните правило для одиночных значений в диапазонах:**\n    *   \"Если признак указан как одиночное число, укажи его в формате `[число, число]` (например, `17.0` -> `[17.0, 17.0]`).\"\n    *   Четко повторите, что для \"не менее\" и \"не более\" используются `null`: \"«не менее X» - `[X, null]`, «не более Y» - `[null, Y]`\".\n\n3.  **Разграничьте \"масса\", \"масса нетто\", \"масса нетто единицы\":**\n    *   Добавьте примеры или более четкие определения, если это возможно из вашего датасета. Например: \"Внимательно различай 'масса' (общее), 'масса нетто' (вес содержимого упаковки/груза), 'масса нетто единицы' (вес одной упаковки).\"\n\n4.  **Уточните извлечение из \"марки\":**\n    *   \"Если в марке (например, \"N7-P20-K30-S3\") содержится массовая доля вещества, извлеки ее *также* как отдельный признак (например, \"массовая доля N\": [7.0, 7.0], \"%\"). Параметр 'марка' должен содержать **полное строковое значение марки**.\"\n\n5.  **Усильте правила преобразований:**\n    *   \"Всегда преобразуй K в K2O для массовых долей. Всегда заменяй полные названия элементов на их химические символы.\"\n\n6.  **Сократите промпт, если возможно:** Если некоторые инструкции избыточны или модель их уже усвоила, можно попробовать их убрать, чтобы уменьшить когнитивную нагрузку. Однако, для данной задачи, скорее всего, потребуется более *четкое* структурирование, а не сокращение.\n\n7.  **Разделение инструкций:** Разделите инструкции на две основные секции: \"Что найти\" и \"Как это представить\".\n\n### 5. Рекомендации по настройке гиперпараметров\n\n*   **`max_new_tokens`:** 512 токенов обычно достаточно для извлечения структурированных данных. Если при генерации JSON ответы обрезаются, это значение можно увеличить. Однако, текущие JSON-ошибки указывают не на обрезку, а на неверный формат.\n*   **`temperature` (если не указана, предполагается значение по умолчанию):** Для задач извлечения информации и строгого форматирования рекомендуется использовать низкую температуру (например, 0.1-0.3). Это сделает ответы модели более детерминированными и менее склонными к \"галлюцинациям\" или отклонениям от формата.\n*   **`top_p`, `top_k`:** Также можно настроить эти параметры для контроля разнообразия генерации, уменьшая их для более сфокусированного и точного вывода.\n\n### 6. Общие рекомендации по улучшению качества\n\n1.  **Few-shot Learning (обучение на нескольких примерах):**\n    *   Включите в промпт 2-3 примера полного цикла: текст → *правильный, валидный JSON-ответ*. Эти примеры должны охватывать разнообразные сценарии (наличие диапазонов, разных единиц, \"прочих\" параметров, обработки марки и т.д.). Это критически важно для моделей, которые плохо следуют строгим инструкциям форматирования.\n\n2.  **Итеративная доработка промпта:**\n    *   После внедрения рекомендаций 4 и 5, проведите повторное тестирование.\n    *   Анализируйте новые ошибки и корректируйте промпт, целенаправленно добавляя правила для случаев, с которыми модель продолжает справляться плохо.\n\n3.  **Пост-обработка ответов модели:**\n    *   Внедрите скрипт, который будет пытаться исправить распространенные ошибки JSON (например, добавить закрывающие скобки, если они отсутствуют, или преобразовать невалидный JSON в наиболее близкий валидный).\n    *   Создайте правила для пост-коррекции значений или категорий, которые модель постоянно путает (например, если она часто путает \"масса\" с \"масса нетто\" для определенных контекстов).\n\n4.  **Файнтюнинг модели (если возможно):**\n    *   Для действительно высокой точности и надежности в такой специфической и строго формализованной задаче, файнтюнинг модели на большом датасете \"текст-JSON\" пар является наиболее эффективным решением. Это позволит модели усвоить специфику предметной области и требуемый формат вывода гораздо глубже, чем только через промпт.\n\n5.  **Валидация данных:**\n    *   Убедитесь, что \"истинные\" данные для сравнения (ground truth) максимально точны и однозначны, особенно в случаях, где модель испытывает трудности (например, различие между `CI` и `Cl`, или `масса` vs `масса нетто`).\n\nСосредоточившись на четком определении JSON-формата в промпте и предоставлении нескольких примеров, вы сможете значительно улучшить как валидность JSON-вывода, так и общую точность извлечения данных.",
  "model_used": "gemini-2.5-flash",
  "parsing_errors_count": 9,
  "hyperparameters": {
    "max_new_tokens": 512,
    "model_name": "gemma-3-12b-it",
    "api_model": true
  },
  "system_info": {
    "api_model": true,
    "multi_agent_mode": null,
    "gpu_info": {
      "api": true
    },
    "gpu_memory_during_inference_gb": 0.0,
    "average_response_time_seconds": 20.90183225393295
  },
  "quality_metrics_summary": {
    "массовая доля": {
      "accuracy": 0.5959477075954349,
      "precision": 0.7415254237288136,
      "recall": 0.691699604743083,
      "f1": 0.7157464212678938
    },
    "прочее": {
      "accuracy": 0.3716588966588966,
      "precision": 0.5182926829268293,
      "recall": 0.4187192118226601,
      "f1": 0.4632152588555858
    }
  }
}