{
  "model_name": "google/gemma-2-2b-it",
  "timestamp": "20260121_001356",
  "analysis": "Отчет эксперта по оценке качества работы языковой модели\n\n**Модель:** google/gemma-2-2b-it\n**Гиперпараметры:** `max_new_tokens: 512`, `do_sample: false`, `torch_dtype: bfloat16`\n**Задача:** Извлечение численных и количественных характеристик из текстов о химических веществах и удобрениях в формате JSON.\n\n---\n\n### 1. Характерные ошибки модели\n\nМодель `gemma-2-2b-it` демонстрирует существенные проблемы в выполнении поставленной задачи, что отражается в низких метриках качества и примерах ошибок:\n\n1.  **Низкая точность извлечения \"Массовой доли\":** F1-мера 38.26% указывает на серьезные проблемы как с избыточным (низкий Precision), так и с недостаточным (низкий Recall) извлечением данных. Модель часто ошибается в определении точных значений, особенно границ диапазонов.\n2.  **Удовлетворительная, но требующая улучшения точность для \"Прочее\":** F1-мера 53.21% лучше, чем для массовой доли, но все еще недостаточна для надежного использования.\n3.  **Критические ошибки парсинга JSON:** Модель регулярно выдает невалидный или незавершенный JSON, что делает автоматическую обработку вывода невозможной без дополнительной пост-обработки.\n4.  **Ошибки в интерпретации диапазонов и логических операторов:** Модель некорректно обрабатывает конструкции типа \"от X до Y\" или \"не менее X\", часто ошибаясь в одной из границ или полностью игнорируя инструкцию по формату `[min, null]`.\n5.  **Галлюцинации данных:** Для группы \"прочее\" модель генерирует значения для параметров (например, \"количество мешков\", \"масса нетто единицы\"), которых нет в исходном тексте. Это крайне нежелательное поведение, так как приводит к появлению ложных данных.\n6.  **Пропуски сущностей:** Модель не всегда извлекает все присутствующие в тексте параметры, что подтверждается низким Recall и примерами (например, K2O).\n7.  **Неполное извлечение комплексных значений:** В случае \"марки\" модель извлекает только часть информации, игнорируя дополнительные детали в скобках.\n\n### 2. Причины ошибок парсинга JSON\n\nОсновной причиной ошибок парсинга JSON является **незавершенный вывод модели**.\n\nПример: `{ \"массовая доля\": [ ... ], \"прочее\": [ {\"параметр\": \"масса нетто ед`\n\nЗдесь вывод обрывается на середине названия параметра (`\"масса нетто ед`), что делает весь JSON невалидным. Это может происходить по нескольким причинам:\n\n*   **Ограничение `max_new_tokens`:** Наиболее вероятная причина. Установленный `max_new_tokens: 512` может быть недостаточен для генерации полного и сложного JSON-ответа, особенно при длинных входных текстах с большим количеством извлекаемых параметров. Модель просто \"исчерпывает\" доступные токены до того, как успевает закрыть все скобки и кавычки.\n*   **Внутренние сбои генерации:** Менее вероятно, но возможно, что модель прерывает генерацию из-за внутренних паттернов или достижения токена `<eos>` раньше времени.\n*   **Синтаксические неточности:** Хотя основной проблемой является обрыв, иногда модель может допускать мелкие синтаксические ошибки (пропуск запятых, некорректное использование `null`), что также делает JSON невалидным. В примере `{\"вещество\": \"K2O\", null}` — если `null` не ожидается для значения, это также будет проблемой, но синтаксически этот фрагмент корректен.\n\n### 3. Причины ошибок в извлечении данных\n\n**Группа \"массовая доля\":**\n\n*   **Ошибки в границах диапазона (`[min, max]`):** Модель систематически ошибается в определении нижней границы диапазона (например, предсказывает `[20.0, 21.0]` вместо `[19.0, 21.0]`).\n    *   **Причина:** Недостаточно точное понимание русского языка в контексте числовых диапазонов (\"от X до Y\", \"X-Y\"). Модель может \"округлять\" или игнорировать первое число, если оно менее выражено или кажется ей \"похожим\" на следующее целое. Это может быть связано с тем, что модель пытается вывести, а не просто извлечь.\n*   **Несоблюдение инструкций для операторов (`[min, null]`):** Модель предсказывает `[2.0, 3.0]` вместо `[2.0, None]` для \"не менее\".\n    *   **Причина:** Прямое игнорирование четкого указания в промпте. Модель либо не придает достаточного веса этой инструкции, либо не может связать ее с конкретной языковой конструкцией в тексте.\n*   **Пропуск сущностей:** Модель полностью пропускает извлечение некоторых массовых долей.\n    *   **Причина:** Низкий Recall модели, возможно, из-за недостаточной обученности на подобных паттернах или общего \"слабого\" внимания к деталям в тексте.\n\n**Группа \"прочее\":**\n\n*   **Неполное извлечение значения (например, \"марка\"):** Модель извлекает \"npks-8\", но игнорирует \"(npk 8:20:30)\".\n    *   **Причина:** Модель может не понимать, что дополнительные детали в скобках являются неотъемлемой частью \"марки\". Она может воспринимать их как отдельные, менее значимые данные.\n*   **Галлюцинации/избыточное извлечение:** Модель генерирует значения для параметров (\"количество мешков\", \"масса нетто единицы\" и т.д.), которых нет в тексте.\n    *   **Причина:** Это одна из самых серьезных проблем. Модель, вероятно, пытается \"заполнить\" ожидаемые ею поля в JSON-структуре, даже если в тексте нет никаких упоминаний. Это может быть результатом:\n        *   **Переобучения на ожидаемой схеме:** Если в тренировочных данных эти поля часто присутствуют, модель учится их \"выводить\", даже если их нет в текущем вводе.\n        *   **Недостаточное понимание инструкции:** Модель не усвоила правило \"извлекай только то, что явно указано\".\n\n### 4. Рекомендации по улучшению промпта\n\nПромпт достаточно подробен, но его можно усилить для решения выявленных проблем:\n\n1.  **Усиление требования к валидному JSON:**\n    *   \"**Крайне важно:** Ответ должен быть представлен **строго** в формате JSON, **полностью завершенным** и **абсолютно валидным**. Не обрывай JSON на середине. Если какой-либо раздел (`массовая_доля` или `прочее`) пуст, используй пустой список `[]`.\"\n    *   **Добавить пример полной JSON-структуры** в промпт, чтобы модель видела, как должен выглядеть конечный результат, включая пустые списки.\n2.  **Детализация обработки диапазонов и операторов:**\n    *   \"Будь предельно точен при извлечении диапазонов: `от X до Y` или `X-Y` всегда должны быть `[X, Y]`. Для операторов: `не менее X` строго `[X, null]`, `не более Y` строго `[null, Y]`.\"\n    *   **Включить в примеры (few-shot) все эти случаи.**\n3.  **Явное предотвращение галлюцинаций:**\n    *   \"**Извлекай только те численные признаки и их значения, которые явно и конкретно указаны в предоставленном тексте.** **НИКОГДА НЕ ГЕНЕРИРУЙ** значения для признаков, если они отсутствуют в тексте. Если признака нет, он не должен быть включен в JSON-ответ (или соответствующий список должен быть пустым).\"\n    *   \"Например, если в тексте нет информации о 'массе брутто', не включай этот параметр в ответ.\"\n4.  **Уточнение извлечения комплексных значений (например, \"марки\"):**\n    *   \"Для параметра 'марка' извлекай **полностью всю информацию**, которая к ней относится, включая любые детали, указанные в скобках или в непосредственной близости.\"\n5.  **Стандартизация ключей в JSON (опционально, но рекомендуется):**\n    *   Текущая структура `\"массовая доля\": [{\"вещество\": \"N\", \"массовая доля\": [33, 35]}]` имеет дублирующийся ключ \"массовая доля\", что может быть запутывающим. Рекомендуется использовать единый шаблон для всех извлекаемых объектов:\n        ```json\n        {\n          \"массовая_доля\": [\n            {\"название\": \"массовая доля N\", \"значение\": [33, 35], \"единица_измерения\": \"%\"},\n            {\"название\": \"массовая доля P2O5\", \"значение\": 3, \"единица_измерения\": \"%\"}\n          ],\n          \"прочее\": [\n            {\"название\": \"стандарт\", \"значение\": \"ГОСТ 12345-67\", \"единица_измерения\": \"\"},\n            {\"название\": \"масса нетто единицы\", \"значение\": 50, \"единица_измерения\": \"кг\"}\n          ]\n        }\n        ```\n    *   Это сделает структуру более предсказуемой и, возможно, облегчит модели ее генерацию.\n\n### 5. Рекомендации по настройке гиперпараметров\n\n1.  **`max_new_tokens`:**\n    *   **Рекомендация:** Увеличить как минимум до `1024` или `2048`. Основная причина обрыва JSON — это, скорее всего, исчерпание токенов. Необходимо дать модели достаточное пространство для полного завершения ответа.\n2.  **`do_sample`:**\n    *   `do_sample: false` (greedy decoding) хорошо для детерминированных и предсказуемых ответов. Однако в случае галлюцинаций или \"застревания\" модели в неверных, но высоковероятных паттернах, это может быть проблемой.\n    *   **Рекомендация:** Протестировать `do_sample: true` с очень низкой `temperature` (например, `0.1` или `0.2`) и `top_p` (например, `0.9`). Это может дать модели достаточно \"креативности\", чтобы выйти из паттернов галлюцинаций или лучше интерпретировать сложные языковые конструкции, но при этом сохранить достаточную предсказуемость.\n3.  **`torch_dtype`:**\n    *   `bfloat16` обычно является хорошим выбором для производительности и не является причиной текущих проблем. **Изменений не требуется.**\n\n### 6. Общие рекомендации по улучшению качества\n\n1.  **Few-shot Learning (Примеры в промпте):** Это самый эффективный шаг после доработки промпта. Включите 1-3 полных, высококачественных примера \"входной текст -> идеальный JSON-вывод\" в промпт. Примеры должны охватывать:\n    *   Различные типы диапазонов и операторов (`[X,Y]`, `[X, null]`, `[null, Y]`).\n    *   Случаи, когда некоторые поля отсутствуют, и соответствующие списки пусты `[]` (для предотвращения галлюцинаций).\n    *   Сложные \"марки\" с дополнительными деталями.\n    *   Полный набор извлекаемых единиц измерения.\n    *   Обязательно используйте ту самую JSON-структуру, которую вы хотите получить.\n2.  **Файн-тюнинг (Fine-tuning) модели:** Если few-shot learning не дает достаточного улучшения, то создание специализированного датасета и тонкая настройка модели на нем будет следующим шагом. Это позволит модели глубоко усвоить специфику предметной области, правила извлечения и требуемый формат JSON.\n3.  **Пост-обработка вывода:** Внедрить логику пост-обработки для исправления распространенных ошибок:\n    *   **Валидация и \"починка\" JSON:** Попытка закрыть незавершенные JSON-структуры, удалить невалидные элементы.\n    *   **Валидация данных:** Проверка типов данных (например, что значение — число или список из двух чисел), корректность единиц измерения.\n    *   **Фильтрация галлюцинаций:** Удаление извлеченных параметров, которые не должны были быть сгенерированы (например, если они не встречаются в исходном тексте).\n4.  **Использование более мощных моделей:** `gemma-2-2b-it` — относительно небольшая модель. Более крупные модели (например, Gemma 7B, Llama 3 8B, Mistral 7B) часто показывают значительно лучшую производительность в задачах извлечения информации и следования инструкциям, особенно с комплексным JSON-выводом. Возможно, стоит рассмотреть переход на более мощную архитектуру, если другие методы не дадут желаемого результата.\n5.  **Тестирование и итерации:** После каждого изменения (промпт, гиперпараметры, файн-тюнинг) необходимо проводить повторное тестирование и анализировать новые ошибки для дальнейших улучшений.",
  "model_used": "gemini-2.5-flash",
  "parsing_errors_count": 1,
  "hyperparameters": {
    "max_new_tokens": 512,
    "do_sample": false,
    "torch_dtype": "bfloat16"
  },
  "system_info": {
    "api_model": false,
    "multi_agent_mode": null,
    "gpu_info": {
      "cuda_available": true,
      "cuda_version": "12.1",
      "gpu_name": "NVIDIA GeForce RTX 4060 Laptop GPU",
      "gpu_memory_total_gb": 8.0,
      "gpu_memory_allocated_gb": 0.0,
      "gpu_memory_reserved_gb": 0.0,
      "gpu_name_detailed": "NVIDIA GeForce RTX 4060 Laptop GPU",
      "driver_version": "591.74"
    },
    "gpu_memory_during_inference_gb": 4.88,
    "average_response_time_seconds": 18.232749025821686
  },
  "quality_metrics_summary": {
    "массовая доля": {
      "accuracy": 0.20086291486291485,
      "precision": 0.29924242424242425,
      "recall": 0.5302013422818792,
      "f1": 0.3825665859564164
    },
    "прочее": {
      "accuracy": 0.45124564190829247,
      "precision": 0.49122807017543857,
      "recall": 0.5803108808290155,
      "f1": 0.5320665083135391
    }
  }
}