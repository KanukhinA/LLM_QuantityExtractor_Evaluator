"""
–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–µ–π LLM
"""
import torch
import gc
import time
import logging
import pandas as pd
import json
import copy
import glob
from datetime import datetime
from typing import Dict, Any, List, Optional, Callable
import os

from utils import build_prompt3, parse_json_safe, is_valid_json, extract_json_from_response
from structured_schemas import latin_to_cyrillic_output, LATIN_TO_CYRILLIC_KEYS
from metrics import calculate_quality_metrics, validate_with_pydantic, calculate_raw_output_metrics
from gpu_info import get_gpu_info, get_gpu_memory_usage
from multi_agent_graph import process_with_multi_agent
from config import PROMPT_TEMPLATE_NAME, MAX_INFERENCE_TIME_MINUTES
from metrics_printer import MetricsPrinter
from file_manager import FileManager
import re


try:
    from gemini_analyzer import analyze_errors_with_gemini
except ImportError:
    analyze_errors_with_gemini = None


class InferenceCriticalFailure(Exception):
    """–í—ã–±—Ä–∞—Å—ã–≤–∞–µ—Ç—Å—è –ø—Ä–∏ –∏—Å—á–µ—Ä–ø–∞–Ω–∏–∏ –≤—Å–µ—Ö –ø–æ–ø—ã—Ç–æ–∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–∞ –æ–¥–Ω–æ–º –ø—Ä–∏–º–µ—Ä–µ; –æ—Ü–µ–Ω–∫—É –º–æ–¥–µ–ª–∏ –∑–∞–≤–µ—Ä—à–∞–µ–º –¥–æ—Å—Ä–æ—á–Ω–æ."""
    def __init__(self, message: str, text_index: int, num_retries: int):
        self.message = message
        self.text_index = text_index
        self.num_retries = num_retries
        super().__init__(message)


class StopAllModelsInterrupt(Exception):
    """–í—ã–±—Ä–∞—Å—ã–≤–∞–µ—Ç—Å—è –ø—Ä–∏ –≤—ã–±–æ—Ä–µ –ø—É–Ω–∫—Ç–∞ 4 (–ø—Ä–µ—Ä–≤–∞—Ç—å –æ—Ü–µ–Ω–∫—É –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π); –¥–æ–ª–∂–Ω–∞ –ø–æ–π–º–∞—Ç—å run_all_models –∏ –≤—ã–π—Ç–∏ –∏–∑ —Ü–∏–∫–ª–∞ –ø–æ –º–æ–¥–µ–ª—è–º."""
    pass


class ModelEvaluator:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –æ—Ü–µ–Ω–∫–∏ LLM –º–æ–¥–µ–ª–µ–π –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ
    """
    
    def __init__(self, 
                 dataset_path: str,
                 ground_truth_path: Optional[str] = None,
                 output_dir: str = "results"):
        """
        Args:
            dataset_path: –ø—É—Ç—å –∫ –¥–∞—Ç–∞—Å–µ—Ç—É (Excel —Ñ–∞–π–ª)
            ground_truth_path: –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –∏—Å—Ç–∏–Ω–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            output_dir: –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        """
        self.dataset_path = dataset_path
        self.ground_truth_path = ground_truth_path
        self.output_dir = output_dir
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        # –°–æ–∑–¥–∞–µ–º FileManager –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ñ–∞–π–ª–∞–º–∏
        self.file_manager = FileManager()
        self.file_manager.ensure_directory(output_dir)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç
        print(f"üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏–∑: {dataset_path}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ –ø–µ—Ä–µ–¥ –∑–∞–≥—Ä—É–∑–∫–æ–π
        if not os.path.exists(dataset_path):
            abs_path = os.path.abspath(dataset_path)
            current_dir = os.getcwd()
            error_msg = (
                f"‚ùå –û—à–∏–±–∫–∞: —Ñ–∞–π–ª –¥–∞—Ç–∞—Å–µ—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω!\n"
                f"   –ü—É—Ç—å: {dataset_path}\n"
                f"   –ê–±—Å–æ–ª—é—Ç–Ω—ã–π –ø—É—Ç—å: {abs_path}\n"
                f"   –¢–µ–∫—É—â–∞—è —Ä–∞–±–æ—á–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {current_dir}\n"
                f"   –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏ –ø—É—Ç—å —É–∫–∞–∑–∞–Ω –ø—Ä–∞–≤–∏–ª—å–Ω–æ."
            )
            raise FileNotFoundError(error_msg)
        
        self.df_full = pd.read_excel(dataset_path)
        print(f"   ‚úÖ –î–∞—Ç–∞—Å–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω: {len(self.df_full)} —Å—Ç—Ä–æ–∫, {len(self.df_full.columns)} –∫–æ–ª–æ–Ω–æ–∫")
        print(f"   üìã –ö–æ–ª–æ–Ω–∫–∏: {', '.join(self.df_full.columns.tolist()[:5])}{'...' if len(self.df_full.columns) > 5 else ''}")
        
        # –£–¥–∞–ª—è–µ–º –∫–æ–ª–æ–Ω–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –Ω—É–∂–Ω—ã –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤
        self.df = self.df_full.drop(["json", "Unnamed: 0"], axis=1, errors='ignore')
        self.texts = self.df["text"].tolist()
        print(f"   ‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(self.texts)} —Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏\n")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º ground truth –∏–∑ —Ç–æ–≥–æ –∂–µ —Ñ–∞–π–ª–∞ (–∫–æ–ª–æ–Ω–∫–∞ json_parsed)
        self.ground_truths = None
        if "json_parsed" in self.df_full.columns:
            try:
                # json_parsed —É–∂–µ —è–≤–ª—è–µ—Ç—Å—è —Å–ª–æ–≤–∞—Ä–µ–º, –Ω–æ –º–æ–∂–µ—Ç –±—ã—Ç—å —Å—Ç—Ä–æ–∫–æ–π
                self.ground_truths = []
                for j in self.df_full["json_parsed"]:
                    if isinstance(j, dict):
                        self.ground_truths.append(j)
                    elif isinstance(j, str):
                        self.ground_truths.append(parse_json_safe(j))
                    else:
                        self.ground_truths.append({})
                non_empty = sum(1 for gt in self.ground_truths if gt)
                print(f"   ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.ground_truths)} ground truth –∑–Ω–∞—á–µ–Ω–∏–π –∏–∑ –∫–æ–ª–æ–Ω–∫–∏ json_parsed")
                print(f"      (–ù–µ–ø—É—Å—Ç—ã—Ö: {non_empty}, –ü—É—Å—Ç—ã—Ö: {len(self.ground_truths) - non_empty})\n")
            except Exception as e:
                print(f"   ‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å ground truth –∏–∑ json_parsed: {e}\n")
        elif ground_truth_path and os.path.exists(ground_truth_path):
            # Fallback: –∑–∞–≥—Ä—É–∑–∫–∞ –∏–∑ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ (—Å—Ç–∞—Ä—ã–π —Å–ø–æ—Å–æ–±)
            try:
                print(f"   üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ ground truth –∏–∑ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞: {ground_truth_path}")
                gt_df = pd.read_excel(ground_truth_path)
                if "json" in gt_df.columns:
                    self.ground_truths = [parse_json_safe(str(j)) for j in gt_df["json"]]
                    print(f"   ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.ground_truths)} ground truth –∑–Ω–∞—á–µ–Ω–∏–π –∏–∑ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞\n")
            except Exception as e:
                print(f"   ‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å ground truth: {e}\n")
        else:
            print(f"   ‚ö†Ô∏è Ground truth –Ω–µ –Ω–∞–π–¥–µ–Ω (–∫–æ–ª–æ–Ω–∫–∞ json_parsed –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç)\n")
    
    def clear_memory(self):
        """–û—á–∏—Å—Ç–∫–∞ GPU –ø–∞–º—è—Ç–∏"""
        print("‚ôªÔ∏è –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ PyTorch...")
        global model, tokenizer
        try:
            del model
        except NameError:
            pass
        try:
            del tokenizer
        except NameError:
            pass
        gc.collect()
        torch.cuda.empty_cache()
        print("‚úÖ –ü–∞–º—è—Ç—å –æ—á–∏—â–µ–Ω–∞")
    
    def _generate_response_with_retries(self, 
                                       model, tokenizer, prompt, generate_func,
                                       hyperparameters, max_new_tokens, num_retries,
                                       is_api_model, verbose, text_index, total_texts, text,
                                       times, memory_samples, parsing_errors):
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏ —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö.
        
        Args:
            text: –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç (–¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –æ—à–∏–±–∫–∞—Ö)
        
        Returns:
            tuple: (response_text, elapsed_time, error_msg) –∏–ª–∏ (None, 0, error_msg) –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        response_text = ""
        error_msg = None
        
        for attempt in range(num_retries):
            try:
                start_time = time.time()
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è structured output –∏ outlines
                structured_output = hyperparameters.get("structured_output", False)
                use_outlines = hyperparameters.get("use_outlines", False)
                response_schema = None
                # response_schema: –¥–ª—è outlines (–ª–æ–∫–∞–ª—å–Ω—ã–µ) - Latin (—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–æ–º); –¥–ª—è API/–±–µ–∑ outlines - Cyrillic alias
                if use_outlines or structured_output:
                    from structured_schemas import FertilizerExtractionOutput, FertilizerExtractionOutputLatin
                    response_schema = FertilizerExtractionOutputLatin if (use_outlines and not is_api_model) else FertilizerExtractionOutput
                
                # –ü–µ—Ä–µ–¥–∞–µ–º repetition_penalty –∏–∑ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –µ—Å–ª–∏ –µ—Å—Ç—å
                repetition_penalty = hyperparameters.get("repetition_penalty")
                
                # –î–ª—è API –º–æ–¥–µ–ª–µ–π –ø–µ—Ä–µ–¥–∞–µ–º model_name –∏ structured_output –∏–∑ hyperparameters
                if is_api_model and "model_name" in hyperparameters:
                    response_text = generate_func(
                        model, tokenizer, prompt, max_new_tokens, 
                        model_name=hyperparameters["model_name"],
                        structured_output=structured_output,
                        response_schema=response_schema
                    )
                # –î–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π —Å outlines (response_schema –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è outlines; structured_output –¥–æ–±–∞–≤–ª—è–µ—Ç —Å—Ö–µ–º—É –≤ –ø—Ä–æ–º–ø—Ç)
                elif use_outlines and not is_api_model and response_schema is not None:
                    response_text = generate_func(
                        model, tokenizer, prompt, max_new_tokens,
                        structured_output=structured_output,
                        response_schema=response_schema,
                        use_outlines=True
                    )
                # –î–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π —Å structured_output (–±–µ–∑ outlines)
                elif structured_output and not is_api_model and response_schema is not None:
                    response_text = generate_func(
                        model, tokenizer, prompt, max_new_tokens,
                        structured_output=structured_output,
                        response_schema=response_schema,
                        use_outlines=False
                    )
                elif repetition_penalty is not None:
                    response_text = generate_func(model, tokenizer, prompt, max_new_tokens, repetition_penalty=repetition_penalty)
                elif "enable_thinking" in hyperparameters:
                    # –î–ª—è Qwen3 –ø–µ—Ä–µ–¥–∞–µ–º enable_thinking –∏–∑ hyperparameters (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é False)
                    enable_thinking_value = hyperparameters.get("enable_thinking", False)
                    response_text = generate_func(model, tokenizer, prompt, max_new_tokens, enable_thinking=enable_thinking_value)
                else:
                    response_text = generate_func(model, tokenizer, prompt, max_new_tokens)
                elapsed = time.time() - start_time
                times.append(elapsed)
                
                # –ò–∑–º–µ—Ä—è–µ–º –ø–∞–º—è—Ç—å –≤–æ –≤—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ (—Ç–æ–ª—å–∫–æ –¥–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π; –¥–ª—è API/Ollama is_api_model=True)
                if not is_api_model:
                    memory_sample = get_gpu_memory_usage()
                    memory_samples.append(memory_sample["allocated"])
                
                return response_text, elapsed, None
                
            except KeyboardInterrupt:
                # –ü—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ–º KeyboardInterrupt –Ω–∞–≤–µ—Ä—Ö –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Ü–∏–∫–ª–µ
                raise
            except Exception as e:
                error_msg = str(e)
                # –î–ª—è API –∏ Ollama –≤—ã–≤–æ–¥–∏–º –ø–æ–ª–Ω—É—é –æ—à–∏–±–∫—É –±–µ–∑ –æ–±—Ä–µ–∑–∫–∏ (is_api_model —Å—é–¥–∞ –ø–µ—Ä–µ–¥–∞—ë—Ç—Å—è –∫–∞–∫ is_api_model or is_ollama)
                if is_api_model:
                    print(f"  ‚ö†Ô∏è –û—Ç–≤–µ—Ç #{text_index+1}/{total_texts} - –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (–ø–æ–ø—ã—Ç–∫–∞ {attempt+1}/{num_retries}):")
                    print(f"     {error_msg}")
                else:
                    # –î–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –æ–±—Ä–µ–∑–∞–µ–º –ø—Ä–∏ –Ω–µ verbose —Ä–µ–∂–∏–º–µ
                    error_display = error_msg if verbose else error_msg[:100]
                    print(f"  ‚ö†Ô∏è –û—Ç–≤–µ—Ç #{text_index+1}/{total_texts} - –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (–ø–æ–ø—ã—Ç–∫–∞ {attempt+1}/{num_retries}): {error_display}")
                if attempt < num_retries - 1:
                    time.sleep(4 + attempt * 2)
                else:
                    # –ï—Å–ª–∏ –≤—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã ‚Äî –¥–æ—Å—Ä–æ—á–Ω–æ –∑–∞–≤–µ—Ä—à–∞–µ–º –æ—Ü–µ–Ω–∫—É —ç—Ç–æ–π –º–æ–¥–µ–ª–∏
                    import traceback
                    traceback_str = traceback.format_exc()
                    traceback_display = traceback_str if is_api_model else traceback_str[:200]
                    parsing_errors.append({
                        "text_index": text_index,
                        "text": text,
                        "error": f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ—Å–ª–µ {num_retries} –ø–æ–ø—ã—Ç–æ–∫: {error_msg}. Traceback: {traceback_display}",
                        "response": ""
                    })
                    raise InferenceCriticalFailure(error_msg, text_index, num_retries)
        
        return None, 0, error_msg
    
    def _print_verbose_output(self, text, response_text, is_api_model, text_index, total_texts):
        """–í—ã–≤–æ–¥–∏—Ç –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç –∏ –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç –≤ –∫–æ–Ω—Å–æ–ª—å (—Ç–æ–ª—å–∫–æ –ø—Ä–∏ verbose)"""
        print(f"\n   –û—Ç–≤–µ—Ç #{text_index + 1}/{total_texts} - –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:")
        print(f"   {'-'*76}")
        for line in text.split('\n'):
            print(f"   {line}")
        print(f"   {'-'*76}")
        model_type_label = "API –º–æ–¥–µ–ª–∏" if is_api_model else "–º–æ–¥–µ–ª–∏"
        print(f"   –û—Ç–≤–µ—Ç #{text_index + 1}/{total_texts} - –ü–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç {model_type_label}:")
        print(f"   {'-'*76}")
        for line in response_text.split('\n'):
            print(f"   {line}")
        print(f"   {'-'*76}")
        # –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∞—Ç–∏–Ω—Å–∫–∏–µ –∫–ª—é—á–∏ (mass_fractions, other_params), –≤—ã–≤–æ–¥–∏–º –≤–µ—Ä—Å–∏—é –Ω–∞ –∫–∏—Ä–∏–ª–ª–∏—Ü–µ
        try:
            json_part = extract_json_from_response(response_text)
            parsed = parse_json_safe(json_part)
            if parsed and isinstance(parsed, dict) and any(k in LATIN_TO_CYRILLIC_KEYS for k in parsed):
                converted = latin_to_cyrillic_output(parsed)
                cyrillic_str = json.dumps(converted, ensure_ascii=False, indent=2)
                print(f"   –í–µ—Ä—Å–∏—è –Ω–∞ –∫–∏—Ä–∏–ª–ª–∏—Ü–µ:")
                print(f"   {'-'*76}")
                for line in cyrillic_str.split('\n'):
                    print(f"   {line}")
                print(f"   {'-'*76}")
        except Exception:
            pass
    
    def _clean_parsed_json(self, parsed_json):
        """
        –£–¥–∞–ª—è–µ—Ç –∏–∑ parsed_json –∑–∞–ø–∏—Å–∏ —Å None –∏–ª–∏ [None, None] –∑–Ω–∞—á–µ–Ω–∏—è–º–∏.
        –¢–∞–∫–∏–µ –∑–∞–ø–∏—Å–∏ –±–µ—Å—Å–º—ã—Å–ª–µ–Ω–Ω—ã –∏ –∑–∞–Ω–∏–∂–∞—é—Ç F1-–º–µ—Ç—Ä–∏–∫—É.
        
        Args:
            parsed_json: —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–π JSON —Å–ª–æ–≤–∞—Ä—å
            
        Returns:
            dict: –æ—á–∏—â–µ–Ω–Ω—ã–π JSON —Å–ª–æ–≤–∞—Ä—å
        """
        if not isinstance(parsed_json, dict):
            return parsed_json
        
        cleaned = {}
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º "–º–∞—Å—Å–æ–≤–∞—è –¥–æ–ª—è"
        if "–º–∞—Å—Å–æ–≤–∞—è –¥–æ–ª—è" in parsed_json:
            mass_fractions = parsed_json["–º–∞—Å—Å–æ–≤–∞—è –¥–æ–ª—è"]
            if isinstance(mass_fractions, list):
                cleaned_mass = []
                for item in mass_fractions:
                    if isinstance(item, dict):
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ "–º–∞—Å—Å–æ–≤–∞—è –¥–æ–ª—è"
                        mass_value = item.get("–º–∞—Å—Å–æ–≤–∞—è –¥–æ–ª—è")
                        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–ø–∏—Å–∏ —Å None
                        if mass_value is None:
                            continue
                        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º [None, None]
                        if isinstance(mass_value, list) and len(mass_value) == 2:
                            if mass_value[0] is None and mass_value[1] is None:
                                continue
                        # –ï—Å–ª–∏ –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è None, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                        if isinstance(mass_value, list) and all(v is None for v in mass_value):
                            continue
                        cleaned_mass.append(item)
                    else:
                        # –ï—Å–ª–∏ —ç—Ç–æ –Ω–µ —Å–ª–æ–≤–∞—Ä—å, –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
                        cleaned_mass.append(item)
                cleaned["–º–∞—Å—Å–æ–≤–∞—è –¥–æ–ª—è"] = cleaned_mass
            else:
                cleaned["–º–∞—Å—Å–æ–≤–∞—è –¥–æ–ª—è"] = mass_fractions
        else:
            # –ï—Å–ª–∏ –∫–ª—é—á–∞ –Ω–µ—Ç, –Ω–µ –¥–æ–±–∞–≤–ª—è–µ–º –µ–≥–æ
            pass
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º "–ø—Ä–æ—á–µ–µ"
        if "–ø—Ä–æ—á–µ–µ" in parsed_json:
            other_params = parsed_json["–ø—Ä–æ—á–µ–µ"]
            if isinstance(other_params, list):
                cleaned_other = []
                for item in other_params:
                    if isinstance(item, dict):
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ —Å–ª–æ–≤–∞—Ä–µ
                        has_valid_value = False
                        for key, value in item.items():
                            if value is None:
                                continue
                            if isinstance(value, list):
                                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ø–∏—Å–∫–∏ –∏–∑ None
                                if all(v is None for v in value):
                                    continue
                                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º [None, None]
                                if len(value) == 2 and value[0] is None and value[1] is None:
                                    continue
                            # –ï—Å–ª–∏ –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ –Ω–µ–ø—É—Å—Ç–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ, –æ—Å—Ç–∞–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å
                            if value is not None and value != "":
                                has_valid_value = True
                                break
                        if has_valid_value:
                            cleaned_other.append(item)
                    else:
                        # –ï—Å–ª–∏ —ç—Ç–æ –Ω–µ —Å–ª–æ–≤–∞—Ä—å, –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
                        cleaned_other.append(item)
                cleaned["–ø—Ä–æ—á–µ–µ"] = cleaned_other
            else:
                cleaned["–ø—Ä–æ—á–µ–µ"] = other_params
        else:
            # –ï—Å–ª–∏ –∫–ª—é—á–∞ –Ω–µ—Ç, –Ω–µ –¥–æ–±–∞–≤–ª—è–µ–º –µ–≥–æ
            pass
        
        # –ö–æ–ø–∏—Ä—É–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –∫–ª—é—á–∏, –µ—Å–ª–∏ –µ—Å—Ç—å
        for key in parsed_json:
            if key not in ["–º–∞—Å—Å–æ–≤–∞—è –¥–æ–ª—è", "–ø—Ä–æ—á–µ–µ"]:
                cleaned[key] = parsed_json[key]
        
        return cleaned
    
    def _process_response(self, response_text, text, text_index, is_api_model, verbose, parsing_errors):
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏: –≤–∞–ª–∏–¥–∞—Ü–∏—è, –ø–∞—Ä—Å–∏–Ω–≥ JSON, –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö.
        
        Returns:
            dict: —Å–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        # –í–∞–ª–∏–¥–∞—Ü–∏—è raw output —á–µ—Ä–µ–∑ Pydantic (—ç—Ç–∞–ø 1)
        raw_validation = validate_with_pydantic(response_text, stage="raw")
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º JSON
        json_part = extract_json_from_response(response_text)
        parsed_json = parse_json_safe(json_part)
        is_valid = is_valid_json(json_part)
        # –ï—Å–ª–∏ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–π JSON —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∞—Ç–∏–Ω—Å–∫–∏–µ –∫–ª—é—á–∏ (mass_fractions, other_params), –ø—Ä–∏–≤–æ–¥–∏–º –∫ –∫–∏—Ä–∏–ª–ª–∏—Ü–µ
        if parsed_json and isinstance(parsed_json, dict) and any(k in LATIN_TO_CYRILLIC_KEYS for k in parsed_json):
            parsed_json = latin_to_cyrillic_output(parsed_json)
            try:
                json_part = json.dumps(parsed_json, ensure_ascii=False, indent=2)
            except Exception:
                pass
        # –û—á–∏—â–∞–µ–º parsed_json –æ—Ç –∑–∞–ø–∏—Å–µ–π —Å None –∏–ª–∏ [None, None]
        if parsed_json and isinstance(parsed_json, dict):
            parsed_json = self._clean_parsed_json(parsed_json)
            # –û–±–Ω–æ–≤–ª—è–µ–º json_part –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏
            try:
                json_part = json.dumps(parsed_json, ensure_ascii=False, indent=2)
            except Exception:
                pass  # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞—Ç—å, –æ—Å—Ç–∞–≤–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π json_part
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –ø–æ—Å–ª–µ –ø–∞—Ä—Å–∏–Ω–≥–∞ —á–µ—Ä–µ–∑ Pydantic (—ç—Ç–∞–ø 2)
        parsed_validation = validate_with_pydantic(parsed_json, stage="parsed")
        
        if not is_valid:
            # –î–ª—è API –º–æ–¥–µ–ª–µ–π –ø—Ä–∏ verbose –≤—ã–≤–æ–¥–∏–º –ø–æ–ª–Ω—ã–π JSON, –∏–Ω–∞—á–µ –æ–±—Ä–µ–∑–∞–µ–º
            json_display = json_part if (is_api_model and verbose) else (json_part[:200] if len(json_part) > 200 else json_part)
            parsing_errors.append({
                "text_index": text_index,
                "text": text,
                "error": f"–ù–µ–≤–∞–ª–∏–¥–Ω—ã–π JSON. –û—Ç–≤–µ—Ç: {json_display}",
                "response": json_part[:500]
            })
        
        return {
            "text": text,
            "json": json_part,
            "json_parsed": parsed_json,
            "is_valid": is_valid,
            "raw_output": response_text,  # –°–æ—Ö—Ä–∞–Ω—è–µ–º raw output –¥–ª—è –º–µ—Ç—Ä–∏–∫
            "raw_validation": raw_validation,  # –†–µ–∑—É–ª—å—Ç–∞—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏ raw output
            "parsed_validation": parsed_validation  # –†–µ–∑—É–ª—å—Ç–∞—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –ø–æ—Å–ª–µ –ø–∞—Ä—Å–∏–Ω–≥–∞
        }
    
    def _handle_no_response(self, text, text_index, total_texts, error_msg, is_api_model, verbose, parsing_errors):
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å–ª—É—á–∞–π, –∫–æ–≥–¥–∞ –æ—Ç–≤–µ—Ç –Ω–µ –±—ã–ª –ø–æ–ª—É—á–µ–Ω.
        
        Returns:
            dict: —Å–ª–æ–≤–∞—Ä—å —Å –ø—É—Å—Ç—ã–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º
        """
        print(f"  ‚ùå –û—Ç–≤–µ—Ç #{text_index+1}/{total_texts} - –û—Ç–≤–µ—Ç –Ω–µ –ø–æ–ª—É—á–µ–Ω ‚Äî –ø—Ä–æ–ø—É—Å–∫")
        if error_msg:
            # –î–ª—è API –º–æ–¥–µ–ª–µ–π –≤—ã–≤–æ–¥–∏–º –ø–æ–ª–Ω—É—é –æ—à–∏–±–∫—É –±–µ–∑ –æ–±—Ä–µ–∑–∫–∏ (–≤—Å–µ–≥–¥–∞, —Ç–∞–∫ –∫–∞–∫ —ç—Ç–æ –æ—à–∏–±–∫–∞)
            if is_api_model:
                print(f"     –ü–æ—Å–ª–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞: {error_msg}")
            else:
                # –î–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –æ–±—Ä–µ–∑–∞–µ–º –ø—Ä–∏ –Ω–µ verbose —Ä–µ–∂–∏–º–µ
                error_display = error_msg if verbose else error_msg[:200]
                print(f"     –ü–æ—Å–ª–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞: {error_display}")
        parsing_errors.append(f"–¢–µ–∫—Å—Ç #{text_index}: –Ω–µ –ø–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç. –û—à–∏–±–∫–∞: {error_msg if error_msg else '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞'}")
        return {
            "text": text,
            "json": "",
            "json_parsed": {},
            "is_valid": False
        }
    
    def _print_progress(self, i, total_texts, results, times, total_start_time, verbose):
        """–í—ã–≤–æ–¥–∏—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        elapsed_total = time.time() - total_start_time
        avg_time = sum(times) / len(times) if times else 0
        progress_pct = ((i + 1) / total_texts) * 100
        remaining = total_texts - (i + 1)
        eta_seconds = avg_time * remaining if avg_time > 0 else 0
        eta_minutes = eta_seconds / 60
        
        valid_count = sum(1 for r in results if r["is_valid"])
        invalid_count = (i + 1) - valid_count
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –≤—Ä–µ–º—è
        if eta_minutes < 1:
            eta_str = f"{eta_seconds:.0f} —Å–µ–∫"
        else:
            eta_str = f"{eta_minutes:.1f} –º–∏–Ω"
        
        # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç—É—Å –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç verbose)
        if verbose:
            # –ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥ –ø—Ä–∏ verbose=True
            status_line = (
                f"  ‚úÖ –û—Ç–≤–µ—Ç #{i + 1}/{total_texts} –æ–±—Ä–∞–±–æ—Ç–∞–Ω ({progress_pct:.1f}%) | "
                f"–í–∞–ª–∏–¥–Ω—ã—Ö: {valid_count} | –ù–µ–≤–∞–ª–∏–¥–Ω—ã—Ö: {invalid_count} | "
                f"ETA: {eta_str}"
            )
            print(status_line)
        else:
            # –ö–æ—Ä–æ—Ç–∫–∏–π –≤—ã–≤–æ–¥ –ø—Ä–∏ verbose=False (—Ç–æ–ª—å–∫–æ —Å—á–µ—Ç—á–∏–∫ –∏ –æ—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏)
            status_line = (
                f"  –û—Ç–≤–µ—Ç #{i + 1}/{total_texts} | "
                f"‚úì: {valid_count} ‚úó: {invalid_count} | "
                f"ETA: {eta_str}"
            )
            print(f"\r{status_line}", end="", flush=True)
        
        # –ü–æ–¥—Ä–æ–±–Ω—ã–π –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 10 —Ç–µ–∫—Å—Ç–æ–≤ –∏–ª–∏ –≤ –∫–æ–Ω—Ü–µ (—Ç–æ–ª—å–∫–æ –ø—Ä–∏ verbose)
        if verbose and ((i + 1) % 10 == 0 or (i + 1) == total_texts):
            print()  # –ù–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –¥–ª—è –ø–æ–¥—Ä–æ–±–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞
            print(f"     üìä –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
            print(f"        ‚Ä¢ –ü—Ä–æ–≥—Ä–µ—Å—Å: {progress_pct:.1f}% ({i + 1}/{total_texts})")
            print(f"        ‚Ä¢ –í–∞–ª–∏–¥–Ω—ã—Ö JSON: {valid_count} | –ù–µ–≤–∞–ª–∏–¥–Ω—ã—Ö: {invalid_count}")
            print(f"        ‚Ä¢ –°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å: {avg_time:.3f} —Å–µ–∫/–æ—Ç–≤–µ—Ç")
            print(f"        ‚Ä¢ –ü—Ä–æ—à–ª–æ –≤—Ä–µ–º–µ–Ω–∏: {elapsed_total/60:.1f} –º–∏–Ω | –û—Å—Ç–∞–ª–æ—Å—å: ~{eta_minutes:.1f} –º–∏–Ω")
            print()
    
    def evaluate_model(self,
                      model_name: str,
                      load_model_func: Callable,
                      generate_func: Callable,
                      hyperparameters: Dict[str, Any],
                      prompt_template: str = None,
                      max_new_tokens: int = 1024,
                      num_retries: int = 2,
                      verbose: bool = False,
                      use_gemini_analysis: bool = False,
                      gemini_api_key: str = None,
                      model_key: str = None,
                      stop_all_on_interrupt: bool = False) -> Dict[str, Any]:
        """
        –û—Ü–µ–Ω–∏–≤–∞–µ—Ç –º–æ–¥–µ–ª—å –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ
        
        Args:
            model_name: –Ω–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
            load_model_func: —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ (–¥–æ–ª–∂–Ω–∞ –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å (model, tokenizer))
            generate_func: —Ñ—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (model, tokenizer, prompt) -> response_text
            hyperparameters: —Å–ª–æ–≤–∞—Ä—å —Å –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ (–º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å multi_agent_mode)
            prompt_template: —à–∞–±–ª–æ–Ω –ø—Ä–æ–º–ø—Ç–∞ (–µ—Å–ª–∏ None, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è build_prompt3)
            max_new_tokens: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–≤—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤
            num_retries: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ –ø—Ä–∏ –æ—à–∏–±–∫–µ
        
        Returns:
            —Å–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –æ—Ü–µ–Ω–∫–∏
        """
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã –∏–∑ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        multi_agent_mode = hyperparameters.get("multi_agent_mode", None)
        use_multi_agent = multi_agent_mode is not None and multi_agent_mode != ""
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –º–æ–¥–µ–ª—å API-–º–æ–¥–µ–ª—å—é –∏–ª–∏ Ollama
        is_api_model = hyperparameters.get("api_model", False)
        is_ollama = hyperparameters.get("ollama", False)
        if not is_api_model and not is_ollama:
            pass  # –õ–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å —Å –≤–µ—Å–∞–º–∏
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º num_retries –¥–ª—è API –∏ Ollama (10 –ø–æ–ø—ã—Ç–æ–∫)
        if is_api_model or is_ollama:
            num_retries = 10
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ —Ä–µ–∂–∏–º–∞ –¥–ª—è –≤—ã–≤–æ–¥–∞
        if multi_agent_mode:
            mode_name = f"–ú—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω—ã–π ({multi_agent_mode})"
        else:
            mode_name = "–û–¥–Ω–æ–∞–≥–µ–Ω—Ç–Ω—ã–π"
        
        print(f"\n{'='*80}")
        print(f"üöÄ –ù–ê–ß–ê–õ–û –û–¶–ï–ù–ö–ò –ú–û–î–ï–õ–ò")
        print(f"{'='*80}")
        print(f"üìå –ú–æ–¥–µ–ª—å: {model_name}")
        print(f"üìå –î–∞—Ç–∞—Å–µ—Ç: {len(self.texts)} —Ç–µ–∫—Å—Ç–æ–≤")
        print(f"üìå –†–µ–∂–∏–º: {mode_name}")
        print(f"üìå –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã:")
        for key, value in hyperparameters.items():
            print(f"   ‚Ä¢ {key}: {value}")
        print(f"{'='*80}\n")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ API –∏–ª–∏ Ollama (–¥–æ –∑–∞–≥—Ä—É–∑–∫–∏)
        is_api_model = hyperparameters.get("api_model", False)
        is_ollama = hyperparameters.get("ollama", False)

        # –ú—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω—ã–π —Ä–µ–∂–∏–º –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –¥–ª—è Ollama
        if is_ollama and use_multi_agent:
            use_multi_agent = False
            multi_agent_mode = None
            print("   Ollama: –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω—ã–π —Ä–µ–∂–∏–º –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –æ–¥–Ω–æ–∞–≥–µ–Ω—Ç–Ω—ã–π.\n")

        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ GPU/API –¥–æ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏
        if is_api_model:
            print(f"üìä –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –†–ï–°–£–†–°–ê–•:")
            print(f"   ‚Ä¢ –¢–∏–ø: API (Google Generative AI)")
            print(f"   ‚Ä¢ –ú–æ–¥–µ–ª—å –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è —á–µ—Ä–µ–∑ API")
            print()
            gpu_info_before = {"api": True}
        elif is_ollama:
            print(f"üìä –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –†–ï–°–£–†–°–ê–•:")
            print(f"   ‚Ä¢ –¢–∏–ø: Ollama (–ª–æ–∫–∞–ª—å–Ω—ã–π API)")
            print()
            gpu_info_before = {"ollama": True}
        else:
            gpu_info_before = get_gpu_info()
            print(f"üìä –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û GPU (–¥–æ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏):")
            print(f"   ‚Ä¢ CUDA –¥–æ—Å—Ç—É–ø–Ω–∞: {gpu_info_before.get('cuda_available', False)}")
            if gpu_info_before.get('cuda_available'):
                print(f"   ‚Ä¢ –ù–∞–∑–≤–∞–Ω–∏–µ GPU: {gpu_info_before.get('gpu_name', 'N/A')}")
                print(f"   ‚Ä¢ –í–µ—Ä—Å–∏—è CUDA: {gpu_info_before.get('cuda_version', 'N/A')}")
                print(f"   ‚Ä¢ –û–±—â–∞—è –ø–∞–º—è—Ç—å: {gpu_info_before.get('gpu_memory_total_gb', 0):.2f} GB")
                print(f"   ‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –ø–∞–º—è—Ç–∏: {gpu_info_before.get('gpu_memory_allocated_gb', 0):.2f} GB")
            print()
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
        print(f"üì¶ –ó–ê–ì–†–£–ó–ö–ê –ú–û–î–ï–õ–ò...")
        start_load = time.time()
        try:
            model, tokenizer = load_model_func()
            load_time = time.time() - start_load
            print(f"‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∑–∞ {load_time:.2f} —Å–µ–∫—É–Ω–¥ ({load_time/60:.2f} –º–∏–Ω—É—Ç)")
        except Exception as e:
            import traceback
            error_details = str(e)
            full_traceback = traceback.format_exc()
            
            print(f"\n{'='*80}")
            print(f"–û–®–ò–ë–ö–ê –ó–ê–ì–†–£–ó–ö–ò –ú–û–î–ï–õ–ò")
            print(f"{'='*80}")
            print(f"–û—à–∏–±–∫–∞: {error_details}")
            print(f"\n–ü–æ–ª–Ω—ã–π traceback:")
            print(f"{'‚îÄ'*80}")
            print(full_traceback)
            print(f"{'‚îÄ'*80}")
            print(f"–î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏ —Ç–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –æ—Ç—á—ë—Ç–µ")
            print(f"{'='*80}\n")
            
            # –û—á–∏—â–∞–µ–º –ø–∞–º—è—Ç—å –ø–æ—Å–ª–µ –æ—à–∏–±–∫–∏ –∑–∞–≥—Ä—É–∑–∫–∏
            self.clear_memory()
            
            return {
                "status": "error",
                "error": f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {error_details}",
                "error_traceback": full_traceback
            }
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ GPU/API –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏
        if is_api_model:
            print(f"üìä –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –†–ï–°–£–†–°–ê–•:")
            print(f"   ‚Ä¢ –¢–∏–ø: API (Google Generative AI)")
            print(f"   ‚Ä¢ –ú–æ–¥–µ–ª—å –¥–æ—Å—Ç—É–ø–Ω–∞ —á–µ—Ä–µ–∑ API")
            print()
            gpu_info_after = {"api": True}
            memory_after_load = {"allocated": 0.0, "reserved": 0.0, "total": 0.0}
        elif is_ollama:
            from gpu_info import get_gpu_memory_usage_nvidia_smi
            _mem = get_gpu_memory_usage_nvidia_smi()
            memory_after_load = {
                "allocated": _mem["used_gb"],
                "reserved": 0.0,
                "total": _mem["total_gb"],
            }
            print(f"üìä –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –†–ï–°–£–†–°–ê–• (Ollama):")
            print(f"   ‚Ä¢ –¢–∏–ø: Ollama (–ª–æ–∫–∞–ª—å–Ω—ã–π API)")
            print(f"   ‚Ä¢ GPU –ø–∞–º—è—Ç—å (nvidia-smi): {memory_after_load['allocated']:.2f} / {memory_after_load['total']:.2f} GB")
            print()
            gpu_info_after = {"ollama": True}
        else:
            gpu_info_after = get_gpu_info()
            memory_after_load = get_gpu_memory_usage()
            print(f"üìä –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û GPU (–ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏):")
            print(f"   ‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –ø–∞–º—è—Ç–∏: {memory_after_load['allocated']:.2f} GB")
            print(f"   ‚Ä¢ –ó–∞—Ä–µ–∑–µ—Ä–≤–∏—Ä–æ–≤–∞–Ω–æ –ø–∞–º—è—Ç–∏: {memory_after_load['reserved']:.2f} GB")
            print(f"   ‚Ä¢ –î–æ—Å—Ç—É–ø–Ω–æ –ø–∞–º—è—Ç–∏: {memory_after_load['total'] - memory_after_load['allocated']:.2f} GB")
            print()
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ–º–ø—Ç
        if prompt_template is None:
            prompt_template = build_prompt3
        
        # –û—Ü–µ–Ω–∫–∞ –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ
        results = []
        parsing_errors = []  # –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –æ—à–∏–±–∫–∞–º–∏: {"text_index": int, "text": str, "error": str, "response": str}
        times = []
        memory_samples = []  # –î–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π ‚Äî torch; –¥–ª—è Ollama ‚Äî nvidia-smi (VRAM –ø—Ä–æ—Ü–µ—Å—Å–∞ Ollama)
        ollama_metrics_list = []  # –ú–µ—Ç—Ä–∏–∫–∏ –∏–∑ –æ—Ç–≤–µ—Ç–æ–≤ Ollama (eval_duration, eval_count –∏ —Ç.–¥.)
        total_start_time = time.time()
        
        # –ü–µ—Ä–µ–≤–æ–¥–∏–º –≤ eval —Ä–µ–∂–∏–º —Ç–æ–ª—å–∫–æ –ª–æ–∫–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ (–Ω–µ API, –Ω–µ Ollama)
        if not is_api_model and not is_ollama and hasattr(model, 'eval'):
            model.eval()
        
        print(f"üîÑ –û–ë–†–ê–ë–û–¢–ö–ê –î–ê–¢–ê–°–ï–¢–ê")
        print(f"{'='*80}")
        print(f"–í—Å–µ–≥–æ —Ç–µ–∫—Å—Ç–æ–≤: {len(self.texts)}")
        print(f"{'='*80}\n")
        
        # –°–æ–∑–¥–∞–µ–º –æ–±–µ—Ä—Ç–∫—É –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –¥–ª—è –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞
        if use_multi_agent:
            if is_api_model:
                # –î–ª—è API –º–æ–¥–µ–ª–µ–π –∏—Å–ø–æ–ª—å–∑—É–µ–º APIGenerator
                from core.generators import APIGenerator
                model_name = hyperparameters.get("model_name", "gemma-3-12b-it")
                generator = APIGenerator(model, tokenizer, model_name=model_name)
            else:
                # –î–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –∏—Å–ø–æ–ª—å–∑—É–µ–º StandardGenerator
                from core.generators import StandardGenerator
                generator = StandardGenerator(model, tokenizer)
        
        interrupted = False
        last_processed_index = -1
        timeout_reason = None
        max_inference_time_seconds = MAX_INFERENCE_TIME_MINUTES * 60
        
        try:
            for i, text in enumerate(self.texts):
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ (—Å—É–º–º–∞/–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ) –ø–µ—Ä–µ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –Ω–æ–≤–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
                avg_inference_time = sum(times) / len(times) if times else 0
                if avg_inference_time > max_inference_time_seconds:
                    interrupted = True
                    last_processed_index = i - 1
                    timeout_reason = f"–ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –≤—Ä–µ–º–µ–Ω–∏ ({MAX_INFERENCE_TIME_MINUTES} –º–∏–Ω—É—Ç)"
                    avg_minutes = avg_inference_time / 60
                    print(f"\n   ‚ö†Ô∏è –ü—Ä–µ—Ä—ã–≤–∞–Ω–∏–µ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞: –ø—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –≤—Ä–µ–º–µ–Ω–∏ ({MAX_INFERENCE_TIME_MINUTES} –º–∏–Ω—É—Ç)")
                    print(f"   ‚è±Ô∏è –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞: {avg_minutes:.1f} –º–∏–Ω/–æ—Ç–≤–µ—Ç")
                    print(f"   üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ç–µ–∫—Å—Ç–æ–≤: {i}/{len(self.texts)}")
                    break
                
                # –í—ã–≤–æ–¥–∏–º –Ω–æ–º–µ—Ä –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
                if not verbose:
                    print(f"\r  üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞ #{i+1}/{len(self.texts)}...", end="", flush=True)
                
                response_text = ""
                error_msg = None
                
                if use_multi_agent:
                    # –ú—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω—ã–π –ø–æ–¥—Ö–æ–¥
                    try:
                        # –í—ã–≤–æ–¥–∏–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –ø—Ä–∏ verbose —Ä–µ–∂–∏–º–µ
                        if verbose:
                            print(f"   üîÑ –û—Ç–≤–µ—Ç #{i+1}/{len(self.texts)} - –ú—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞:")
                        start_time = time.time()
                        result = process_with_multi_agent(
                            text=text,
                            generator=generator,
                            max_new_tokens=max_new_tokens,
                            multi_agent_mode=multi_agent_mode
                        )
                        elapsed = time.time() - start_time
                        times.append(elapsed)
                        
                        # –ò–∑–º–µ—Ä—è–µ–º –ø–∞–º—è—Ç—å –≤–æ –≤—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ (—Ç–æ–ª—å–∫–æ –¥–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π —Å –≤–µ—Å–∞–º–∏)
                        if not is_api_model and not is_ollama:
                            memory_sample = get_gpu_memory_usage()
                            memory_samples.append(memory_sample["allocated"])
                        
                        response_text = result.get("response", "")
                        json_part = result.get("json", "")
                        parsed_json = result.get("json_parsed", {})
                        # –û—á–∏—â–∞–µ–º parsed_json –æ—Ç –∑–∞–ø–∏—Å–µ–π —Å None –∏–ª–∏ [None, None]
                        if parsed_json and isinstance(parsed_json, dict):
                            parsed_json = self._clean_parsed_json(parsed_json)
                            # –û–±–Ω–æ–≤–ª—è–µ–º json_part –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏
                            try:
                                json_part = json.dumps(parsed_json, ensure_ascii=False, indent=2)
                            except Exception:
                                pass  # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞—Ç—å, –æ—Å—Ç–∞–≤–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π json_part
                        is_valid = result.get("is_valid", False)
                        error_msg = result.get("error")
                        
                        if error_msg:
                            parsing_errors.append({
                                "text_index": i,
                                "text": text,
                                "error": f"–û—à–∏–±–∫–∞ –≤ –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–æ–º –ø–æ–¥—Ö–æ–¥–µ: {error_msg}",
                                "response": response_text[:500] if response_text else ""
                            })
                        
                        if not is_valid and json_part:
                            # –î–ª—è API –º–æ–¥–µ–ª–µ–π —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—ã–π JSON –ø—Ä–∏ verbose
                            json_display = json_part if (is_api_model and verbose) else json_part[:200]
                            parsing_errors.append({
                                "text_index": i,
                                "text": text,
                                "error": f"–ù–µ–≤–∞–ª–∏–¥–Ω—ã–π JSON. –û—Ç–≤–µ—Ç: {json_display}",
                                "response": json_part[:500]
                            })
                        
                        # –î–ª—è –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞ –Ω—É–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å raw_output, raw_validation –∏ parsed_validation
                        # response_text —Å–æ–¥–µ—Ä–∂–∏—Ç —Å—ã—Ä–æ–π –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏
                        raw_output_for_result = response_text
                        # –í–∞–ª–∏–¥–∞—Ü–∏—è raw output —á–µ—Ä–µ–∑ Pydantic
                        raw_validation_for_result = validate_with_pydantic(raw_output_for_result, stage="raw")
                        # –í–∞–ª–∏–¥–∞—Ü–∏—è –ø–æ—Å–ª–µ –ø–∞—Ä—Å–∏–Ω–≥–∞ —á–µ—Ä–µ–∑ Pydantic
                        parsed_validation_for_result = validate_with_pydantic(parsed_json, stage="parsed")
                        
                        results.append({
                            "text": text,
                            "json": json_part,
                            "json_parsed": parsed_json,
                            "is_valid": is_valid,
                            "raw_output": raw_output_for_result,
                            "raw_validation": raw_validation_for_result,
                            "parsed_validation": parsed_validation_for_result
                        })
                    except Exception as e:
                        error_msg = str(e)
                        import traceback
                        traceback_str = traceback.format_exc()
                        # –î–ª—è API –º–æ–¥–µ–ª–µ–π —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—ã–π traceback
                        traceback_display = traceback_str if is_api_model else traceback_str[:200]
                        parsing_errors.append({
                            "text_index": i,
                            "text": text,
                            "error": f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–æ–º –ø–æ–¥—Ö–æ–¥–µ: {error_msg}. Traceback: {traceback_display}",
                            "response": ""
                        })
                        results.append({
                            "text": text,
                            "json": "",
                            "json_parsed": {},
                            "is_valid": False
                        })
                else:
                    # –û–¥–Ω–æ–∞–≥–µ–Ω—Ç–Ω—ã–π –ø–æ–¥—Ö–æ–¥ (–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π)
                    so = hyperparameters.get("structured_output", False)
                    uo = hyperparameters.get("use_outlines", False)
                    rs = None
                    if uo or so:
                        from structured_schemas import FertilizerExtractionOutput, FertilizerExtractionOutputLatin
                        rs = FertilizerExtractionOutputLatin if (uo and not is_api_model and not is_ollama) else FertilizerExtractionOutput
                    pt_name = hyperparameters.get("prompt_template_name") or PROMPT_TEMPLATE_NAME
                    prompt = prompt_template(text, structured_output=so, response_schema=rs, prompt_template_name=pt_name)
                    
                    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏
                    response_text, elapsed, error_msg = self._generate_response_with_retries(
                        model, tokenizer, prompt, generate_func,
                        hyperparameters, max_new_tokens, num_retries,
                        is_api_model or is_ollama, verbose, i, len(self.texts), text,
                        times, memory_samples, parsing_errors
                    )
                    # Ollama: –∑–∞–º–µ—Ä GPU —á–µ—Ä–µ–∑ nvidia-smi –∏ —Å–±–æ—Ä –º–µ—Ç—Ä–∏–∫ –∏–∑ –æ—Ç–≤–µ—Ç–∞ API
                    if is_ollama and response_text:
                        from gpu_info import get_gpu_memory_usage_nvidia_smi
                        _m = get_gpu_memory_usage_nvidia_smi()
                        memory_samples.append(_m.get("used_gb", 0.0))
                        try:
                            from model_loaders_ollama import get_last_ollama_metrics
                            _om = get_last_ollama_metrics()
                            if _om:
                                ollama_metrics_list.append(_om)
                        except Exception:
                            pass
                    # –í—ã–≤–æ–¥–∏–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç –∏ –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç –≤ –∫–æ–Ω—Å–æ–ª—å (—Ç–æ–ª—å–∫–æ –ø—Ä–∏ verbose)
                    if verbose and response_text:
                        self._print_verbose_output(text, response_text, is_api_model or is_ollama, i, len(self.texts))
                    
                    if not response_text:
                        result = self._handle_no_response(
                            text, i, len(self.texts), error_msg,
                            is_api_model or is_ollama, verbose, parsing_errors
                        )
                        results.append(result)
                        continue
                    
                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Ç–≤–µ—Ç: –≤–∞–ª–∏–¥–∞—Ü–∏—è, –ø–∞—Ä—Å–∏–Ω–≥ JSON
                    result = self._process_response(
                        response_text, text, i, is_api_model or is_ollama, verbose, parsing_errors
                    )
                    results.append(result)
            
            # –í—ã–≤–æ–¥–∏–º –ø—Ä–æ–≥—Ä–µ—Å—Å –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
            self._print_progress(i, len(self.texts), results, times, total_start_time, verbose)
            last_processed_index = i
        
        except InferenceCriticalFailure as e:
            print(f"\n\n{'='*80}")
            print(f"–î–û–°–†–û–ß–ù–û–ï –ó–ê–í–ï–†–®–ï–ù–ò–ï –û–¶–ï–ù–ö–ò –ú–û–î–ï–õ–ò")
            print(f"{'='*80}")
            print(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –ø–æ—Å–ª–µ {e.num_retries} –ø–æ–ø—ã—Ç–æ–∫ –Ω–∞ –ø—Ä–∏–º–µ—Ä–µ #{e.text_index + 1}.")
            print(f"–û—à–∏–±–∫–∞: {e.message}")
            print(f"{'='*80}\n")
            self.clear_memory()
            return {
                "status": "error",
                "error": f"–î–æ—Å—Ä–æ—á–Ω–æ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ: –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –ø–æ—Å–ª–µ {e.num_retries} –ø–æ–ø—ã—Ç–æ–∫ –Ω–∞ –ø—Ä–∏–º–µ—Ä–µ #{e.text_index + 1}. {e.message}",
                "parsing_errors": parsing_errors,
            }
        except KeyboardInterrupt:
            interrupted = True
            last_processed_index = i if 'i' in locals() else -1
            print(f"\n\n{'='*80}")
            print(f"‚ö†Ô∏è  –ü–†–ï–†–´–í–ê–ù–ò–ï –û–ë–†–ê–ë–û–¢–ö–ò –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–ï–ú")
            print(f"{'='*80}")
            print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ç–µ–∫—Å—Ç–æ–≤: {len(results)}/{len(self.texts)}")
            print(f"–ü–æ—Å–ª–µ–¥–Ω–∏–π –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –∏–Ω–¥–µ–∫—Å: {last_processed_index + 1}")
            print()
            
            menu_lines = [
                "–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:",
                "  1 - –ó–∞–≤–µ—Ä—à–∏—Ç—å (–º–µ—Ç—Ä–∏–∫–∏ –≤ –∫–æ–Ω—Å–æ–ª—å, –±–µ–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è)",
                "  2 - –ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É",
                "  3 - –ó–∞–≤–µ—Ä—à–∏—Ç—å –±–µ–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è",
            ]
            if stop_all_on_interrupt:
                menu_lines.append("  4 - –ü—Ä–µ—Ä–≤–∞—Ç—å –æ—Ü–µ–Ω–∫—É –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π (–≤—ã–π—Ç–∏ –∏–∑ run_all_models)")
            menu_prompt = "\n".join(menu_lines) + "\n–í–∞—à –≤—ã–±–æ—Ä (1/2/3" + ("/4" if stop_all_on_interrupt else "") + "): "
            while True:
                try:
                    choice = input(menu_prompt).strip()
                    
                    if choice == "1":
                        print("\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
                        # –ü—Ä–æ–¥–æ–ª–∂–∏–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                        break
                    elif choice == "2":
                        print("\n‚ñ∂Ô∏è  –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É...\n")
                        # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ü–∏–∫–ª —Å —Ç–æ–≥–æ –º–µ—Å—Ç–∞, –≥–¥–µ –æ—Å—Ç–∞–Ω–æ–≤–∏–ª–∏—Å—å
                        try:
                            for i in range(last_processed_index + 1, len(self.texts)):
                                # –í—ã–≤–æ–¥–∏–º –Ω–æ–º–µ—Ä –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
                                if not verbose:
                                    print(f"\r  üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞ #{i+1}/{len(self.texts)}...", end="", flush=True)
                                
                                response_text = ""
                                error_msg = None
                                
                                if use_multi_agent:
                                    try:
                                        # –í—ã–≤–æ–¥–∏–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –ø—Ä–∏ verbose —Ä–µ–∂–∏–º–µ
                                        if verbose:
                                            print(f"   üîÑ –û—Ç–≤–µ—Ç #{i+1}/{len(self.texts)} - –ú—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞:")
                                        start_time = time.time()
                                        result = process_with_multi_agent(
                                            text=self.texts[i],
                                            generator=generator,
                                            max_new_tokens=max_new_tokens,
                                            multi_agent_mode=multi_agent_mode
                                        )
                                        elapsed = time.time() - start_time
                                        times.append(elapsed)
                                        
                                        memory_sample = get_gpu_memory_usage()
                                        memory_samples.append(memory_sample["allocated"])
                                        
                                        response_text = result.get("response", "")
                                        json_part = result.get("json", "")
                                        parsed_json = result.get("json_parsed", {})
                                        # –û—á–∏—â–∞–µ–º parsed_json –æ—Ç –∑–∞–ø–∏—Å–µ–π —Å None –∏–ª–∏ [None, None]
                                        if parsed_json and isinstance(parsed_json, dict):
                                            parsed_json = self._clean_parsed_json(parsed_json)
                                            # –û–±–Ω–æ–≤–ª—è–µ–º json_part –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏
                                            try:
                                                json_part = json.dumps(parsed_json, ensure_ascii=False, indent=2)
                                            except Exception:
                                                pass  # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞—Ç—å, –æ—Å—Ç–∞–≤–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π json_part
                                        is_valid = result.get("is_valid", False)
                                        error_msg = result.get("error")
                                        
                                        if error_msg:
                                            parsing_errors.append(f"–¢–µ–∫—Å—Ç #{i}: –æ—à–∏–±–∫–∞ –≤ –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–æ–º –ø–æ–¥—Ö–æ–¥–µ. –û—à–∏–±–∫–∞: {error_msg}")
                                        
                                        if not is_valid and json_part:
                                            # –î–ª—è API –º–æ–¥–µ–ª–µ–π –ø—Ä–∏ verbose –≤—ã–≤–æ–¥–∏–º –ø–æ–ª–Ω—ã–π JSON, –∏–Ω–∞—á–µ –æ–±—Ä–µ–∑–∞–µ–º
                                            json_display = json_part if (is_api_model and verbose) else (json_part[:200] if len(json_part) > 200 else json_part)
                                            parsing_errors.append(f"–¢–µ–∫—Å—Ç #{i}: –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π JSON. –û—Ç–≤–µ—Ç: {json_display}")
                                        
                                        # –î–ª—è –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞ –Ω—É–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å raw_output, raw_validation –∏ parsed_validation
                                        # response_text —Å–æ–¥–µ—Ä–∂–∏—Ç —Å—ã—Ä–æ–π –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏
                                        raw_output_for_result = response_text
                                        # –í–∞–ª–∏–¥–∞—Ü–∏—è raw output —á–µ—Ä–µ–∑ Pydantic
                                        raw_validation_for_result = validate_with_pydantic(raw_output_for_result, stage="raw")
                                        # –í–∞–ª–∏–¥–∞—Ü–∏—è –ø–æ—Å–ª–µ –ø–∞—Ä—Å–∏–Ω–≥–∞ —á–µ—Ä–µ–∑ Pydantic
                                        parsed_validation_for_result = validate_with_pydantic(parsed_json, stage="parsed")
                                        
                                        results.append({
                                            "text": self.texts[i],
                                            "json": json_part,
                                            "json_parsed": parsed_json,
                                            "is_valid": is_valid,
                                            "raw_output": raw_output_for_result,
                                            "raw_validation": raw_validation_for_result,
                                            "parsed_validation": parsed_validation_for_result
                                        })
                                    except Exception as e:
                                        error_msg = str(e)
                                        import traceback
                                        parsing_errors.append(f"–¢–µ–∫—Å—Ç #{i}: –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–æ–º –ø–æ–¥—Ö–æ–¥–µ. –û—à–∏–±–∫–∞: {error_msg}. Traceback: {traceback.format_exc()[:200]}")
                                        results.append({
                                            "text": self.texts[i],
                                            "json": "",
                                            "json_parsed": {},
                                            "is_valid": False
                                        })
                                else:
                                    so = hyperparameters.get("structured_output", False)
                                    uo = hyperparameters.get("use_outlines", False)
                                    rs = None
                                    if uo or so:
                                        from structured_schemas import FertilizerExtractionOutput, FertilizerExtractionOutputLatin
                                        rs = FertilizerExtractionOutputLatin if (uo and not is_api_model and not is_ollama) else FertilizerExtractionOutput
                                    pt_name = hyperparameters.get("prompt_template_name") or PROMPT_TEMPLATE_NAME
                                    prompt = prompt_template(self.texts[i], structured_output=so, response_schema=rs, prompt_template_name=pt_name)
                                    
                                    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏
                                    response_text, elapsed, error_msg = self._generate_response_with_retries(
                                        model, tokenizer, prompt, generate_func,
                                        hyperparameters, max_new_tokens, num_retries,
                                        is_api_model or is_ollama, verbose, i, len(self.texts), self.texts[i],
                                        times, memory_samples, parsing_errors
                                    )
                                    if is_ollama and response_text:
                                        from gpu_info import get_gpu_memory_usage_nvidia_smi
                                        _m = get_gpu_memory_usage_nvidia_smi()
                                        memory_samples.append(_m.get("used_gb", 0.0))
                                        try:
                                            from model_loaders_ollama import get_last_ollama_metrics
                                            _om = get_last_ollama_metrics()
                                            if _om:
                                                ollama_metrics_list.append(_om)
                                        except Exception:
                                            pass
                                    # –í—ã–≤–æ–¥–∏–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç –∏ –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç –≤ –∫–æ–Ω—Å–æ–ª—å (—Ç–æ–ª—å–∫–æ –ø—Ä–∏ verbose)
                                    if verbose and response_text:
                                        self._print_verbose_output(self.texts[i], response_text, is_api_model or is_ollama, i, len(self.texts))
                                    
                                    if not response_text:
                                        result = self._handle_no_response(
                                            self.texts[i], i, len(self.texts), error_msg,
                                            is_api_model or is_ollama, verbose, parsing_errors
                                        )
                                        results.append(result)
                                        continue
                                    
                                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Ç–≤–µ—Ç: –≤–∞–ª–∏–¥–∞—Ü–∏—è, –ø–∞—Ä—Å–∏–Ω–≥ JSON
                                    result = self._process_response(
                                        response_text, self.texts[i], i, is_api_model or is_ollama, verbose, parsing_errors
                                    )
                                    results.append(result)
                                
                                # –í—ã–≤–æ–¥–∏–º –ø—Ä–æ–≥—Ä–µ—Å—Å
                                self._print_progress(i, len(self.texts), results, times, total_start_time, verbose)
                        except InferenceCriticalFailure as e:
                            print(f"\n\n{'='*80}")
                            print(f"–î–û–°–†–û–ß–ù–û–ï –ó–ê–í–ï–†–®–ï–ù–ò–ï –û–¶–ï–ù–ö–ò –ú–û–î–ï–õ–ò")
                            print(f"{'='*80}")
                            print(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –ø–æ—Å–ª–µ {e.num_retries} –ø–æ–ø—ã—Ç–æ–∫ –Ω–∞ –ø—Ä–∏–º–µ—Ä–µ #{e.text_index + 1}.")
                            print(f"–û—à–∏–±–∫–∞: {e.message}")
                            print(f"{'='*80}\n")
                            self.clear_memory()
                            return {
                                "status": "error",
                                "error": f"–î–æ—Å—Ä–æ—á–Ω–æ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ: –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –ø–æ—Å–ª–µ {e.num_retries} –ø–æ–ø—ã—Ç–æ–∫ –Ω–∞ –ø—Ä–∏–º–µ—Ä–µ #{e.text_index + 1}. {e.message}",
                                "parsing_errors": parsing_errors,
                            }
                        except KeyboardInterrupt:
                            print(f"\n\n‚ö†Ô∏è  –ü–æ–≤—Ç–æ—Ä–Ω–æ–µ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏–µ. –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ –±–µ–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è...")
                            interrupted = True
                            break
                        break
                    elif choice == "3":
                        print("\n‚ùå –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ –±–µ–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è...")
                        return {
                            "status": "interrupted",
                            "message": "–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º –±–µ–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è",
                            "processed_count": len(results)
                        }
                    elif stop_all_on_interrupt and choice == "4":
                        print("\n‚ùå –ü—Ä–µ—Ä—ã–≤–∞–Ω–∏–µ –æ—Ü–µ–Ω–∫–∏ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π...")
                        raise StopAllModelsInterrupt()
                    else:
                        print("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ 1, 2" + (", 3, 4" if stop_all_on_interrupt else " –∏–ª–∏ 3"))
                except StopAllModelsInterrupt:
                    raise
                except KeyboardInterrupt:
                    print("\n\n‚ö†Ô∏è  –ü–æ–≤—Ç–æ—Ä–Ω–æ–µ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏–µ. –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ –±–µ–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è...")
                    interrupted = True
                    break
        
        # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        total_time = time.time() - total_start_time
        print(f"\n{'='*80}")
        print(f"üìä –í–´–ß–ò–°–õ–ï–ù–ò–ï –ú–ï–¢–†–ò–ö")
        print(f"{'='*80}\n")
        
        # –ü—Ä–æ—Ü–µ–Ω—Ç –Ω–µ–≤–∞–ª–∏–¥–Ω—ã—Ö JSON
        invalid_count = sum(1 for r in results if not r["is_valid"])
        valid_count = len(results) - invalid_count
        parsing_error_rate = invalid_count / len(results) if results else 0.0
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        avg_speed = sum(times) / len(times) if times else 0.0
        min_time = min(times) if times else 0.0
        max_time = max(times) if times else 0.0
        total_inference_time = sum(times)
        
        # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ –≤–æ –≤—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ –≤—Å–µ—Ö –∏–∑–º–µ—Ä–µ–Ω–∏–π –≤–æ –≤—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
        if is_api_model:
            # –î–ª—è API –º–æ–¥–µ–ª–µ–π –Ω–µ –∏–∑–º–µ—Ä—è–µ–º –ø–∞–º—è—Ç—å
            memory_during_inference_avg = 0.0
        elif memory_samples:
            # –î–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π ‚Äî torch allocated; –¥–ª—è Ollama ‚Äî nvidia-smi used_gb
            memory_during_inference_avg = sum(memory_samples) / len(memory_samples)
        else:
            # Fallback: –∏–∑–º–µ—Ä—è–µ–º —Å–µ–π—á–∞—Å, –µ—Å–ª–∏ –Ω–µ –±—ã–ª–æ –∏–∑–º–µ—Ä–µ–Ω–∏–π
            current_memory = get_gpu_memory_usage()
            memory_during_inference_avg = current_memory["allocated"]
        
        # –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–µ
        memory_during_inference = {"allocated": memory_during_inference_avg}
        
        print(f"‚è±Ô∏è  –í–†–ï–ú–Ø –í–´–ü–û–õ–ù–ï–ù–ò–Ø:")
        print(f"   ‚Ä¢ –û–±—â–µ–µ –≤—Ä–µ–º—è: {total_time/60:.2f} –º–∏–Ω—É—Ç ({total_time:.2f} —Å–µ–∫—É–Ω–¥)")
        print(f"   ‚Ä¢ –í—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞: {total_inference_time/60:.2f} –º–∏–Ω—É—Ç")
        print(f"   ‚Ä¢ –í—Ä–µ–º—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {load_time:.2f} —Å–µ–∫—É–Ω–¥")
        print(f"   ‚Ä¢ –°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞: {avg_speed:.3f} —Å–µ–∫/–æ—Ç–≤–µ—Ç")
        print(f"   ‚Ä¢ –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è: {min_time:.3f} —Å–µ–∫")
        print(f"   ‚Ä¢ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è: {max_time:.3f} —Å–µ–∫")
        print()
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è –≤—ã–≤–æ–¥–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        example_text = self.texts[0] if self.texts else "–ü—Ä–∏–º–µ—Ä —Ç–µ–∫—Å—Ç–∞"
        
        workflow_description = ""  # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –≤—ã–≤–æ–¥–µ
        workflow_prompts = None  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
        if use_multi_agent:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏—Å—Ç–µ–º—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ workflow –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø—Ä–æ–º–ø—Ç–æ–≤
            from workflow_config import get_workflow_prompts
            workflow_prompts = get_workflow_prompts(multi_agent_mode, example_text)
            full_prompt_example = workflow_prompts["full_prompt_example"]
            workflow_description = workflow_prompts.get("description", "")
        else:
            pt_name = hyperparameters.get("prompt_template_name") or PROMPT_TEMPLATE_NAME
            full_prompt_example = prompt_template(example_text, prompt_template_name=pt_name)
        
        # –í—ã–≤–æ–¥–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–º–ø—Ç–µ –∏ —Ä–µ–∂–∏–º–µ
        print(f"üìù –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ù–´–ô –ü–†–û–ú–ü–¢:")
        if use_multi_agent:
            print(f"   ‚Ä¢ –†–µ–∂–∏–º: –ú—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω—ã–π ({multi_agent_mode})")
            print(f"   ‚Ä¢ –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã –∏–∑ prompt_config.py")
            print(f"   ‚Ä¢ –ê–≥–µ–Ω—Ç—ã: {workflow_description}")
            print(f"   ‚Ä¢ –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –≤—Å–µ—Ö –ø—Ä–æ–º–ø—Ç–æ–≤ (–ø—Ä–∏–º–µ—Ä —Å –ø–µ—Ä–≤—ã–º —Ç–µ–∫—Å—Ç–æ–º):")
            print(f"{'‚îÄ'*80}")
            # –í—ã–≤–æ–¥–∏–º –ø—Ä–æ–º–ø—Ç—ã —Å –æ—Ç—Å—Ç—É–ø–∞–º–∏ –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
            prompt_lines = full_prompt_example.split('\n')
            for line in prompt_lines[:50]:  # –ü–µ—Ä–≤—ã–µ 50 —Å—Ç—Ä–æ–∫, —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–≥—Ä—É–∂–∞—Ç—å –∫–æ–Ω—Å–æ–ª—å
                print(f"   {line}")
            if len(prompt_lines) > 50:
                print(f"   ... (–µ—â—ë {len(prompt_lines) - 50} —Å—Ç—Ä–æ–∫, –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ –æ—Ç—á—ë—Ç–µ)")
            print(f"{'‚îÄ'*80}")
        else:
            print(f"   ‚Ä¢ –†–µ–∂–∏–º: –û–¥–Ω–æ–∞–≥–µ–Ω—Ç–Ω—ã–π")
            print(f"   ‚Ä¢ –®–∞–±–ª–æ–Ω: {prompt_template.__name__ if hasattr(prompt_template, '__name__') else str(prompt_template)}")
            print(f"   ‚Ä¢ –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –ø—Ä–æ–º–ø—Ç–∞ (–ø—Ä–∏–º–µ—Ä —Å –ø–µ—Ä–≤—ã–º —Ç–µ–∫—Å—Ç–æ–º):")
            print(f"{'‚îÄ'*80}")
            # –í—ã–≤–æ–¥–∏–º –ø—Ä–æ–º–ø—Ç —Å –æ—Ç—Å—Ç—É–ø–∞–º–∏ –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
            prompt_lines = full_prompt_example.split('\n')
            for line in prompt_lines[:30]:  # –ü–µ—Ä–≤—ã–µ 30 —Å—Ç—Ä–æ–∫, —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–≥—Ä—É–∂–∞—Ç—å –∫–æ–Ω—Å–æ–ª—å
                print(f"   {line}")
            if len(prompt_lines) > 30:
                print(f"   ... (–µ—â—ë {len(prompt_lines) - 30} —Å—Ç—Ä–æ–∫, –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ –æ—Ç—á—ë—Ç–µ)")
            print(f"{'‚îÄ'*80}")
        print()
        
        if is_api_model:
            print(f"üíæ –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –†–ï–°–£–†–°–ê–•:")
            print(f"   ‚Ä¢ –¢–∏–ø: API (Google Generative AI)")
            print(f"   ‚Ä¢ –ú–æ–¥–µ–ª—å –¥–æ—Å—Ç—É–ø–Ω–∞ —á–µ—Ä–µ–∑ API")
            print()
        elif is_ollama:
            print(f"üíæ –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–ï –†–ï–°–£–†–°–û–í (Ollama, nvidia-smi):")
            print(f"   ‚Ä¢ –ü–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏: {memory_after_load['allocated']:.2f} GB")
            print(f"   ‚Ä¢ –í–æ –≤—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ (—Å—Ä–µ–¥–Ω.): {memory_during_inference_avg:.2f} GB")
            if ollama_metrics_list:
                total_ns = sum(m.get("total_duration_ns") or 0 for m in ollama_metrics_list)
                eval_count = sum(m.get("eval_count") or 0 for m in ollama_metrics_list)
                print(f"   ‚Ä¢ –ú–µ—Ç—Ä–∏–∫–∏ Ollama: {len(ollama_metrics_list)} –æ—Ç–≤–µ—Ç–æ–≤, –≤—Å–µ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤: {eval_count}, total_duration: {total_ns/1e9:.1f} —Å")
            print()
        else:
            print(f"üíæ –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–ï –ü–ê–ú–Ø–¢–ò:")
            print(f"   ‚Ä¢ –ü–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {memory_after_load['allocated']:.2f} GB")
            print(f"   ‚Ä¢ –í–æ –≤—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞: {memory_during_inference_avg:.2f} GB")
            print(f"   ‚Ä¢ –ò–∑–º–µ–Ω–µ–Ω–∏–µ –æ—Ç –∑–∞–≥—Ä—É–∑–∫–∏: {memory_during_inference_avg - memory_after_load['allocated']:+.2f} GB")
            print()
        
        print(f"üìù –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–ê–†–°–ò–ù–ì–ê JSON:")
        print(f"   ‚Ä¢ –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(results)}")
        print(f"   ‚Ä¢ –í–∞–ª–∏–¥–Ω—ã—Ö JSON: {valid_count} ({100-parsing_error_rate*100:.1f}%)")
        print(f"   ‚Ä¢ –ù–µ–≤–∞–ª–∏–¥–Ω—ã—Ö JSON: {invalid_count} ({parsing_error_rate*100:.1f}%)")
        print(f"   ‚Ä¢ –û—à–∏–±–æ–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞: {len(parsing_errors)}")
        if parsing_errors:
            print(f"\n   üìã –ü–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫ –æ—à–∏–±–æ–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞ ({len(parsing_errors)} –æ—à–∏–±–æ–∫):")
            print(f"   {'‚îÄ'*76}")
            for i, error in enumerate(parsing_errors, 1):
                # –û–±—Ä–µ–∑–∞–µ–º –¥–ª–∏–Ω–Ω—ã–µ –æ—à–∏–±–∫–∏ –¥–ª—è –∫–æ–Ω—Å–æ–ª–∏
                error_display = error[:200] + "..." if len(error) > 200 else error
                print(f"   {i}. {error_display}")
            print(f"   {'‚îÄ'*76}")
        print()
        
        # –ö–∞—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–æ–≤ (–µ—Å–ª–∏ –µ—Å—Ç—å ground truth)
        quality_metrics = None
        raw_output_metrics = None
        validation_stats = None
        
        if self.ground_truths and len(self.ground_truths) == len(results):
            try:
                print(f"üéØ –í–´–ß–ò–°–õ–ï–ù–ò–ï –ú–ï–¢–†–ò–ö –ö–ê–ß–ï–°–¢–í–ê...")
                # –§–∏–ª—å—Ç—Ä—É–µ–º –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º predictions: –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä—è–º–∏
                predictions = []
                raw_outputs = []
                texts_for_metrics = []
                responses_for_metrics = []
                
                for r in results:
                    json_parsed = r.get("json_parsed", {})
                    # –ï—Å–ª–∏ —ç—Ç–æ —Å–ø–∏—Å–æ–∫, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∏–ª–∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å–ª–æ–≤–∞—Ä—å
                    if isinstance(json_parsed, list):
                        # –ï—Å–ª–∏ —Å–ø–∏—Å–æ–∫ –ø—É—Å—Ç–æ–π –∏–ª–∏ —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–µ —Å–ª–æ–≤–∞—Ä–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å
                        predictions.append({})
                    elif isinstance(json_parsed, dict):
                        predictions.append(json_parsed)
                    else:
                        predictions.append({})
                
                # –¢–∞–∫–∂–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º ground_truths
                ground_truths_normalized = []
                for gt in self.ground_truths:
                    if isinstance(gt, list):
                        ground_truths_normalized.append({})
                    elif isinstance(gt, dict):
                        ground_truths_normalized.append(gt)
                    else:
                        ground_truths_normalized.append({})
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç—ã, –æ—Ç–≤–µ—Ç—ã –∏ raw outputs –∏–∑ results
                for r in results:
                    texts_for_metrics.append(r.get("text", ""))
                    responses_for_metrics.append(r.get("json", ""))  # json —Å–æ–¥–µ—Ä–∂–∏—Ç –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏
                    # –î–ª—è raw output –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ —Ä–µ–∞–ª—å–Ω—ã–π raw_output, –±–µ–∑ fallback –Ω–∞ json
                    # —Ç–∞–∫ –∫–∞–∫ json —É–∂–µ –ø—Ä–æ—à–µ–ª —á–µ—Ä–µ–∑ —É–º–Ω—ã–π –ø–∞—Ä—Å–µ—Ä
                    raw_output = r.get("raw_output", "")
                    if not raw_output:
                        # –ï—Å–ª–∏ raw_output –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç (–Ω–∞–ø—Ä–∏–º–µ—Ä, –≤ –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–æ–º —Ä–µ–∂–∏–º–µ),
                        # –∏—Å–ø–æ–ª—å–∑—É–µ–º response, –∫–æ—Ç–æ—Ä—ã–π –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Å—ã—Ä–æ–π –æ—Ç–≤–µ—Ç
                        raw_output = r.get("response", "")
                    if not raw_output:
                        # –ï—Å–ª–∏ –∏ response –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É
                        raw_output = ""
                    raw_outputs.append(raw_output)
                
                quality_metrics = calculate_quality_metrics(
                    predictions, ground_truths_normalized,
                    texts=texts_for_metrics,
                    responses=responses_for_metrics,
                    prompt=full_prompt_example
                )
                
                # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤–∞–ª–∏–¥–∞—Ü–∏–∏
                raw_validations = [r.get("raw_validation", {}) for r in results]
                # –î–ª—è parsed —É—á–∏—Ç—ã–≤–∞–µ–º –≤—Å–µ –æ—Ç–≤–µ—Ç—ã, –Ω–æ –≤–∞–ª–∏–¥–∞—Ü–∏—è –≤—ã—á–∏—Å–ª—è–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –¥–ª—è —É—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã—Ö
                parsed_validations = [r.get("parsed_validation", {}) for r in results if r.get("is_valid", False)]
                
                # –§–∏–ª—å—Ç—Ä—É–µ–º –ø—É—Å—Ç—ã–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (–µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ –±—ã–ª–∏ –≤—ã—á–∏—Å–ª–µ–Ω—ã)
                raw_validations = [v for v in raw_validations if v]
                parsed_validations = [v for v in parsed_validations if v]
                
                # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ (is_valid = True)
                total_parsed_count = sum(1 for r in results if r.get("is_valid", False))
                
                if raw_validations or parsed_validations:
                    raw_valid_count = sum(1 for v in raw_validations if v.get("is_valid", False)) if raw_validations else 0
                    parsed_valid_count = sum(1 for v in parsed_validations if v.get("is_valid", False)) if parsed_validations else 0
                    
                    # –î–ª—è parsed: invalid_count = –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–µ —Å—Ä–µ–¥–∏ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã—Ö + –Ω–µ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã
                    parsed_invalid_count = (len(parsed_validations) - parsed_valid_count) if parsed_validations else 0
                    # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
                    not_parsed_count = len(results) - total_parsed_count
                    parsed_invalid_count += not_parsed_count
                    
                    validation_stats = {
                        "raw_output": {
                            "invalid_count": len(raw_validations) - raw_valid_count if raw_validations else 0,
                            "validation_rate": raw_valid_count / len(raw_validations) if raw_validations else 0.0
                        },
                        "parsed": {
                            "invalid_count": parsed_invalid_count,
                            "validation_rate": parsed_valid_count / len(results) if len(results) > 0 else 0.0
                        }
                    }
                else:
                    validation_stats = None
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ quality_metrics - —ç—Ç–æ —Å–ª–æ–≤–∞—Ä—å
                if not isinstance(quality_metrics, dict):
                    print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞: calculate_quality_metrics –≤–µ—Ä–Ω—É–ª–∞ –Ω–µ —Å–ª–æ–≤–∞—Ä—å, –∞ {type(quality_metrics)}")
                    quality_metrics = None
                else:
                    # –í—ã–≤–æ–¥–∏–º –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ —á–µ—Ä–µ–∑ MetricsPrinter (cleaned output)
                    MetricsPrinter.print_quality_metrics(quality_metrics)
                
                # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤–∞–ª–∏–¥–∞—Ü–∏–∏ cleaned output, –µ—Å–ª–∏ –æ–Ω–∞ –±—ã–ª–∞ –≤—ã—á–∏—Å–ª–µ–Ω–∞
                if validation_stats:
                    MetricsPrinter.print_validation_stats(validation_stats)
                else:
                    print(f"\n   ‚ö†Ô∏è –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –Ω–µ –±—ã–ª–∞ –≤—ã—á–∏—Å–ª–µ–Ω–∞ (raw_validation –∏–ª–∏ parsed_validation –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ results)")
                
                # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è raw output (–±–µ–∑ –¥–æ–ø—É—â–µ–Ω–∏–π, –∫—Ä–æ–º–µ —Ä–µ–≥–∏—Å—Ç—Ä–∞)
                print(f"\nüéØ –í–´–ß–ò–°–õ–ï–ù–ò–ï –ú–ï–¢–†–ò–ö –ö–ê–ß–ï–°–¢–í–ê –î–õ–Ø RAW OUTPUT...")
                print(f"   ‚Ä¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ raw_outputs: {len(raw_outputs)}")
                print(f"   ‚Ä¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ–ø—É—Å—Ç—ã—Ö raw_outputs: {sum(1 for ro in raw_outputs if ro)}")
                print(f"   ‚Ä¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—É—Å—Ç—ã—Ö raw_outputs: {sum(1 for ro in raw_outputs if not ro)}")
                if sum(1 for ro in raw_outputs if not ro) > 0:
                    print(f"   ‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: {sum(1 for ro in raw_outputs if not ro)} raw_outputs –ø—É—Å—Ç—ã–µ! –≠—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä–æ–±–ª–µ–º–æ–π –≤ –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–æ–º —Ä–µ–∂–∏–º–µ.")
                try:
                    raw_output_metrics = calculate_raw_output_metrics(
                        raw_outputs, ground_truths_normalized,
                        texts=texts_for_metrics,
                        responses=raw_outputs,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º raw_outputs –∫–∞–∫ responses
                        prompt=full_prompt_example
                    )
                    print(f"   ‚úÖ –ú–µ—Ç—Ä–∏–∫–∏ raw output –≤—ã—á–∏—Å–ª–µ–Ω—ã")
                    if raw_output_metrics:
                        print(f"   ‚Ä¢ Raw –º–µ—Ç—Ä–∏–∫–∏ —Å–æ–¥–µ—Ä–∂–∞—Ç: {list(raw_output_metrics.keys())}")
                        # –í—ã–≤–æ–¥–∏–º raw –º–µ—Ç—Ä–∏–∫–∏ —á–µ—Ä–µ–∑ MetricsPrinter
                        MetricsPrinter.print_raw_output_metrics(raw_output_metrics)
                    else:
                        print(f"   ‚ö†Ô∏è Raw –º–µ—Ç—Ä–∏–∫–∏ –ø—É—Å—Ç—ã–µ")
                except Exception as e:
                    print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–∏ –º–µ—Ç—Ä–∏–∫ raw output: {e}")
                    import traceback
                    traceback.print_exc()
                    raw_output_metrics = None
            except Exception as e:
                print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–∏ –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞: {e}")
                import traceback
                if verbose:
                    traceback.print_exc()
        else:
            print(f"   ‚ö†Ô∏è Ground truth –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω –∏–ª–∏ –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç –ø–æ —Ä–∞–∑–º–µ—Ä—É —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏")
            if not self.ground_truths:
                print(f"      (Ground truth –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ)")
            elif len(self.ground_truths) != len(results):
                print(f"      (–†–∞–∑–º–µ—Ä—ã –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç: GT={len(self.ground_truths)}, Results={len(results)})")
        print()
        
        # –ê–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ Gemini API (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω)
        gemini_analysis = None
        if use_gemini_analysis and analyze_errors_with_gemini is not None:
            if gemini_api_key is None:
                gemini_api_key = os.environ.get("GEMINI_API_KEY")
            
            if gemini_api_key:
                print(f"ü§ñ –ó–ê–ü–£–°–ö –ê–ù–ê–õ–ò–ó–ê –ß–ï–†–ï–ó GEMINI API...")
                try:
                    gemini_analysis = analyze_errors_with_gemini(
                        model_name=model_name,
                        parsing_errors=parsing_errors,
                        quality_metrics=quality_metrics or {},
                        hyperparameters=hyperparameters,
                        prompt_full_text=full_prompt_example,
                        gemini_api_key=gemini_api_key
                    )
                    
                    if gemini_analysis.get("status") == "success":
                        print(f"   ‚úÖ –ê–Ω–∞–ª–∏–∑ –æ—Ç Gemini –ø–æ–ª—É—á–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
                        analysis_text = gemini_analysis.get("analysis", "")
                        if analysis_text:
                            print(f"\n   {'‚îÄ'*76}")
                            print(f"   üìù –ê–ù–ê–õ–ò–ó –ò –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –û–¢ GEMINI:")
                            print(f"   {'‚îÄ'*76}")
                            # –í—ã–≤–æ–¥–∏–º –∞–Ω–∞–ª–∏–∑ —Å –æ—Ç—Å—Ç—É–ø–∞–º–∏ –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
                            analysis_lines = analysis_text.split('\n')
                            for line in analysis_lines[:50]:  # –ü–µ—Ä–≤—ã–µ 50 —Å—Ç—Ä–æ–∫
                                print(f"   {line}")
                            if len(analysis_lines) > 50:
                                print(f"   ... (–µ—â—ë {len(analysis_lines) - 50} —Å—Ç—Ä–æ–∫, –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ –æ—Ç—á—ë—Ç–µ)")
                            print(f"   {'‚îÄ'*76}")
                    else:
                        print(f"   ‚ö†Ô∏è –ê–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ Gemini –Ω–µ —É–¥–∞–ª—Å—è: {gemini_analysis.get('message', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}")
                except Exception as e:
                    print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —á–µ—Ä–µ–∑ Gemini: {e}")
                    gemini_analysis = {
                        "status": "error",
                        "message": str(e)
                    }
            else:
                print(f"   ‚ö†Ô∏è GEMINI_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ Gemini")
        elif use_gemini_analysis and analyze_errors_with_gemini is None:
            print(f"   ‚ö†Ô∏è –ú–æ–¥—É–ª—å gemini_analyzer –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ Gemini")
        print()
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–º–ø—Ç–∞—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –æ—Ç—á—ë—Ç
        if use_multi_agent:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–∂–µ –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ workflow_prompts (–∏–∑–±–µ–≥–∞–µ–º –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è –≤—ã–∑–æ–≤–∞)
            prompt_info = workflow_prompts["prompt_info"]
        else:
            # –î–ª—è –æ–¥–Ω–æ–∞–≥–µ–Ω—Ç–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞ full_prompt_example —É–∂–µ —Å–æ–∑–¥–∞–Ω –≤—ã—à–µ
            prompt_info = None
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (—á—Ç–æ–±—ã –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –∑–Ω–∞—á–µ–Ω–∏–π)
        hyperparameters_to_save = copy.deepcopy(hyperparameters)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –ø–æ—Ä—è–¥–∫–æ–º –ø–æ–ª–µ–π
        # 1. –°–Ω–∞—á–∞–ª–∞ –º–µ—Ç—Ä–∏–∫–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        # 2. –ó–∞—Ç–µ–º quality_metrics
        # 3. –ó–∞—Ç–µ–º raw_output_metrics
        # 4. –ü–æ—Ç–æ–º –≤—Å–µ –æ—Å—Ç–∞–ª—å–Ω–æ–µ
        evaluation_result = {
            "timestamp": datetime.now().strftime("%Y%m%d_%H%M"),
            "model_name": model_name,
            "model_key": model_key,  # Alias –º–æ–¥–µ–ª–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "gemma-2-2b")
            "interrupted": interrupted,
            "timeout_reason": timeout_reason,  # –ü—Ä–∏—á–∏–Ω–∞ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è (–µ—Å–ª–∏ –±—ã–ª–æ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏–µ –ø–æ –≤—Ä–µ–º–µ–Ω–∏)
            "total_samples": len(results),  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–º–æ–∂–µ—Ç –±—ã—Ç—å –º–µ–Ω—å—à–µ –æ–±—â–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ç–µ–∫—Å—Ç–æ–≤ –ø—Ä–∏ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏–∏)
            # –ú–µ—Ç—Ä–∏–∫–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (–ø–µ—Ä–≤—ã–º–∏)
            "valid_json_count": valid_count,  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∞–ª–∏–¥–Ω—ã—Ö JSON (–º–æ–∂–Ω–æ –≤—ã—á–∏—Å–ª–∏—Ç—å: total_samples - invalid_json_count)
            "invalid_json_count": invalid_count,  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ–≤–∞–ª–∏–¥–Ω—ã—Ö JSON
            "parsing_error_rate": parsing_error_rate,  # –ü—Ä–æ—Ü–µ–Ω—Ç –æ—à–∏–±–æ–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞ (–º–æ–∂–Ω–æ –≤—ã—á–∏—Å–ª–∏—Ç—å: invalid_json_count / total_samples)
            "parsing_errors_count": len(parsing_errors),  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π –æ–± –æ—à–∏–±–∫–∞—Ö (–º–æ–∂–µ—Ç –æ—Ç–ª–∏—á–∞—Ç—å—Å—è –æ—Ç invalid_json_count)
            "validation_stats": validation_stats,  # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ Pydantic
            # –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ (–≤—Ç–æ—Ä—ã–º–∏)
            "quality_metrics": quality_metrics,
            # –ú–µ—Ç—Ä–∏–∫–∏ raw output (—Ç—Ä–µ—Ç—å–∏–º–∏)
            "raw_output_metrics": raw_output_metrics,  # –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è raw output
            # –û—Å—Ç–∞–ª—å–Ω—ã–µ –ø–æ–ª—è
            "multi_agent_mode": multi_agent_mode if use_multi_agent else None,
            "gpu_info": gpu_info_before if not (is_api_model or is_ollama) else ({"api": True} if is_api_model else {"ollama": True}),
            "gpu_memory_after_load_gb": memory_after_load["allocated"] if not is_api_model else 0.0,
            "gpu_memory_during_inference_gb": memory_during_inference_avg if not is_api_model else 0.0,
            "api_model": is_api_model,
            "ollama": is_ollama,
            "ollama_metrics": ollama_metrics_list if is_ollama else None,
            "average_response_time_seconds": avg_speed,
            "hyperparameters": hyperparameters_to_save,
            "prompt_template": (hyperparameters.get("prompt_template_name") or PROMPT_TEMPLATE_NAME) if not use_multi_agent else multi_agent_mode,
            "prompt_full_text": full_prompt_example,
            "prompt_info": prompt_info,
            "parsing_errors": parsing_errors,
            "gemini_analysis": gemini_analysis
        }
        
        # –ü—Ä–∏ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏–∏ –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, —Ç–æ–ª—å–∫–æ –ø–∏—à–µ–º –≤ model_errors.log
        if interrupted:
            log_file = os.path.join(self.output_dir, "model_errors.log")
            error_msg = (
                f"\n{'='*80}\n"
                f"–ü–†–ï–†–´–í–ê–ù–ò–ï –û–ë–†–ê–ë–û–¢–ö–ò –ú–û–î–ï–õ–ò\n"
                f"{'='*80}\n"
                f"–í—Ä–µ–º—è: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
                f"–ú–æ–¥–µ–ª—å: {model_name}\n"
                f"–ü—Ä–∏—á–∏–Ω–∞: {timeout_reason or '–ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º'}\n"
                f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ç–µ–∫—Å—Ç–æ–≤: {len(results)}/{len(self.texts)}\n"
                f"{'='*80}\n"
            )
            logging.error(error_msg)
            print(f"\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã (–ø—Ä–µ—Ä—ã–≤–∞–Ω–∏–µ). –ó–∞–ø–∏—Å—å –≤ {log_file}")
        else:
            print(f"üíæ –°–û–•–†–ê–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í...")
            self._save_results(evaluation_result, results)
        
        print(f"\n{'='*80}")
        if interrupted:
            print(f"‚ö†Ô∏è  –û–¶–ï–ù–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê –° –ü–†–ï–†–´–í–ê–ù–ò–ï–ú")
        else:
            print(f"‚úÖ –û–¶–ï–ù–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê –£–°–ü–ï–®–ù–û!")
        print(f"{'='*80}\n")
        
        return evaluation_result
    
    def _save_results(self, evaluation_result: Dict[str, Any], results: List[Dict[str, Any]]):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ñ–∞–π–ª—ã —Å –æ—Ä–≥–∞–Ω–∏–∑–æ–≤–∞–Ω–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π –ø–∞–ø–æ–∫"""
        timestamp = evaluation_result["timestamp"]
        
        print(f"\nüíæ –°–û–•–†–ê–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í...")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤—ã–π –º–µ—Ç–æ–¥ FileManager –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤—Å–µ—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        saved_files = self.file_manager.save_evaluation_results(
            evaluation_result=evaluation_result,
            results=results,
            output_dir=self.output_dir,
            timestamp=timestamp
        )
        
        print(f"‚úÖ –í—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ!")
    
    @staticmethod
    def reevaluate_from_file(
        results_csv_path: str,
        dataset_path: str,
        output_dir: str = "results",
        model_name: str = None,
        use_gemini_analysis: bool = False,
        gemini_api_key: str = None
    ) -> Dict[str, Any]:
        """
        –ü–µ—Ä–µ–æ—Ü–µ–Ω–∏–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–≥–æ CSV —Ñ–∞–π–ª–∞ –±–µ–∑ –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ –º–æ–¥–µ–ª–∏.
        
        Args:
            results_csv_path: –ø—É—Ç—å –∫ CSV —Ñ–∞–π–ª—É —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, results_model_name_timestamp.csv)
            dataset_path: –ø—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É –¥–∞—Ç–∞—Å–µ—Ç—É –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è ground truth
            output_dir: –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            model_name: –∏–º—è –º–æ–¥–µ–ª–∏ (–µ—Å–ª–∏ None, –∏–∑–≤–ª–µ–∫–∞–µ—Ç—Å—è –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞)
        
        Returns:
            —Å–ª–æ–≤–∞—Ä—å —Å –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏
        """
        print(f"\n{'='*80}")
        print(f"üîÑ –ü–ï–†–ï–û–¶–ï–ù–ö–ê –†–ï–ó–£–õ–¨–¢–ê–¢–û–í –ò–ó –§–ê–ô–õ–ê")
        print(f"{'='*80}\n")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑ CSV
        print(f"üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏–∑: {results_csv_path}")
        if not os.path.exists(results_csv_path):
            raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {results_csv_path}")
        
        df_results = pd.read_csv(results_csv_path)
        print(f"   ‚Ä¢ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(df_results)}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
        required_columns = ['text', 'json_parsed']
        missing_columns = [col for col in required_columns if col not in df_results.columns]
        if missing_columns:
            raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {missing_columns}")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º ground truth –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞
        df_full = pd.read_excel(dataset_path)
        
        if "json_parsed" not in df_full.columns:
            raise ValueError("–í –¥–∞—Ç–∞—Å–µ—Ç–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–æ–ª–æ–Ω–∫–∞ 'json_parsed' —Å ground truth")
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º ground truth
        ground_truths = []
        for idx, row in df_full.iterrows():
            gt = row.get("json_parsed", {})
            if isinstance(gt, str):
                try:
                    gt = json.loads(gt)
                except:
                    gt = parse_json_safe(gt)
            ground_truths.append(gt if isinstance(gt, dict) else {})
        
        print(f"   ‚Ä¢ –ó–∞–≥—Ä—É–∂–µ–Ω–æ ground truth –∑–∞–ø–∏—Å–µ–π: {len(ground_truths)}")
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        # –ï—Å–ª–∏ json_parsed –ø—É—Å—Ç–æ–π –∏–ª–∏ –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π, –ø—ã—Ç–∞–µ–º—Å—è –ø–µ—Ä–µ–ø–∞—Ä—Å–∏—Ç—å –∏–∑ –∫–æ–ª–æ–Ω–∫–∏ json
        predictions = []
        reparse_count = 0
        for idx, row in df_results.iterrows():
            pred = row.get("json_parsed", {})
            is_valid = row.get("is_valid", False)
            
            # –ï—Å–ª–∏ json_parsed –ø—É—Å—Ç–æ–π –∏–ª–∏ –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π, –ø—ã—Ç–∞–µ–º—Å—è –ø–µ—Ä–µ–ø–∞—Ä—Å–∏—Ç—å –∏–∑ –∫–æ–ª–æ–Ω–∫–∏ json
            pred_is_valid = pred and isinstance(pred, dict) and len(pred) > 0
            if not pred_is_valid or not is_valid:
                json_str = row.get("json", "")
                if json_str:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞
                    extracted_json = extract_json_from_response(str(json_str))
                    new_pred = parse_json_safe(extracted_json)
                    if new_pred and isinstance(new_pred, dict) and len(new_pred) > 0:
                        pred = new_pred
                        reparse_count += 1
                    elif not new_pred:
                        # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å —á–µ—Ä–µ–∑ extract_json_from_response, –ø—Ä–æ–±—É–µ–º parse_json_safe –Ω–∞–ø—Ä—è–º—É—é
                        new_pred = parse_json_safe(str(json_str))
                        if new_pred and isinstance(new_pred, dict) and len(new_pred) > 0:
                            pred = new_pred
                            reparse_count += 1
            
            # –ï—Å–ª–∏ pred –≤—Å–µ –µ—â–µ —Å—Ç—Ä–æ–∫–∞, –ø—ã—Ç–∞–µ–º—Å—è –µ—ë —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å
            if isinstance(pred, str):
                try:
                    pred = json.loads(pred)
                except:
                    pred = parse_json_safe(pred)
            
            predictions.append(pred if isinstance(pred, dict) else {})
        
        if reparse_count > 0:
            print(f"   ‚Ä¢ –ü–µ—Ä–µ–ø–∞—Ä—Å–µ–Ω–æ {reparse_count} JSON –∏–∑ –∫–æ–ª–æ–Ω–∫–∏ json —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞
        if len(predictions) != len(ground_truths):
            print(f"‚ö†Ô∏è  –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π ({len(predictions)}) –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º ground truth ({len(ground_truths)})")
            min_len = min(len(predictions), len(ground_truths))
            predictions = predictions[:min_len]
            ground_truths = ground_truths[:min_len]
            print(f"   ‚Ä¢ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è {min_len} –∑–∞–ø–∏—Å–µ–π")
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç—ã –∏ –æ—Ç–≤–µ—Ç—ã –∏–∑ CSV –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ –≤ –º–µ—Ç—Ä–∏–∫–∏
        texts_for_metrics = []
        responses_for_metrics = []
        if "text" in df_results.columns:
            texts_for_metrics = df_results["text"].tolist()
        if "json" in df_results.columns:
            responses_for_metrics = df_results["json"].tolist()
        
        # –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        try:
            # –ü–µ—Ä–µ–¥–∞–µ–º —Ç–µ–∫—Å—Ç—ã –∏ –æ—Ç–≤–µ—Ç—ã –∏–∑ CSV, –µ—Å–ª–∏ –æ–Ω–∏ –¥–æ—Å—Ç—É–ø–Ω—ã
            quality_metrics = calculate_quality_metrics(
                predictions, 
                ground_truths, 
                texts=texts_for_metrics if texts_for_metrics else None, 
                responses=responses_for_metrics if responses_for_metrics else None
            )
            
            # –í—ã–≤–æ–¥–∏–º –¥–µ—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ —á–µ—Ä–µ–∑ MetricsPrinter (cleaned output)
            if quality_metrics:
                MetricsPrinter.print_quality_metrics(quality_metrics)
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–∏ –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞: {e}")
            import traceback
            traceback.print_exc()
            quality_metrics = None
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å –∫–æ–ª–æ–Ω–∫–∏ raw_validation –∏ parsed_validation)
        validation_stats = None
        if "raw_validation" in df_results.columns or "parsed_validation" in df_results.columns:
            print(f"\nüìä –í–´–ß–ò–°–õ–ï–ù–ò–ï –°–¢–ê–¢–ò–°–¢–ò–ö–ò –í–ê–õ–ò–î–ê–¶–ò–ò...")
            try:
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏–∑ CSV
                raw_validations = []
                parsed_validations = []
                
                if "raw_validation" in df_results.columns:
                    for idx, row in df_results.iterrows():
                        raw_val = row.get("raw_validation", "")
                        # –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å, –µ—Å–ª–∏ —ç—Ç–æ —Å—Ç—Ä–æ–∫–∞
                        if isinstance(raw_val, str) and raw_val:
                            # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –ø—É—Å—Ç–∞—è –ª–∏ —Å—Ç—Ä–æ–∫–∞
                            raw_val = raw_val.strip()
                            if raw_val and raw_val != "nan" and raw_val != "None":
                                try:
                                    raw_val = json.loads(raw_val)
                                except (json.JSONDecodeError, ValueError):
                                    # –ï—Å–ª–∏ –Ω–µ JSON, –ø—ã—Ç–∞–µ–º—Å—è —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –∫–∞–∫ Python dict literal
                                    try:
                                        raw_val = eval(raw_val) if raw_val else {}
                                    except:
                                        raw_val = {}
                            else:
                                raw_val = {}
                        elif not isinstance(raw_val, dict):
                            raw_val = {}
                        raw_validations.append(raw_val)
                else:
                    raw_validations = [{}] * len(df_results)
                
                if "parsed_validation" in df_results.columns:
                    for idx, row in df_results.iterrows():
                        # –î–ª—è parsed —É—á–∏—Ç—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ —É—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã (is_valid = True)
                        is_valid = row.get("is_valid", False)
                        if not is_valid:
                            continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã
                        
                        parsed_val = row.get("parsed_validation", "")
                        # –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å, –µ—Å–ª–∏ —ç—Ç–æ —Å—Ç—Ä–æ–∫–∞
                        if isinstance(parsed_val, str) and parsed_val:
                            # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –ø—É—Å—Ç–∞—è –ª–∏ —Å—Ç—Ä–æ–∫–∞
                            parsed_val = parsed_val.strip()
                            if parsed_val and parsed_val != "nan" and parsed_val != "None":
                                try:
                                    parsed_val = json.loads(parsed_val)
                                except (json.JSONDecodeError, ValueError):
                                    # –ï—Å–ª–∏ –Ω–µ JSON, –ø—ã—Ç–∞–µ–º—Å—è —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –∫–∞–∫ Python dict literal
                                    try:
                                        parsed_val = eval(parsed_val) if parsed_val else {}
                                    except:
                                        parsed_val = {}
                            else:
                                parsed_val = {}
                        elif not isinstance(parsed_val, dict):
                            parsed_val = {}
                        parsed_validations.append(parsed_val)
                else:
                    # –ï—Å–ª–∏ –∫–æ–ª–æ–Ω–∫–∏ parsed_validation –Ω–µ—Ç, –Ω–æ –µ—Å—Ç—å is_valid, —É—á–∏—Ç—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–Ω—ã–µ
                    if "is_valid" in df_results.columns:
                        parsed_validations = [{}] * sum(1 for _, row in df_results.iterrows() if row.get("is_valid", False))
                    else:
                        parsed_validations = []
                
                # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                raw_valid_count = sum(1 for v in raw_validations if v.get("is_valid", False))
                parsed_valid_count = sum(1 for v in parsed_validations if v.get("is_valid", False))
                
                # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ (is_valid = True)
                total_parsed_count = sum(1 for _, row in df_results.iterrows() if row.get("is_valid", False))
                total_results_count = len(df_results)
                
                # –î–ª—è parsed: invalid_count = –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–µ —Å—Ä–µ–¥–∏ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã—Ö + –Ω–µ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã
                parsed_invalid_count = (len(parsed_validations) - parsed_valid_count) if parsed_validations else 0
                # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
                not_parsed_count = total_results_count - total_parsed_count
                parsed_invalid_count += not_parsed_count
                
                validation_stats = {
                    "raw_output": {
                        "invalid_count": len(raw_validations) - raw_valid_count,
                        "validation_rate": raw_valid_count / len(raw_validations) if raw_validations else 0.0
                    },
                    "parsed": {
                        "invalid_count": parsed_invalid_count,
                        "validation_rate": parsed_valid_count / total_results_count if total_results_count > 0 else 0.0
                    }
                }
                
                print(f"   ‚úÖ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∞")
                # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤–∞–ª–∏–¥–∞—Ü–∏–∏ cleaned output —á–µ—Ä–µ–∑ MetricsPrinter
                MetricsPrinter.print_validation_stats(validation_stats)
            except Exception as e:
                print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}")
                import traceback
                traceback.print_exc()
                validation_stats = None
        else:
            print(f"\n‚ö†Ô∏è  –ö–æ–ª–æ–Ω–∫–∏ 'raw_validation' –∏ 'parsed_validation' –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ CSV, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏")
        
        # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è raw output (–µ—Å–ª–∏ –µ—Å—Ç—å –∫–æ–ª–æ–Ω–∫–∞ raw_output)
        raw_output_metrics = None
        
        if "raw_output" in df_results.columns:
            print(f"\nüéØ –í–´–ß–ò–°–õ–ï–ù–ò–ï –ú–ï–¢–†–ò–ö –ö–ê–ß–ï–°–¢–í–ê –î–õ–Ø RAW OUTPUT...")
            try:
                # –ó–∞–º–µ–Ω—è–µ–º NaN –∏ None –Ω–∞ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏, –∑–∞—Ç–µ–º –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Å–ø–∏—Å–æ–∫
                raw_outputs = df_results["raw_output"].fillna("").astype(str).tolist()
                # –£–±–∏—Ä–∞–µ–º —Å—Ç—Ä–æ–∫–∏ "nan" –∏ "None"
                raw_outputs = [ro if ro not in ["nan", "None", ""] else "" for ro in raw_outputs]
                print(f"   ‚Ä¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ raw_outputs: {len(raw_outputs)}")
                print(f"   ‚Ä¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ–ø—É—Å—Ç—ã—Ö raw_outputs: {sum(1 for ro in raw_outputs if ro)}")
                
                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º ground_truths –¥–ª—è raw –º–µ—Ç—Ä–∏–∫
                ground_truths_normalized = []
                for gt in ground_truths:
                    if isinstance(gt, list):
                        ground_truths_normalized.append({})
                    elif isinstance(gt, dict):
                        ground_truths_normalized.append(gt)
                    else:
                        ground_truths_normalized.append({})
                
                # –û–±—Ä–µ–∑–∞–µ–º –¥–æ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã
                min_len = min(len(raw_outputs), len(ground_truths_normalized))
                raw_outputs = raw_outputs[:min_len]
                ground_truths_normalized = ground_truths_normalized[:min_len]
                
                raw_output_metrics = calculate_raw_output_metrics(
                    raw_outputs, ground_truths_normalized,
                    texts=texts_for_metrics[:min_len] if texts_for_metrics else None,
                    responses=raw_outputs  # –ò—Å–ø–æ–ª—å–∑—É–µ–º raw_outputs –∫–∞–∫ responses
                )
                print(f"   ‚úÖ –ú–µ—Ç—Ä–∏–∫–∏ raw output –≤—ã—á–∏—Å–ª–µ–Ω—ã")
                if raw_output_metrics:
                    print(f"   ‚Ä¢ Raw –º–µ—Ç—Ä–∏–∫–∏ —Å–æ–¥–µ—Ä–∂–∞—Ç: {list(raw_output_metrics.keys())}")
                    # –í—ã–≤–æ–¥–∏–º raw –º–µ—Ç—Ä–∏–∫–∏ —á–µ—Ä–µ–∑ MetricsPrinter
                    MetricsPrinter.print_raw_output_metrics(raw_output_metrics)
                else:
                    print(f"   ‚ö†Ô∏è Raw –º–µ—Ç—Ä–∏–∫–∏ –ø—É—Å—Ç—ã–µ")
            except Exception as e:
                print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–∏ –º–µ—Ç—Ä–∏–∫ raw output: {e}")
                import traceback
                traceback.print_exc()
                raw_output_metrics = None
        else:
            print(f"\n‚ö†Ô∏è  –ö–æ–ª–æ–Ω–∫–∞ 'raw_output' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ CSV, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ raw –º–µ—Ç—Ä–∏–∫")
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –ø–∞—Ä—Å–∏–Ω–≥—É
        valid_count = sum(1 for p in predictions if p and isinstance(p, dict))
        invalid_count = len(predictions) - valid_count
        parsing_error_rate = invalid_count / len(predictions) if predictions else 0.0
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º parsing errors –∏–∑ CSV, –µ—Å–ª–∏ –µ—Å—Ç—å (—Ç–æ–ª—å–∫–æ –¥–ª—è —Ç–µ—Ö, —á—Ç–æ –≤—Å–µ –µ—â–µ –Ω–µ–≤–∞–ª–∏–¥–Ω—ã –ø–æ—Å–ª–µ –ø–µ—Ä–µ–ø–∞—Ä—Å–∏–Ω–≥–∞)
        parsing_errors = []
        if "json" in df_results.columns:
            for idx, (_, row) in enumerate(df_results.iterrows()):
                pred = predictions[idx] if idx < len(predictions) else {}
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –≤–∞–ª–∏–¥–Ω—ã–º –ø–æ—Å–ª–µ –ø–µ—Ä–µ–ø–∞—Ä—Å–∏–Ω–≥–∞
                if not pred or not isinstance(pred, dict) or len(pred) == 0:
                    json_str = row.get("json", "")
                    if json_str:
                        # –û–±—Ä–µ–∑–∞–µ–º –¥–ª–∏–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –∫–æ–º–ø–∞–∫—Ç–Ω–æ—Å—Ç–∏
                        json_display = str(json_str)[:500] if len(str(json_str)) > 500 else str(json_str)
                        parsing_errors.append(f"–¢–µ–∫—Å—Ç #{idx}: –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π JSON. –û—Ç–≤–µ—Ç: {json_display}")
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º—è –º–æ–¥–µ–ª–∏ –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞, –µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–æ
        if model_name is None:
            file_manager = FileManager()
            filename = file_manager.get_basename(results_csv_path)
            # –§–æ—Ä–º–∞—Ç: results_model_name_timestamp.csv –∏–ª–∏ results_timestamp.csv (–Ω–æ–≤–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞)
            # –£–±–∏—Ä–∞–µ–º –ø—Ä–µ—Ñ–∏–∫—Å "results_" –∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ ".csv"
            name_without_ext = filename.replace("results_", "").replace(".csv", "")
            # –£–±–∏—Ä–∞–µ–º timestamp –≤ –∫–æ–Ω—Ü–µ (—Ñ–æ—Ä–º–∞—Ç: _HHMMSS –∏–ª–∏ _YYYYMMDD_HHMMSS)
            import re
            # –£–±–∏—Ä–∞–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Ç–∏–ø–∞ _123456 –∏–ª–∏ _20260123_123456
            name_without_timestamp = re.sub(r'_\d{4}$|_\d{8}_\d{4}$', '', name_without_ext)
            if name_without_timestamp:
                model_name = name_without_timestamp
            else:
                # –ï—Å–ª–∏ –ø–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è timestamp –Ω–∏—á–µ–≥–æ –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ –∏–º—è
                parts = name_without_ext.split("_")
                if len(parts) >= 2:
                    # –ë–µ—Ä–µ–º –≤—Å–µ —á–∞—Å—Ç–∏ –∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–µ–π (timestamp)
                    model_name = "_".join(parts[:-1])
                else:
                    model_name = "unknown"
        
        # –ê–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ Gemini API (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω)
        gemini_analysis = None
        if use_gemini_analysis and analyze_errors_with_gemini is not None:
            if gemini_api_key is None:
                gemini_api_key = os.environ.get("GEMINI_API_KEY")
            
            if gemini_api_key:
                print(f"\nü§ñ –ó–ê–ü–£–°–ö –ê–ù–ê–õ–ò–ó–ê –ß–ï–†–ï–ó GEMINI API...")
                try:
                    # –î–ª—è reevaluate –Ω–∞–º –Ω—É–∂–Ω—ã –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã - –ø—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ –º–µ—Ç—Ä–∏–∫, –µ—Å–ª–∏ –µ—Å—Ç—å
                    # –ò–ª–∏ —Å–æ–∑–¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä
                    hyperparameters = {"reevaluated": True}
                    
                    # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –º–µ—Ç—Ä–∏–∫, –µ—Å–ª–∏ –æ–Ω —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
                    metrics_file_pattern = f"metrics_{FileManager.sanitize_filename(model_name)}_*.json"
                    file_manager = FileManager()
                    metrics_files = file_manager.find_files(metrics_file_pattern, file_manager.get_dirname(results_csv_path))
                    if metrics_files:
                        # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ñ–∞–π–ª –º–µ—Ç—Ä–∏–∫
                        try:
                            with open(metrics_files[-1], 'r', encoding='utf-8') as f:
                                existing_metrics = json.load(f)
                                hyperparameters = existing_metrics.get("hyperparameters", hyperparameters)
                        except:
                            pass
                    
                    gemini_analysis = analyze_errors_with_gemini(
                        model_name=model_name,
                        parsing_errors=parsing_errors,
                        quality_metrics=quality_metrics or {},
                        hyperparameters=hyperparameters,
                        prompt_full_text=None,  # –î–ª—è reevaluate –ø—Ä–æ–º–ø—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
                        gemini_api_key=gemini_api_key
                    )
                    
                    if gemini_analysis.get("status") == "success":
                        print(f"   ‚úÖ –ê–Ω–∞–ª–∏–∑ –æ—Ç Gemini –ø–æ–ª—É—á–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
                        analysis_text = gemini_analysis.get("analysis", "")
                        if analysis_text:
                            print(f"\n   {'‚îÄ'*76}")
                            print(f"   üìù –ê–ù–ê–õ–ò–ó –ò –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –û–¢ GEMINI:")
                            print(f"   {'‚îÄ'*76}")
                            # –í—ã–≤–æ–¥–∏–º –∞–Ω–∞–ª–∏–∑ —Å –æ—Ç—Å—Ç—É–ø–∞–º–∏ –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
                            analysis_lines = analysis_text.split('\n')
                            for line in analysis_lines[:50]:  # –ü–µ—Ä–≤—ã–µ 50 —Å—Ç—Ä–æ–∫
                                print(f"   {line}")
                            if len(analysis_lines) > 50:
                                print(f"   ... (–µ—â—ë {len(analysis_lines) - 50} —Å—Ç—Ä–æ–∫, –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ –æ—Ç—á—ë—Ç–µ)")
                            print(f"   {'‚îÄ'*76}")
                    else:
                        print(f"   ‚ö†Ô∏è –ê–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ Gemini –Ω–µ —É–¥–∞–ª—Å—è: {gemini_analysis.get('message', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}")
                except Exception as e:
                    print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —á–µ—Ä–µ–∑ Gemini: {e}")
                    gemini_analysis = {
                        "status": "error",
                        "message": str(e)
                    }
            else:
                print(f"   ‚ö†Ô∏è GEMINI_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ Gemini")
        elif use_gemini_analysis and analyze_errors_with_gemini is None:
            print(f"   ‚ö†Ô∏è –ú–æ–¥—É–ª—å gemini_analyzer –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ Gemini")
        print()
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        timestamp = datetime.now().strftime("%Y%m%d_%H%M")
        evaluation_result = {
            "timestamp": timestamp,
            "model_name": model_name,
            "reevaluated_from": results_csv_path,
            "parsing_error_rate": parsing_error_rate,
            "parsing_errors_count": len(parsing_errors),
            "quality_metrics": quality_metrics,
            "raw_output_metrics": raw_output_metrics,  # –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è raw output
            "validation_stats": validation_stats,  # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ Pydantic
            "parsing_errors": parsing_errors,
            "total_samples": len(predictions),
            "valid_json_count": valid_count,
            "invalid_json_count": invalid_count,
            "gemini_analysis": gemini_analysis
        }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        print(f"\nüíæ –°–û–•–†–ê–ù–ï–ù–ò–ï –û–ë–ù–û–í–õ–ï–ù–ù–´–• –†–ï–ó–£–õ–¨–¢–ê–¢–û–í...")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤—ã–π –º–µ—Ç–æ–¥ FileManager –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤—Å–µ—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–µ—Ä–µ–æ—Ü–µ–Ω–∫–∏
        file_manager = FileManager()
        saved_files = file_manager.save_reevaluation_results(
            evaluation_result=evaluation_result,
            results_csv_path=results_csv_path,
            df_results=df_results,
            predictions=predictions,
            quality_metrics=quality_metrics,
            raw_output_metrics=raw_output_metrics,
            timestamp=timestamp,
            model_name=model_name
        )
        
        print(f"‚úÖ –í—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–µ—Ä–µ–æ—Ü–µ–Ω–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ!")
        
        # –í—ã–≤–æ–¥–∏–º —Å–≤–æ–¥–∫—É
        print(f"\n{'='*80}")
        print(f"‚úÖ –ü–ï–†–ï–û–¶–ï–ù–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê!")
        print(f"{'='*80}")
        print(f"üìå –ò—Ç–æ–≥–æ–≤–∞—è —Å–≤–æ–¥–∫–∞:")
        print(f"   ‚Ä¢ –ú–æ–¥–µ–ª—å: {model_name}")
        print(f"   ‚Ä¢ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ç–µ–∫—Å—Ç–æ–≤: {len(predictions)}")
        print(f"   ‚Ä¢ –û—à–∏–±–∫–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞: {parsing_error_rate:.2%} ({invalid_count}/{len(predictions)})")
        if quality_metrics:
            mass_acc = quality_metrics.get('–º–∞—Å—Å–æ–≤–∞—è –¥–æ–ª—è', {}).get('accuracy', 0)
            prochee_acc = quality_metrics.get('–ø—Ä–æ—á–µ–µ', {}).get('accuracy', 0)
            mass_f1 = quality_metrics.get('–º–∞—Å—Å–æ–≤–∞—è –¥–æ–ª—è', {}).get('f1', 0)
            prochee_f1 = quality_metrics.get('–ø—Ä–æ—á–µ–µ', {}).get('f1', 0)
            print(f"   ‚Ä¢ –ö–∞—á–µ—Å—Ç–≤–æ '–º–∞—Å—Å–æ–≤–∞—è –¥–æ–ª—è': Accuracy={mass_acc:.2%}, F1={mass_f1:.2%}")
            print(f"   ‚Ä¢ –ö–∞—á–µ—Å—Ç–≤–æ '–ø—Ä–æ—á–µ–µ': Accuracy={prochee_acc:.2%}, F1={prochee_f1:.2%}")
        print(f"{'='*80}\n")
        
        return evaluation_result

