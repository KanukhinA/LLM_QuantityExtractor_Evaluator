"""
–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–µ–π LLM
"""
import torch
import gc
import time
import pandas as pd
import json
import copy
import glob
from datetime import datetime
from typing import Dict, Any, List, Optional, Callable
import os

from utils import build_prompt3, parse_json_safe, is_valid_json, extract_json_from_response
from metrics import calculate_quality_metrics
from gpu_info import get_gpu_info, get_gpu_memory_usage
from multi_agent_graph import process_with_multi_agent
import re


def sanitize_filename(name: str) -> str:
    """
    –°–∞–Ω–∏—Ç–∏–∑–∏—Ä—É–µ—Ç –∏–º—è –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞.
    –ó–∞–º–µ–Ω—è–µ—Ç –≤—Å–µ –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–µ —Å–∏–º–≤–æ–ª—ã –Ω–∞ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏—è.
    
    Args:
        name: –∏—Å—Ö–æ–¥–Ω–æ–µ –∏–º—è
        
    Returns:
        –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–º—è –¥–ª—è —Ñ–∞–π–ª–∞
    """
    # –ù–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–µ —Å–∏–º–≤–æ–ª—ã –¥–ª—è –∏–º–µ–Ω —Ñ–∞–π–ª–æ–≤ –≤ Windows –∏ Linux: < > : " / \ | ? *
    # –¢–∞–∫–∂–µ –∑–∞–º–µ–Ω—è–µ–º –ø—Ä–æ–±–µ–ª—ã –∏ –¥—Ä—É–≥–∏–µ –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
    invalid_chars = r'[<>:"/\\|?*\s]'
    sanitized = re.sub(invalid_chars, '_', name)
    # –£–¥–∞–ª—è–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏—è
    sanitized = re.sub(r'_+', '_', sanitized)
    # –£–¥–∞–ª—è–µ–º –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏—è –≤ –Ω–∞—á–∞–ª–µ –∏ –∫–æ–Ω—Ü–µ
    sanitized = sanitized.strip('_')
    return sanitized
try:
    from gemini_analyzer import analyze_errors_with_gemini
except ImportError:
    analyze_errors_with_gemini = None


class ModelEvaluator:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –æ—Ü–µ–Ω–∫–∏ LLM –º–æ–¥–µ–ª–µ–π –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ
    """
    
    def __init__(self, 
                 dataset_path: str,
                 ground_truth_path: Optional[str] = None,
                 output_dir: str = "results"):
        """
        Args:
            dataset_path: –ø—É—Ç—å –∫ –¥–∞—Ç–∞—Å–µ—Ç—É (Excel —Ñ–∞–π–ª)
            ground_truth_path: –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –∏—Å—Ç–∏–Ω–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            output_dir: –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        """
        self.dataset_path = dataset_path
        self.ground_truth_path = ground_truth_path
        self.output_dir = output_dir
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        os.makedirs(output_dir, exist_ok=True)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç
        print(f"üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏–∑: {dataset_path}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ –ø–µ—Ä–µ–¥ –∑–∞–≥—Ä—É–∑–∫–æ–π
        if not os.path.exists(dataset_path):
            abs_path = os.path.abspath(dataset_path)
            current_dir = os.getcwd()
            error_msg = (
                f"‚ùå –û—à–∏–±–∫–∞: —Ñ–∞–π–ª –¥–∞—Ç–∞—Å–µ—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω!\n"
                f"   –ü—É—Ç—å: {dataset_path}\n"
                f"   –ê–±—Å–æ–ª—é—Ç–Ω—ã–π –ø—É—Ç—å: {abs_path}\n"
                f"   –¢–µ–∫—É—â–∞—è —Ä–∞–±–æ—á–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {current_dir}\n"
                f"   –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏ –ø—É—Ç—å —É–∫–∞–∑–∞–Ω –ø—Ä–∞–≤–∏–ª—å–Ω–æ."
            )
            raise FileNotFoundError(error_msg)
        
        self.df_full = pd.read_excel(dataset_path)
        print(f"   ‚úÖ –î–∞—Ç–∞—Å–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω: {len(self.df_full)} —Å—Ç—Ä–æ–∫, {len(self.df_full.columns)} –∫–æ–ª–æ–Ω–æ–∫")
        print(f"   üìã –ö–æ–ª–æ–Ω–∫–∏: {', '.join(self.df_full.columns.tolist()[:5])}{'...' if len(self.df_full.columns) > 5 else ''}")
        
        # –£–¥–∞–ª—è–µ–º –∫–æ–ª–æ–Ω–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –Ω—É–∂–Ω—ã –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤
        self.df = self.df_full.drop(["json", "Unnamed: 0"], axis=1, errors='ignore')
        self.texts = self.df["text"].tolist()
        print(f"   ‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(self.texts)} —Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏\n")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º ground truth –∏–∑ —Ç–æ–≥–æ –∂–µ —Ñ–∞–π–ª–∞ (–∫–æ–ª–æ–Ω–∫–∞ json_parsed)
        self.ground_truths = None
        if "json_parsed" in self.df_full.columns:
            try:
                # json_parsed —É–∂–µ —è–≤–ª—è–µ—Ç—Å—è —Å–ª–æ–≤–∞—Ä–µ–º, –Ω–æ –º–æ–∂–µ—Ç –±—ã—Ç—å —Å—Ç—Ä–æ–∫–æ–π
                self.ground_truths = []
                for j in self.df_full["json_parsed"]:
                    if isinstance(j, dict):
                        self.ground_truths.append(j)
                    elif isinstance(j, str):
                        self.ground_truths.append(parse_json_safe(j))
                    else:
                        self.ground_truths.append({})
                non_empty = sum(1 for gt in self.ground_truths if gt)
                print(f"   ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.ground_truths)} ground truth –∑–Ω–∞—á–µ–Ω–∏–π –∏–∑ –∫–æ–ª–æ–Ω–∫–∏ json_parsed")
                print(f"      (–ù–µ–ø—É—Å—Ç—ã—Ö: {non_empty}, –ü—É—Å—Ç—ã—Ö: {len(self.ground_truths) - non_empty})\n")
            except Exception as e:
                print(f"   ‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å ground truth –∏–∑ json_parsed: {e}\n")
        elif ground_truth_path and os.path.exists(ground_truth_path):
            # Fallback: –∑–∞–≥—Ä—É–∑–∫–∞ –∏–∑ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ (—Å—Ç–∞—Ä—ã–π —Å–ø–æ—Å–æ–±)
            try:
                print(f"   üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ ground truth –∏–∑ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞: {ground_truth_path}")
                gt_df = pd.read_excel(ground_truth_path)
                if "json" in gt_df.columns:
                    self.ground_truths = [parse_json_safe(str(j)) for j in gt_df["json"]]
                    print(f"   ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.ground_truths)} ground truth –∑–Ω–∞—á–µ–Ω–∏–π –∏–∑ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞\n")
            except Exception as e:
                print(f"   ‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å ground truth: {e}\n")
        else:
            print(f"   ‚ö†Ô∏è Ground truth –Ω–µ –Ω–∞–π–¥–µ–Ω (–∫–æ–ª–æ–Ω–∫–∞ json_parsed –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç)\n")
    
    def clear_memory(self):
        """–û—á–∏—Å—Ç–∫–∞ GPU –ø–∞–º—è—Ç–∏"""
        print("‚ôªÔ∏è –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ PyTorch...")
        global model, tokenizer
        try:
            del model
        except NameError:
            pass
        try:
            del tokenizer
        except NameError:
            pass
        gc.collect()
        torch.cuda.empty_cache()
        print("‚úÖ –ü–∞–º—è—Ç—å –æ—á–∏—â–µ–Ω–∞")
    
    def evaluate_model(self,
                      model_name: str,
                      load_model_func: Callable,
                      generate_func: Callable,
                      hyperparameters: Dict[str, Any],
                      prompt_template: str = None,
                      max_new_tokens: int = 1024,
                      num_retries: int = 2,
                      verbose: bool = False,
                      use_gemini_analysis: bool = False,
                      gemini_api_key: str = None) -> Dict[str, Any]:
        """
        –û—Ü–µ–Ω–∏–≤–∞–µ—Ç –º–æ–¥–µ–ª—å –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ
        
        Args:
            model_name: –Ω–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
            load_model_func: —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ (–¥–æ–ª–∂–Ω–∞ –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å (model, tokenizer))
            generate_func: —Ñ—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (model, tokenizer, prompt) -> response_text
            hyperparameters: —Å–ª–æ–≤–∞—Ä—å —Å –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ (–º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å multi_agent_mode)
            prompt_template: —à–∞–±–ª–æ–Ω –ø—Ä–æ–º–ø—Ç–∞ (–µ—Å–ª–∏ None, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è build_prompt3)
            max_new_tokens: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–≤—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤
            num_retries: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ –ø—Ä–∏ –æ—à–∏–±–∫–µ
        
        Returns:
            —Å–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –æ—Ü–µ–Ω–∫–∏
        """
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã –∏–∑ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        multi_agent_mode = hyperparameters.get("multi_agent_mode", None)
        use_multi_agent = multi_agent_mode is not None and multi_agent_mode != ""
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –º–æ–¥–µ–ª—å API-–º–æ–¥–µ–ª—å—é
        is_api_model = hyperparameters.get("api_model", False)
        if not is_api_model:
            # –¢–∞–∫–∂–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ —Ç–∏–ø—É –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏
            # –î–ª—è API –º–æ–¥–µ–ª–µ–π tokenizer –±—É–¥–µ—Ç None
            pass  # –ü—Ä–æ–≤–µ—Ä–∏–º –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º num_retries –¥–ª—è API –º–æ–¥–µ–ª–µ–π (10 –ø–æ–ø—ã—Ç–æ–∫)
        if is_api_model:
            num_retries = 10
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ —Ä–µ–∂–∏–º–∞ –¥–ª—è –≤—ã–≤–æ–¥–∞
        if multi_agent_mode:
            mode_name = f"–ú—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω—ã–π ({multi_agent_mode})"
        else:
            mode_name = "–û–¥–Ω–æ–∞–≥–µ–Ω—Ç–Ω—ã–π"
        
        print(f"\n{'='*80}")
        print(f"üöÄ –ù–ê–ß–ê–õ–û –û–¶–ï–ù–ö–ò –ú–û–î–ï–õ–ò")
        print(f"{'='*80}")
        print(f"üìå –ú–æ–¥–µ–ª—å: {model_name}")
        print(f"üìå –î–∞—Ç–∞—Å–µ—Ç: {len(self.texts)} —Ç–µ–∫—Å—Ç–æ–≤")
        print(f"üìå –†–µ–∂–∏–º: {mode_name}")
        print(f"üìå –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã:")
        for key, value in hyperparameters.items():
            print(f"   ‚Ä¢ {key}: {value}")
        print(f"{'='*80}\n")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ API –º–æ–¥–µ–ª—å—é (–¥–æ –∑–∞–≥—Ä—É–∑–∫–∏)
        is_api_model = hyperparameters.get("api_model", False)
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ GPU/API –¥–æ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏
        if is_api_model:
            print(f"üìä –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –†–ï–°–£–†–°–ê–•:")
            print(f"   ‚Ä¢ –¢–∏–ø: API (Google Generative AI)")
            print(f"   ‚Ä¢ –ú–æ–¥–µ–ª—å –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è —á–µ—Ä–µ–∑ API")
            print()
            gpu_info_before = {"api": True}
        else:
            gpu_info_before = get_gpu_info()
            print(f"üìä –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û GPU (–¥–æ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏):")
            print(f"   ‚Ä¢ CUDA –¥–æ—Å—Ç—É–ø–Ω–∞: {gpu_info_before.get('cuda_available', False)}")
            if gpu_info_before.get('cuda_available'):
                print(f"   ‚Ä¢ –ù–∞–∑–≤–∞–Ω–∏–µ GPU: {gpu_info_before.get('gpu_name', 'N/A')}")
                print(f"   ‚Ä¢ –í–µ—Ä—Å–∏—è CUDA: {gpu_info_before.get('cuda_version', 'N/A')}")
                print(f"   ‚Ä¢ –û–±—â–∞—è –ø–∞–º—è—Ç—å: {gpu_info_before.get('gpu_memory_total_gb', 0):.2f} GB")
                print(f"   ‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –ø–∞–º—è—Ç–∏: {gpu_info_before.get('gpu_memory_allocated_gb', 0):.2f} GB")
            print()
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
        print(f"üì¶ –ó–ê–ì–†–£–ó–ö–ê –ú–û–î–ï–õ–ò...")
        start_load = time.time()
        try:
            model, tokenizer = load_model_func()
            load_time = time.time() - start_load
            print(f"‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∑–∞ {load_time:.2f} —Å–µ–∫—É–Ω–¥ ({load_time/60:.2f} –º–∏–Ω—É—Ç)")
        except Exception as e:
            import traceback
            error_details = str(e)
            full_traceback = traceback.format_exc()
            
            print(f"\n{'='*80}")
            print(f"–û–®–ò–ë–ö–ê –ó–ê–ì–†–£–ó–ö–ò –ú–û–î–ï–õ–ò")
            print(f"{'='*80}")
            print(f"–û—à–∏–±–∫–∞: {error_details}")
            print(f"\n–ü–æ–ª–Ω—ã–π traceback:")
            print(f"{'‚îÄ'*80}")
            print(full_traceback)
            print(f"{'‚îÄ'*80}")
            print(f"–î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏ —Ç–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –æ—Ç—á—ë—Ç–µ")
            print(f"{'='*80}\n")
            
            # –û—á–∏—â–∞–µ–º –ø–∞–º—è—Ç—å –ø–æ—Å–ª–µ –æ—à–∏–±–∫–∏ –∑–∞–≥—Ä—É–∑–∫–∏
            self.clear_memory()
            
            return {
                "status": "error",
                "error": f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {error_details}",
                "error_traceback": full_traceback
            }
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ GPU/API –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏
        if is_api_model:
            print(f"üìä –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –†–ï–°–£–†–°–ê–•:")
            print(f"   ‚Ä¢ –¢–∏–ø: API (Google Generative AI)")
            print(f"   ‚Ä¢ –ú–æ–¥–µ–ª—å –¥–æ—Å—Ç—É–ø–Ω–∞ —á–µ—Ä–µ–∑ API")
            print()
            gpu_info_after = {"api": True}
            memory_after_load = {"allocated": 0.0, "reserved": 0.0, "total": 0.0}
        else:
            gpu_info_after = get_gpu_info()
            memory_after_load = get_gpu_memory_usage()
            print(f"üìä –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û GPU (–ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏):")
            print(f"   ‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –ø–∞–º—è—Ç–∏: {memory_after_load['allocated']:.2f} GB")
            print(f"   ‚Ä¢ –ó–∞—Ä–µ–∑–µ—Ä–≤–∏—Ä–æ–≤–∞–Ω–æ –ø–∞–º—è—Ç–∏: {memory_after_load['reserved']:.2f} GB")
            print(f"   ‚Ä¢ –î–æ—Å—Ç—É–ø–Ω–æ –ø–∞–º—è—Ç–∏: {memory_after_load['total'] - memory_after_load['allocated']:.2f} GB")
            print()
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ–º–ø—Ç
        if prompt_template is None:
            prompt_template = build_prompt3
        
        # –û—Ü–µ–Ω–∫–∞ –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ
        results = []
        parsing_errors = []  # –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –æ—à–∏–±–∫–∞–º–∏: {"text_index": int, "text": str, "error": str, "response": str}
        times = []
        memory_samples = []  # –î–ª—è —Å–±–æ—Ä–∞ –∏–∑–º–µ—Ä–µ–Ω–∏–π –ø–∞–º—è—Ç–∏ –≤–æ –≤—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ (—Ç–æ–ª—å–∫–æ –¥–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π)
        total_start_time = time.time()
        
        # –ü–µ—Ä–µ–≤–æ–¥–∏–º –≤ eval —Ä–µ–∂–∏–º —Ç–æ–ª—å–∫–æ –ª–æ–∫–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏
        if not is_api_model and hasattr(model, 'eval'):
            model.eval()
        
        print(f"üîÑ –û–ë–†–ê–ë–û–¢–ö–ê –î–ê–¢–ê–°–ï–¢–ê")
        print(f"{'='*80}")
        print(f"–í—Å–µ–≥–æ —Ç–µ–∫—Å—Ç–æ–≤: {len(self.texts)}")
        print(f"{'='*80}\n")
        
        # –°–æ–∑–¥–∞–µ–º –æ–±–µ—Ä—Ç–∫—É –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –¥–ª—è –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞
        if use_multi_agent:
            if is_api_model:
                # –î–ª—è API –º–æ–¥–µ–ª–µ–π –∏—Å–ø–æ–ª—å–∑—É–µ–º APIGenerator
                from core.generators import APIGenerator
                model_name = hyperparameters.get("model_name", "gemma-3-12b-it")
                generator = APIGenerator(model, tokenizer, model_name=model_name)
            else:
                # –î–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –∏—Å–ø–æ–ª—å–∑—É–µ–º StandardGenerator
                from core.generators import StandardGenerator
                generator = StandardGenerator(model, tokenizer)
        
        interrupted = False
        last_processed_index = -1
        
        try:
            for i, text in enumerate(self.texts):
                response_text = ""
                error_msg = None
                
                if use_multi_agent:
                    # –ú—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω—ã–π –ø–æ–¥—Ö–æ–¥
                    try:
                        # –í—ã–≤–æ–¥–∏–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –ø—Ä–∏ verbose —Ä–µ–∂–∏–º–µ
                        if verbose:
                            print(f"   üîÑ –ú—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ {i+1}/{len(self.texts)}:")
                        start_time = time.time()
                        result = process_with_multi_agent(
                            text=text,
                            generator=generator,
                            max_new_tokens=max_new_tokens,
                            multi_agent_mode=multi_agent_mode
                        )
                        elapsed = time.time() - start_time
                        times.append(elapsed)
                        
                        # –ò–∑–º–µ—Ä—è–µ–º –ø–∞–º—è—Ç—å –≤–æ –≤—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
                        if not is_api_model:
                            memory_sample = get_gpu_memory_usage()
                            memory_samples.append(memory_sample["allocated"])
                        
                        response_text = result.get("response", "")
                        json_part = result.get("json", "")
                        parsed_json = result.get("json_parsed", {})
                        is_valid = result.get("is_valid", False)
                        error_msg = result.get("error")
                        
                        if error_msg:
                            parsing_errors.append({
                                "text_index": i,
                                "text": text,
                                "error": f"–û—à–∏–±–∫–∞ –≤ –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–æ–º –ø–æ–¥—Ö–æ–¥–µ: {error_msg}",
                                "response": response_text[:500] if response_text else ""
                            })
                        
                        if not is_valid and json_part:
                            # –î–ª—è API –º–æ–¥–µ–ª–µ–π —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—ã–π JSON –ø—Ä–∏ verbose
                            json_display = json_part if (is_api_model and verbose) else json_part[:200]
                            parsing_errors.append({
                                "text_index": i,
                                "text": text,
                                "error": f"–ù–µ–≤–∞–ª–∏–¥–Ω—ã–π JSON. –û—Ç–≤–µ—Ç: {json_display}",
                                "response": json_part[:500]
                            })
                        
                        results.append({
                            "text": text,
                            "json": json_part,
                            "json_parsed": parsed_json,
                            "is_valid": is_valid
                        })
                    except Exception as e:
                        error_msg = str(e)
                        import traceback
                        traceback_str = traceback.format_exc()
                        # –î–ª—è API –º–æ–¥–µ–ª–µ–π —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—ã–π traceback
                        traceback_display = traceback_str if is_api_model else traceback_str[:200]
                        parsing_errors.append({
                            "text_index": i,
                            "text": text,
                            "error": f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–æ–º –ø–æ–¥—Ö–æ–¥–µ: {error_msg}. Traceback: {traceback_display}",
                            "response": ""
                        })
                        results.append({
                            "text": text,
                            "json": "",
                            "json_parsed": {},
                            "is_valid": False
                        })
                else:
                    # –û–¥–Ω–æ–∞–≥–µ–Ω—Ç–Ω—ã–π –ø–æ–¥—Ö–æ–¥ (–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π)
                    prompt = prompt_template(text)
                    
                    # –ü–æ–ø—ã—Ç–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
                    for attempt in range(num_retries):
                        try:
                            start_time = time.time()
                            # –ü–µ—Ä–µ–¥–∞–µ–º repetition_penalty –∏–∑ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –µ—Å–ª–∏ –µ—Å—Ç—å
                            repetition_penalty = hyperparameters.get("repetition_penalty")
                            # –î–ª—è API –º–æ–¥–µ–ª–µ–π –ø–µ—Ä–µ–¥–∞–µ–º model_name –∏–∑ hyperparameters
                            if is_api_model and "model_name" in hyperparameters:
                                response_text = generate_func(model, tokenizer, prompt, max_new_tokens, model_name=hyperparameters["model_name"])
                            elif repetition_penalty is not None:
                                response_text = generate_func(model, tokenizer, prompt, max_new_tokens, repetition_penalty=repetition_penalty)
                            elif "enable_thinking" in hyperparameters:
                                # –î–ª—è Qwen3 –ø–µ—Ä–µ–¥–∞–µ–º enable_thinking –∏–∑ hyperparameters
                                response_text = generate_func(model, tokenizer, prompt, max_new_tokens, enable_thinking=hyperparameters.get("enable_thinking", True))
                            else:
                                response_text = generate_func(model, tokenizer, prompt, max_new_tokens)
                            elapsed = time.time() - start_time
                            times.append(elapsed)
                            
                            # –í—ã–≤–æ–¥–∏–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç –∏ –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç –≤ –∫–æ–Ω—Å–æ–ª—å (—Ç–æ–ª—å–∫–æ –ø—Ä–∏ verbose)
                            if verbose:
                                print(f"   üìù –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:")
                                print(f"   {'‚îÄ'*76}")
                                for line in text.split('\n'):
                                    print(f"   {line}")
                                print(f"   {'‚îÄ'*76}")
                                model_type_label = "API –º–æ–¥–µ–ª–∏" if is_api_model else "–º–æ–¥–µ–ª–∏"
                                print(f"   üìã –ü–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç {model_type_label}:")
                                print(f"   {'‚îÄ'*76}")
                                for line in response_text.split('\n'):
                                    print(f"   {line}")
                                print(f"   {'‚îÄ'*76}")
                            
                            # –ò–∑–º–µ—Ä—è–µ–º –ø–∞–º—è—Ç—å –≤–æ –≤—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ (—Ç–æ–ª—å–∫–æ –¥–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π)
                            if not is_api_model:
                                memory_sample = get_gpu_memory_usage()
                                memory_samples.append(memory_sample["allocated"])
                            break
                        except KeyboardInterrupt:
                            # –ü—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ–º KeyboardInterrupt –Ω–∞–≤–µ—Ä—Ö –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Ü–∏–∫–ª–µ
                            raise
                        except Exception as e:
                            error_msg = str(e)
                            # –î–ª—è API –º–æ–¥–µ–ª–µ–π –≤—ã–≤–æ–¥–∏–º –ø–æ–ª–Ω—É—é –æ—à–∏–±–∫—É –±–µ–∑ –æ–±—Ä–µ–∑–∫–∏ (–≤—Å–µ–≥–¥–∞, —Ç–∞–∫ –∫–∞–∫ —ç—Ç–æ –æ—à–∏–±–∫–∞)
                            if is_api_model:
                                print(f"  ‚ö†Ô∏è [{i+1}/{len(self.texts)}] –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (–ø–æ–ø—ã—Ç–∫–∞ {attempt+1}/{num_retries}):")
                                print(f"     {error_msg}")
                            else:
                                # –î–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –æ–±—Ä–µ–∑–∞–µ–º –ø—Ä–∏ –Ω–µ verbose —Ä–µ–∂–∏–º–µ
                                error_display = error_msg if verbose else error_msg[:100]
                                print(f"  ‚ö†Ô∏è [{i+1}/{len(self.texts)}] –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (–ø–æ–ø—ã—Ç–∫–∞ {attempt+1}/{num_retries}): {error_display}")
                            if attempt < num_retries - 1:
                                time.sleep(4 + attempt * 2)
                            else:
                                # –ï—Å–ª–∏ –≤—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ—à–∏–±–∫–µ
                                import traceback
                                traceback_str = traceback.format_exc()
                                # –î–ª—è API –º–æ–¥–µ–ª–µ–π —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—ã–π traceback
                                traceback_display = traceback_str if is_api_model else traceback_str[:200]
                                parsing_errors.append({
                                    "text_index": i,
                                    "text": text,
                                    "error": f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ—Å–ª–µ {num_retries} –ø–æ–ø—ã—Ç–æ–∫: {error_msg}. Traceback: {traceback_display}",
                                    "response": ""
                                })
                    
                    if not response_text:
                        print(f"  ‚ùå [{i+1}/{len(self.texts)}] –û—Ç–≤–µ—Ç –Ω–µ –ø–æ–ª—É—á–µ–Ω ‚Äî –ø—Ä–æ–ø—É—Å–∫")
                        if error_msg:
                            # –î–ª—è API –º–æ–¥–µ–ª–µ–π –≤—ã–≤–æ–¥–∏–º –ø–æ–ª–Ω—É—é –æ—à–∏–±–∫—É –±–µ–∑ –æ–±—Ä–µ–∑–∫–∏ (–≤—Å–µ–≥–¥–∞, —Ç–∞–∫ –∫–∞–∫ —ç—Ç–æ –æ—à–∏–±–∫–∞)
                            if is_api_model:
                                print(f"     –ü–æ—Å–ª–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞: {error_msg}")
                            else:
                                # –î–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –æ–±—Ä–µ–∑–∞–µ–º –ø—Ä–∏ –Ω–µ verbose —Ä–µ–∂–∏–º–µ
                                error_display = error_msg if verbose else error_msg[:200]
                                print(f"     –ü–æ—Å–ª–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞: {error_display}")
                        parsing_errors.append(f"–¢–µ–∫—Å—Ç #{i}: –Ω–µ –ø–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç. –û—à–∏–±–∫–∞: {error_msg if error_msg else '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞'}")
                        results.append({
                            "text": text,
                            "json": "",
                            "json_parsed": {},
                            "is_valid": False
                        })
                        continue
                    
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º JSON
                    json_part = extract_json_from_response(response_text)
                    parsed_json = parse_json_safe(json_part)
                    is_valid = is_valid_json(json_part)
                    
                    if not is_valid:
                        # –î–ª—è API –º–æ–¥–µ–ª–µ–π –ø—Ä–∏ verbose –≤—ã–≤–æ–¥–∏–º –ø–æ–ª–Ω—ã–π JSON, –∏–Ω–∞—á–µ –æ–±—Ä–µ–∑–∞–µ–º
                        json_display = json_part if (is_api_model and verbose) else (json_part[:200] if len(json_part) > 200 else json_part)
                        parsing_errors.append({
                            "text_index": i,
                            "text": text,
                            "error": f"–ù–µ–≤–∞–ª–∏–¥–Ω—ã–π JSON. –û—Ç–≤–µ—Ç: {json_display}",
                            "response": json_part[:500]
                        })
                    
                    results.append({
                        "text": text,
                        "json": json_part,
                        "json_parsed": parsed_json,
                        "is_valid": is_valid
                    })
            
            # –í—ã–≤–æ–¥–∏–º –ø—Ä–æ–≥—Ä–µ—Å—Å –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
            elapsed_total = time.time() - total_start_time
            avg_time = sum(times) / len(times) if times else 0
            progress_pct = ((i + 1) / len(self.texts)) * 100
            remaining = len(self.texts) - (i + 1)
            eta_seconds = avg_time * remaining if avg_time > 0 else 0
            eta_minutes = eta_seconds / 60
            
            valid_count = sum(1 for r in results if r["is_valid"])
            invalid_count = (i + 1) - valid_count
            
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –≤—Ä–µ–º—è
            if eta_minutes < 1:
                eta_str = f"{eta_seconds:.0f} —Å–µ–∫"
            else:
                eta_str = f"{eta_minutes:.1f} –º–∏–Ω"
            
            # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç—É—Å –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç verbose)
            if verbose:
                # –ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥ –ø—Ä–∏ verbose=True
                status_line = (
                    f"  ‚úÖ [{i + 1}/{len(self.texts)}] ({progress_pct:.1f}%) | "
                    f"–í–∞–ª–∏–¥–Ω—ã—Ö: {valid_count} | –ù–µ–≤–∞–ª–∏–¥–Ω—ã—Ö: {invalid_count} | "
                    f"ETA: {eta_str}"
                )
                print(status_line)
            else:
                # –ö–æ—Ä–æ—Ç–∫–∏–π –≤—ã–≤–æ–¥ –ø—Ä–∏ verbose=False (—Ç–æ–ª—å–∫–æ —Å—á–µ—Ç—á–∏–∫ –∏ –æ—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏)
                status_line = (
                    f"  [{i + 1}/{len(self.texts)}] "
                    f"‚úì: {valid_count} ‚úó: {invalid_count} | "
                    f"ETA: {eta_str}"
                )
                print(f"\r{status_line}", end="", flush=True)
            
            # –ü–æ–¥—Ä–æ–±–Ω—ã–π –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 10 —Ç–µ–∫—Å—Ç–æ–≤ –∏–ª–∏ –≤ –∫–æ–Ω—Ü–µ (—Ç–æ–ª—å–∫–æ –ø—Ä–∏ verbose)
            if verbose and ((i + 1) % 10 == 0 or (i + 1) == len(self.texts)):
                print()  # –ù–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –¥–ª—è –ø–æ–¥—Ä–æ–±–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞
                print(f"     üìä –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
                print(f"        ‚Ä¢ –ü—Ä–æ–≥—Ä–µ—Å—Å: {progress_pct:.1f}% ({i + 1}/{len(self.texts)})")
                print(f"        ‚Ä¢ –í–∞–ª–∏–¥–Ω—ã—Ö JSON: {valid_count} | –ù–µ–≤–∞–ª–∏–¥–Ω—ã—Ö: {invalid_count}")
                print(f"        ‚Ä¢ –°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å: {avg_time:.3f} —Å–µ–∫/–æ—Ç–≤–µ—Ç")
                print(f"        ‚Ä¢ –ü—Ä–æ—à–ª–æ –≤—Ä–µ–º–µ–Ω–∏: {elapsed_total/60:.1f} –º–∏–Ω | –û—Å—Ç–∞–ª–æ—Å—å: ~{eta_minutes:.1f} –º–∏–Ω")
                print()
                
                last_processed_index = i
            else:
                last_processed_index = i
        
        except KeyboardInterrupt:
            interrupted = True
            last_processed_index = i if 'i' in locals() else -1
            print(f"\n\n{'='*80}")
            print(f"‚ö†Ô∏è  –ü–†–ï–†–´–í–ê–ù–ò–ï –û–ë–†–ê–ë–û–¢–ö–ò –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–ï–ú")
            print(f"{'='*80}")
            print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ç–µ–∫—Å—Ç–æ–≤: {len(results)}/{len(self.texts)}")
            print(f"–ü–æ—Å–ª–µ–¥–Ω–∏–π –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –∏–Ω–¥–µ–∫—Å: {last_processed_index + 1}")
            print()
            
            while True:
                try:
                    choice = input("–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:\n  1 - –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ –∑–∞–≤–µ—Ä—à–∏—Ç—å\n  2 - –ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É\n  3 - –ó–∞–≤–µ—Ä—à–∏—Ç—å –±–µ–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è\n–í–∞—à –≤—ã–±–æ—Ä (1/2/3): ").strip()
                    
                    if choice == "1":
                        print("\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
                        # –ü—Ä–æ–¥–æ–ª–∂–∏–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                        break
                    elif choice == "2":
                        print("\n‚ñ∂Ô∏è  –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É...\n")
                        # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ü–∏–∫–ª —Å —Ç–æ–≥–æ –º–µ—Å—Ç–∞, –≥–¥–µ –æ—Å—Ç–∞–Ω–æ–≤–∏–ª–∏—Å—å
                        try:
                            for i in range(last_processed_index + 1, len(self.texts)):
                                response_text = ""
                                error_msg = None
                                
                                if use_multi_agent:
                                    try:
                                        # –í—ã–≤–æ–¥–∏–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –ø—Ä–∏ verbose —Ä–µ–∂–∏–º–µ
                                        if verbose:
                                            print(f"   üîÑ –ú—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ {i+1}/{len(self.texts)}:")
                                        start_time = time.time()
                                        result = process_with_multi_agent(
                                            text=self.texts[i],
                                            generator=generator,
                                            max_new_tokens=max_new_tokens,
                                            multi_agent_mode=multi_agent_mode
                                        )
                                        elapsed = time.time() - start_time
                                        times.append(elapsed)
                                        
                                        memory_sample = get_gpu_memory_usage()
                                        memory_samples.append(memory_sample["allocated"])
                                        
                                        response_text = result.get("response", "")
                                        json_part = result.get("json", "")
                                        parsed_json = result.get("json_parsed", {})
                                        is_valid = result.get("is_valid", False)
                                        error_msg = result.get("error")
                                        
                                        if error_msg:
                                            parsing_errors.append(f"–¢–µ–∫—Å—Ç #{i}: –æ—à–∏–±–∫–∞ –≤ –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–æ–º –ø–æ–¥—Ö–æ–¥–µ. –û—à–∏–±–∫–∞: {error_msg}")
                                        
                                        if not is_valid and json_part:
                                            # –î–ª—è API –º–æ–¥–µ–ª–µ–π –ø—Ä–∏ verbose –≤—ã–≤–æ–¥–∏–º –ø–æ–ª–Ω—ã–π JSON, –∏–Ω–∞—á–µ –æ–±—Ä–µ–∑–∞–µ–º
                                            json_display = json_part if (is_api_model and verbose) else (json_part[:200] if len(json_part) > 200 else json_part)
                                            parsing_errors.append(f"–¢–µ–∫—Å—Ç #{i}: –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π JSON. –û—Ç–≤–µ—Ç: {json_display}")
                                        
                                        results.append({
                                            "text": self.texts[i],
                                            "json": json_part,
                                            "json_parsed": parsed_json,
                                            "is_valid": is_valid
                                        })
                                    except Exception as e:
                                        error_msg = str(e)
                                        import traceback
                                        parsing_errors.append(f"–¢–µ–∫—Å—Ç #{i}: –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–æ–º –ø–æ–¥—Ö–æ–¥–µ. –û—à–∏–±–∫–∞: {error_msg}. Traceback: {traceback.format_exc()[:200]}")
                                        results.append({
                                            "text": self.texts[i],
                                            "json": "",
                                            "json_parsed": {},
                                            "is_valid": False
                                        })
                                else:
                                    prompt = prompt_template(self.texts[i])
                                    
                                    for attempt in range(num_retries):
                                        try:
                                            start_time = time.time()
                                            repetition_penalty = hyperparameters.get("repetition_penalty")
                                            # –î–ª—è API –º–æ–¥–µ–ª–µ–π –ø–µ—Ä–µ–¥–∞–µ–º model_name –∏–∑ hyperparameters
                                            if is_api_model and "model_name" in hyperparameters:
                                                response_text = generate_func(model, tokenizer, prompt, max_new_tokens, model_name=hyperparameters["model_name"])
                                            elif repetition_penalty is not None:
                                                response_text = generate_func(model, tokenizer, prompt, max_new_tokens, repetition_penalty=repetition_penalty)
                                            elif "enable_thinking" in hyperparameters:
                                                # –î–ª—è Qwen3 –ø–µ—Ä–µ–¥–∞–µ–º enable_thinking –∏–∑ hyperparameters
                                                response_text = generate_func(model, tokenizer, prompt, max_new_tokens, enable_thinking=hyperparameters.get("enable_thinking", True))
                                            else:
                                                response_text = generate_func(model, tokenizer, prompt, max_new_tokens)
                                            elapsed = time.time() - start_time
                                            times.append(elapsed)
                                            
                                            # –í—ã–≤–æ–¥–∏–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç –∏ –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç –≤ –∫–æ–Ω—Å–æ–ª—å (—Ç–æ–ª—å–∫–æ –ø—Ä–∏ verbose)
                                            if verbose:
                                                print(f"   üìù –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:")
                                                print(f"   {'‚îÄ'*76}")
                                                for line in self.texts[i].split('\n'):
                                                    print(f"   {line}")
                                                print(f"   {'‚îÄ'*76}")
                                                model_type_label = "API –º–æ–¥–µ–ª–∏" if is_api_model else "–º–æ–¥–µ–ª–∏"
                                                print(f"   üìã –ü–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç {model_type_label}:")
                                                print(f"   {'‚îÄ'*76}")
                                                for line in response_text.split('\n'):
                                                    print(f"   {line}")
                                                print(f"   {'‚îÄ'*76}")
                                            
                                            # –ò–∑–º–µ—Ä—è–µ–º –ø–∞–º—è—Ç—å –≤–æ –≤—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ (—Ç–æ–ª—å–∫–æ –¥–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π)
                                            if not is_api_model:
                                                memory_sample = get_gpu_memory_usage()
                                                memory_samples.append(memory_sample["allocated"])
                                            break
                                        except Exception as e:
                                            error_msg = str(e)
                                            # –î–ª—è API –º–æ–¥–µ–ª–µ–π –≤—ã–≤–æ–¥–∏–º –ø–æ–ª–Ω—É—é –æ—à–∏–±–∫—É –±–µ–∑ –æ–±—Ä–µ–∑–∫–∏ (–≤—Å–µ–≥–¥–∞, —Ç–∞–∫ –∫–∞–∫ —ç—Ç–æ –æ—à–∏–±–∫–∞)
                                            if is_api_model:
                                                print(f"  ‚ö†Ô∏è [{i+1}/{len(self.texts)}] –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (–ø–æ–ø—ã—Ç–∫–∞ {attempt+1}/{num_retries}):")
                                                print(f"     {error_msg}")
                                            else:
                                                # –î–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –æ–±—Ä–µ–∑–∞–µ–º –ø—Ä–∏ –Ω–µ verbose —Ä–µ–∂–∏–º–µ
                                                error_display = error_msg if verbose else error_msg[:100]
                                                print(f"  ‚ö†Ô∏è [{i+1}/{len(self.texts)}] –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (–ø–æ–ø—ã—Ç–∫–∞ {attempt+1}/{num_retries}): {error_display}")
                                            if attempt < num_retries - 1:
                                                time.sleep(4 + attempt * 2)
                                            else:
                                                import traceback
                                                traceback_str = traceback.format_exc()
                                                # –î–ª—è API –º–æ–¥–µ–ª–µ–π —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—ã–π traceback
                                                if is_api_model:
                                                    parsing_errors.append(f"–¢–µ–∫—Å—Ç #{i}: –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ—Å–ª–µ {num_retries} –ø–æ–ø—ã—Ç–æ–∫. –û—à–∏–±–∫–∞: {error_msg}. Traceback: {traceback_str}")
                                                else:
                                                    parsing_errors.append(f"–¢–µ–∫—Å—Ç #{i}: –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ—Å–ª–µ {num_retries} –ø–æ–ø—ã—Ç–æ–∫. –û—à–∏–±–∫–∞: {error_msg}. Traceback: {traceback_str[:200]}")
                                
                                    if not response_text:
                                        print(f"  ‚ùå [{i+1}/{len(self.texts)}] –û—Ç–≤–µ—Ç –Ω–µ –ø–æ–ª—É—á–µ–Ω ‚Äî –ø—Ä–æ–ø—É—Å–∫")
                                        if error_msg:
                                            # –î–ª—è API –º–æ–¥–µ–ª–µ–π –≤—ã–≤–æ–¥–∏–º –ø–æ–ª–Ω—É—é –æ—à–∏–±–∫—É –±–µ–∑ –æ–±—Ä–µ–∑–∫–∏ (–≤—Å–µ–≥–¥–∞, —Ç–∞–∫ –∫–∞–∫ —ç—Ç–æ –æ—à–∏–±–∫–∞)
                                            if is_api_model:
                                                print(f"     –ü–æ—Å–ª–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞: {error_msg}")
                                            else:
                                                # –î–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –æ–±—Ä–µ–∑–∞–µ–º –ø—Ä–∏ –Ω–µ verbose —Ä–µ–∂–∏–º–µ
                                                error_display = error_msg if verbose else error_msg[:200]
                                                print(f"     –ü–æ—Å–ª–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞: {error_display}")
                                        parsing_errors.append({
                                            "text_index": i,
                                            "text": self.texts[i],
                                            "error": f"–ù–µ –ø–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç. –û—à–∏–±–∫–∞: {error_msg if error_msg else '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞'}",
                                            "response": ""
                                        })
                                        results.append({
                                            "text": self.texts[i],
                                            "json": "",
                                            "json_parsed": {},
                                            "is_valid": False
                                        })
                                        continue
                                    
                                    json_part = extract_json_from_response(response_text)
                                    parsed_json = parse_json_safe(json_part)
                                    is_valid = is_valid_json(json_part)
                                    
                                    if not is_valid:
                                        # –î–ª—è API –º–æ–¥–µ–ª–µ–π –ø—Ä–∏ verbose –≤—ã–≤–æ–¥–∏–º –ø–æ–ª–Ω—ã–π JSON, –∏–Ω–∞—á–µ –æ–±—Ä–µ–∑–∞–µ–º
                                        json_display = json_part if (is_api_model and verbose) else (json_part[:200] if len(json_part) > 200 else json_part)
                                        parsing_errors.append({
                                            "text_index": i,
                                            "text": self.texts[i],
                                            "error": f"–ù–µ–≤–∞–ª–∏–¥–Ω—ã–π JSON. –û—Ç–≤–µ—Ç: {json_display}",
                                            "response": response_text[:500] if response_text else json_part[:500]
                                        })
                                    
                                    results.append({
                                        "text": self.texts[i],
                                        "json": json_part,
                                        "json_parsed": parsed_json,
                                        "is_valid": is_valid
                                    })
                                
                                # –í—ã–≤–æ–¥–∏–º –ø—Ä–æ–≥—Ä–µ—Å—Å
                                elapsed_total = time.time() - total_start_time
                                avg_time = sum(times) / len(times) if times else 0
                                progress_pct = ((i + 1) / len(self.texts)) * 100
                                remaining = len(self.texts) - (i + 1)
                                eta_seconds = avg_time * remaining if avg_time > 0 else 0
                                eta_minutes = eta_seconds / 60
                                
                                valid_count = sum(1 for r in results if r["is_valid"])
                                invalid_count = (i + 1) - valid_count
                                
                                if eta_minutes < 1:
                                    eta_str = f"{eta_seconds:.0f} —Å–µ–∫"
                                else:
                                    eta_str = f"{eta_minutes:.1f} –º–∏–Ω"
                                
                                status_line = (
                                    f"  [{i + 1}/{len(self.texts)}] "
                                    f"‚úì: {valid_count} ‚úó: {invalid_count} | "
                                    f"–°–∫–æ—Ä–æ—Å—Ç—å: {avg_time:.2f}—Å/–æ—Ç–≤–µ—Ç | "
                                    f"–û—Å—Ç–∞–ª–æ—Å—å: ~{eta_str}"
                                )
                                print(f"\r{status_line}", end="", flush=True)
                                
                                # –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ç–æ–ª—å–∫–æ –ø—Ä–∏ verbose
                                if verbose and ((i + 1) % 10 == 0 or (i + 1) == len(self.texts)):
                                    print()
                                    print(f"     üìä –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
                                    print(f"        ‚Ä¢ –ü—Ä–æ–≥—Ä–µ—Å—Å: {progress_pct:.1f}% ({i + 1}/{len(self.texts)})")
                                    print(f"        ‚Ä¢ –í–∞–ª–∏–¥–Ω—ã—Ö JSON: {valid_count} | –ù–µ–≤–∞–ª–∏–¥–Ω—ã—Ö: {invalid_count}")
                                    print(f"        ‚Ä¢ –°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å: {avg_time:.3f} —Å–µ–∫/–æ—Ç–≤–µ—Ç")
                                    print(f"        ‚Ä¢ –ü—Ä–æ—à–ª–æ –≤—Ä–µ–º–µ–Ω–∏: {elapsed_total/60:.1f} –º–∏–Ω | –û—Å—Ç–∞–ª–æ—Å—å: ~{eta_minutes:.1f} –º–∏–Ω")
                                    print()
                        except KeyboardInterrupt:
                            print(f"\n\n‚ö†Ô∏è  –ü–æ–≤—Ç–æ—Ä–Ω–æ–µ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏–µ. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
                            interrupted = True
                            break
                        break
                    elif choice == "3":
                        print("\n‚ùå –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ –±–µ–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è...")
                        return {
                            "status": "interrupted",
                            "message": "–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º –±–µ–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è",
                            "processed_count": len(results),
                            "total_count": len(self.texts)
                        }
                    else:
                        print("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ 1, 2 –∏–ª–∏ 3")
                except KeyboardInterrupt:
                    print("\n\n‚ö†Ô∏è  –ü–æ–≤—Ç–æ—Ä–Ω–æ–µ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏–µ. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
                    interrupted = True
                    break
        
        # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        total_time = time.time() - total_start_time
        print(f"\n{'='*80}")
        print(f"üìä –í–´–ß–ò–°–õ–ï–ù–ò–ï –ú–ï–¢–†–ò–ö")
        print(f"{'='*80}\n")
        
        # –ü—Ä–æ—Ü–µ–Ω—Ç –Ω–µ–≤–∞–ª–∏–¥–Ω—ã—Ö JSON
        invalid_count = sum(1 for r in results if not r["is_valid"])
        valid_count = len(results) - invalid_count
        parsing_error_rate = invalid_count / len(results) if results else 0.0
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        avg_speed = sum(times) / len(times) if times else 0.0
        min_time = min(times) if times else 0.0
        max_time = max(times) if times else 0.0
        total_inference_time = sum(times)
        
        # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ –≤–æ –≤—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ –≤—Å–µ—Ö –∏–∑–º–µ—Ä–µ–Ω–∏–π –≤–æ –≤—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
        if is_api_model:
            # –î–ª—è API –º–æ–¥–µ–ª–µ–π –Ω–µ –∏–∑–º–µ—Ä—è–µ–º –ø–∞–º—è—Ç—å
            memory_during_inference_avg = 0.0
            memory_during_inference_max = 0.0
            memory_during_inference_min = 0.0
        elif memory_samples:
            memory_during_inference_avg = sum(memory_samples) / len(memory_samples)
            memory_during_inference_max = max(memory_samples)
            memory_during_inference_min = min(memory_samples)
        else:
            # Fallback: –∏–∑–º–µ—Ä—è–µ–º —Å–µ–π—á–∞—Å, –µ—Å–ª–∏ –Ω–µ –±—ã–ª–æ –∏–∑–º–µ—Ä–µ–Ω–∏–π
            current_memory = get_gpu_memory_usage()
            memory_during_inference_avg = current_memory["allocated"]
            memory_during_inference_max = current_memory["allocated"]
            memory_during_inference_min = current_memory["allocated"]
        
        # –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–µ
        memory_during_inference = {"allocated": memory_during_inference_avg}
        
        print(f"‚è±Ô∏è  –í–†–ï–ú–Ø –í–´–ü–û–õ–ù–ï–ù–ò–Ø:")
        print(f"   ‚Ä¢ –û–±—â–µ–µ –≤—Ä–µ–º—è: {total_time/60:.2f} –º–∏–Ω—É—Ç ({total_time:.2f} —Å–µ–∫—É–Ω–¥)")
        print(f"   ‚Ä¢ –í—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞: {total_inference_time/60:.2f} –º–∏–Ω—É—Ç")
        print(f"   ‚Ä¢ –í—Ä–µ–º—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {load_time:.2f} —Å–µ–∫—É–Ω–¥")
        print(f"   ‚Ä¢ –°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞: {avg_speed:.3f} —Å–µ–∫/–æ—Ç–≤–µ—Ç")
        print(f"   ‚Ä¢ –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è: {min_time:.3f} —Å–µ–∫")
        print(f"   ‚Ä¢ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è: {max_time:.3f} —Å–µ–∫")
        print()
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è –≤—ã–≤–æ–¥–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        example_text = self.texts[0] if self.texts else "–ü—Ä–∏–º–µ—Ä —Ç–µ–∫—Å—Ç–∞"
        
        workflow_description = ""  # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –≤—ã–≤–æ–¥–µ
        workflow_prompts = None  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
        if use_multi_agent:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏—Å—Ç–µ–º—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ workflow –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø—Ä–æ–º–ø—Ç–æ–≤
            from workflow_config import get_workflow_prompts
            workflow_prompts = get_workflow_prompts(multi_agent_mode, example_text)
            full_prompt_example = workflow_prompts["full_prompt_example"]
            workflow_description = workflow_prompts.get("description", "")
        else:
            full_prompt_example = prompt_template(example_text)
        
        # –í—ã–≤–æ–¥–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–º–ø—Ç–µ –∏ —Ä–µ–∂–∏–º–µ
        print(f"üìù –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ù–´–ô –ü–†–û–ú–ü–¢:")
        if use_multi_agent:
            print(f"   ‚Ä¢ –†–µ–∂–∏–º: –ú—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω—ã–π ({multi_agent_mode})")
            print(f"   ‚Ä¢ –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã –∏–∑ prompt_config.py")
            print(f"   ‚Ä¢ –ê–≥–µ–Ω—Ç—ã: {workflow_description}")
            print(f"   ‚Ä¢ –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –≤—Å–µ—Ö –ø—Ä–æ–º–ø—Ç–æ–≤ (–ø—Ä–∏–º–µ—Ä —Å –ø–µ—Ä–≤—ã–º —Ç–µ–∫—Å—Ç–æ–º):")
            print(f"{'‚îÄ'*80}")
            # –í—ã–≤–æ–¥–∏–º –ø—Ä–æ–º–ø—Ç—ã —Å –æ—Ç—Å—Ç—É–ø–∞–º–∏ –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
            prompt_lines = full_prompt_example.split('\n')
            for line in prompt_lines[:50]:  # –ü–µ—Ä–≤—ã–µ 50 —Å—Ç—Ä–æ–∫, —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–≥—Ä—É–∂–∞—Ç—å –∫–æ–Ω—Å–æ–ª—å
                print(f"   {line}")
            if len(prompt_lines) > 50:
                print(f"   ... (–µ—â—ë {len(prompt_lines) - 50} —Å—Ç—Ä–æ–∫, –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ –æ—Ç—á—ë—Ç–µ)")
            print(f"{'‚îÄ'*80}")
        else:
            print(f"   ‚Ä¢ –†–µ–∂–∏–º: –û–¥–Ω–æ–∞–≥–µ–Ω—Ç–Ω—ã–π")
            print(f"   ‚Ä¢ –®–∞–±–ª–æ–Ω: {prompt_template.__name__ if hasattr(prompt_template, '__name__') else str(prompt_template)}")
            print(f"   ‚Ä¢ –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –ø—Ä–æ–º–ø—Ç–∞ (–ø—Ä–∏–º–µ—Ä —Å –ø–µ—Ä–≤—ã–º —Ç–µ–∫—Å—Ç–æ–º):")
            print(f"{'‚îÄ'*80}")
            # –í—ã–≤–æ–¥–∏–º –ø—Ä–æ–º–ø—Ç —Å –æ—Ç—Å—Ç—É–ø–∞–º–∏ –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
            prompt_lines = full_prompt_example.split('\n')
            for line in prompt_lines[:30]:  # –ü–µ—Ä–≤—ã–µ 30 —Å—Ç—Ä–æ–∫, —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–≥—Ä—É–∂–∞—Ç—å –∫–æ–Ω—Å–æ–ª—å
                print(f"   {line}")
            if len(prompt_lines) > 30:
                print(f"   ... (–µ—â—ë {len(prompt_lines) - 30} —Å—Ç—Ä–æ–∫, –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ –æ—Ç—á—ë—Ç–µ)")
            print(f"{'‚îÄ'*80}")
        print()
        
        if is_api_model:
            print(f"üíæ –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –†–ï–°–£–†–°–ê–•:")
            print(f"   ‚Ä¢ –¢–∏–ø: API (Google Generative AI)")
            print(f"   ‚Ä¢ –ú–æ–¥–µ–ª—å –¥–æ—Å—Ç—É–ø–Ω–∞ —á–µ—Ä–µ–∑ API")
            print()
        else:
            print(f"üíæ –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–ï –ü–ê–ú–Ø–¢–ò:")
            print(f"   ‚Ä¢ –ü–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {memory_after_load['allocated']:.2f} GB")
            print(f"   ‚Ä¢ –í–æ –≤—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ (—Å—Ä–µ–¥–Ω–µ–µ): {memory_during_inference_avg:.2f} GB")
            print(f"   ‚Ä¢ –í–æ –≤—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ (–º–∞–∫—Å–∏–º—É–º): {memory_during_inference_max:.2f} GB")
            print(f"   ‚Ä¢ –í–æ –≤—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ (–º–∏–Ω–∏–º—É–º): {memory_during_inference_min:.2f} GB")
            print(f"   ‚Ä¢ –ò–∑–º–µ–Ω–µ–Ω–∏–µ –æ—Ç –∑–∞–≥—Ä—É–∑–∫–∏: {memory_during_inference_avg - memory_after_load['allocated']:+.2f} GB")
            print()
        
        print(f"üìù –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–ê–†–°–ò–ù–ì–ê JSON:")
        print(f"   ‚Ä¢ –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(results)}")
        print(f"   ‚Ä¢ –í–∞–ª–∏–¥–Ω—ã—Ö JSON: {valid_count} ({100-parsing_error_rate*100:.1f}%)")
        print(f"   ‚Ä¢ –ù–µ–≤–∞–ª–∏–¥–Ω—ã—Ö JSON: {invalid_count} ({parsing_error_rate*100:.1f}%)")
        print(f"   ‚Ä¢ –û—à–∏–±–æ–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞: {len(parsing_errors)}")
        if parsing_errors:
            print(f"\n   üìã –ü–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫ –æ—à–∏–±–æ–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞ ({len(parsing_errors)} –æ—à–∏–±–æ–∫):")
            print(f"   {'‚îÄ'*76}")
            for i, error in enumerate(parsing_errors, 1):
                # –û–±—Ä–µ–∑–∞–µ–º –¥–ª–∏–Ω–Ω—ã–µ –æ—à–∏–±–∫–∏ –¥–ª—è –∫–æ–Ω—Å–æ–ª–∏
                error_display = error[:200] + "..." if len(error) > 200 else error
                print(f"   {i}. {error_display}")
            print(f"   {'‚îÄ'*76}")
        print()
        
        # –ö–∞—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–æ–≤ (–µ—Å–ª–∏ –µ—Å—Ç—å ground truth)
        quality_metrics = None
        if self.ground_truths and len(self.ground_truths) == len(results):
            try:
                print(f"üéØ –í–´–ß–ò–°–õ–ï–ù–ò–ï –ú–ï–¢–†–ò–ö –ö–ê–ß–ï–°–¢–í–ê...")
                # –§–∏–ª—å—Ç—Ä—É–µ–º –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º predictions: –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä—è–º–∏
                predictions = []
                for r in results:
                    json_parsed = r.get("json_parsed", {})
                    # –ï—Å–ª–∏ —ç—Ç–æ —Å–ø–∏—Å–æ–∫, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∏–ª–∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å–ª–æ–≤–∞—Ä—å
                    if isinstance(json_parsed, list):
                        # –ï—Å–ª–∏ —Å–ø–∏—Å–æ–∫ –ø—É—Å—Ç–æ–π –∏–ª–∏ —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–µ —Å–ª–æ–≤–∞—Ä–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å
                        predictions.append({})
                    elif isinstance(json_parsed, dict):
                        predictions.append(json_parsed)
                    else:
                        predictions.append({})
                
                # –¢–∞–∫–∂–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º ground_truths
                ground_truths_normalized = []
                for gt in self.ground_truths:
                    if isinstance(gt, list):
                        ground_truths_normalized.append({})
                    elif isinstance(gt, dict):
                        ground_truths_normalized.append(gt)
                    else:
                        ground_truths_normalized.append({})
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç—ã –∏ –æ—Ç–≤–µ—Ç—ã –∏–∑ results
                texts_for_metrics = []
                responses_for_metrics = []
                for r in results:
                    texts_for_metrics.append(r.get("text", ""))
                    responses_for_metrics.append(r.get("json", ""))  # json —Å–æ–¥–µ—Ä–∂–∏—Ç –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏
                
                quality_metrics = calculate_quality_metrics(
                    predictions, ground_truths_normalized,
                    texts=texts_for_metrics,
                    responses=responses_for_metrics
                )
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ quality_metrics - —ç—Ç–æ —Å–ª–æ–≤–∞—Ä—å
                if not isinstance(quality_metrics, dict):
                    print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞: calculate_quality_metrics –≤–µ—Ä–Ω—É–ª–∞ –Ω–µ —Å–ª–æ–≤–∞—Ä—å, –∞ {type(quality_metrics)}")
                    quality_metrics = None
                else:
                    mass_dolya = quality_metrics.get('–º–∞—Å—Å–æ–≤–∞—è –¥–æ–ª—è', {})
                    prochee = quality_metrics.get('–ø—Ä–æ—á–µ–µ', {})
                    
                    print(f"   ‚úÖ –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –≤—ã—á–∏—Å–ª–µ–Ω—ã:")
                    print(f"   üìä –ì—Ä—É–ø–ø–∞ '–º–∞—Å—Å–æ–≤–∞—è –¥–æ–ª—è':")
                    print(f"      ‚Ä¢ Accuracy: {mass_dolya.get('accuracy', 0):.2%}")
                    print(f"      ‚Ä¢ Precision: {mass_dolya.get('precision', 0):.2%}")
                    print(f"      ‚Ä¢ Recall: {mass_dolya.get('recall', 0):.2%}")
                    print(f"      ‚Ä¢ F1-score: {mass_dolya.get('f1', 0):.2%}")
                    print(f"      ‚Ä¢ TP: {mass_dolya.get('tp', 0)}, FP: {mass_dolya.get('fp', 0)}, FN: {mass_dolya.get('fn', 0)}")
                    print(f"      ‚Ä¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏–π: {mass_dolya.get('–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ_—Å—Ä–∞–≤–Ω–µ–Ω–∏–π', 0)}")
                    print(f"      ‚Ä¢ –ü—Ä–∏–º–µ—Ä—ã –æ—à–∏–±–æ–∫: {len(mass_dolya.get('–æ—à–∏–±–∫–∏', []))}")
                    print(f"   üìä –ì—Ä—É–ø–ø–∞ '–ø—Ä–æ—á–µ–µ':")
                    print(f"      ‚Ä¢ Accuracy: {prochee.get('accuracy', 0):.2%}")
                    print(f"      ‚Ä¢ Precision: {prochee.get('precision', 0):.2%}")
                    print(f"      ‚Ä¢ Recall: {prochee.get('recall', 0):.2%}")
                    print(f"      ‚Ä¢ F1-score: {prochee.get('f1', 0):.2%}")
                    print(f"      ‚Ä¢ TP: {prochee.get('tp', 0)}, FP: {prochee.get('fp', 0)}, FN: {prochee.get('fn', 0)}")
                    print(f"      ‚Ä¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏–π: {prochee.get('–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ_—Å—Ä–∞–≤–Ω–µ–Ω–∏–π', 0)}")
                    print(f"      ‚Ä¢ –ü—Ä–∏–º–µ—Ä—ã –æ—à–∏–±–æ–∫: {len(prochee.get('–æ—à–∏–±–∫–∏', []))}")
            except Exception as e:
                print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–∏ –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞: {e}")
                import traceback
                if verbose:
                    traceback.print_exc()
        else:
            print(f"   ‚ö†Ô∏è Ground truth –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω –∏–ª–∏ –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç –ø–æ —Ä–∞–∑–º–µ—Ä—É —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏")
            if not self.ground_truths:
                print(f"      (Ground truth –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ)")
            elif len(self.ground_truths) != len(results):
                print(f"      (–†–∞–∑–º–µ—Ä—ã –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç: GT={len(self.ground_truths)}, Results={len(results)})")
        print()
        
        # –ê–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ Gemini API (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω)
        gemini_analysis = None
        if use_gemini_analysis and analyze_errors_with_gemini is not None:
            if gemini_api_key is None:
                gemini_api_key = os.environ.get("GEMINI_API_KEY")
            
            if gemini_api_key:
                print(f"ü§ñ –ó–ê–ü–£–°–ö –ê–ù–ê–õ–ò–ó–ê –ß–ï–†–ï–ó GEMINI API...")
                try:
                    gemini_analysis = analyze_errors_with_gemini(
                        model_name=model_name,
                        parsing_errors=parsing_errors,
                        quality_metrics=quality_metrics or {},
                        hyperparameters=hyperparameters,
                        prompt_full_text=full_prompt_example,
                        gemini_api_key=gemini_api_key
                    )
                    
                    if gemini_analysis.get("status") == "success":
                        print(f"   ‚úÖ –ê–Ω–∞–ª–∏–∑ –æ—Ç Gemini –ø–æ–ª—É—á–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
                        analysis_text = gemini_analysis.get("analysis", "")
                        if analysis_text:
                            print(f"\n   {'‚îÄ'*76}")
                            print(f"   üìù –ê–ù–ê–õ–ò–ó –ò –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –û–¢ GEMINI:")
                            print(f"   {'‚îÄ'*76}")
                            # –í—ã–≤–æ–¥–∏–º –∞–Ω–∞–ª–∏–∑ —Å –æ—Ç—Å—Ç—É–ø–∞–º–∏ –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
                            analysis_lines = analysis_text.split('\n')
                            for line in analysis_lines[:50]:  # –ü–µ—Ä–≤—ã–µ 50 —Å—Ç—Ä–æ–∫
                                print(f"   {line}")
                            if len(analysis_lines) > 50:
                                print(f"   ... (–µ—â—ë {len(analysis_lines) - 50} —Å—Ç—Ä–æ–∫, –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ –æ—Ç—á—ë—Ç–µ)")
                            print(f"   {'‚îÄ'*76}")
                    else:
                        print(f"   ‚ö†Ô∏è –ê–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ Gemini –Ω–µ —É–¥–∞–ª—Å—è: {gemini_analysis.get('message', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}")
                except Exception as e:
                    print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —á–µ—Ä–µ–∑ Gemini: {e}")
                    gemini_analysis = {
                        "status": "error",
                        "message": str(e)
                    }
            else:
                print(f"   ‚ö†Ô∏è GEMINI_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ Gemini")
        elif use_gemini_analysis and analyze_errors_with_gemini is None:
            print(f"   ‚ö†Ô∏è –ú–æ–¥—É–ª—å gemini_analyzer –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ Gemini")
        print()
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–º–ø—Ç–∞—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –æ—Ç—á—ë—Ç
        if use_multi_agent:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–∂–µ –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ workflow_prompts (–∏–∑–±–µ–≥–∞–µ–º –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è –≤—ã–∑–æ–≤–∞)
            prompt_info = workflow_prompts["prompt_info"]
        else:
            # –î–ª—è –æ–¥–Ω–æ–∞–≥–µ–Ω—Ç–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞ full_prompt_example —É–∂–µ —Å–æ–∑–¥–∞–Ω –≤—ã—à–µ
            prompt_info = None
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (—á—Ç–æ–±—ã –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –∑–Ω–∞—á–µ–Ω–∏–π)
        hyperparameters_to_save = copy.deepcopy(hyperparameters)
        
        evaluation_result = {
            "timestamp": datetime.now().strftime("%Y%m%d_%H%M%S"),
            "model_name": model_name,
            "interrupted": interrupted,
            "processed_count": len(results),
            "total_count": len(self.texts),
            "multi_agent_mode": multi_agent_mode if use_multi_agent else None,
            "gpu_info": gpu_info_before if not is_api_model else {"api": True},
            "gpu_memory_after_load_gb": memory_after_load["allocated"] if not is_api_model else 0.0,
            "gpu_memory_during_inference_gb": memory_during_inference_avg if not is_api_model else 0.0,
            "gpu_memory_during_inference_max_gb": memory_during_inference_max if not is_api_model else 0.0,
            "gpu_memory_during_inference_min_gb": memory_during_inference_min if not is_api_model else 0.0,
            "api_model": is_api_model,
            "average_response_time_seconds": avg_speed,
            "parsing_error_rate": parsing_error_rate,
            "parsing_errors_count": len(parsing_errors),
            "quality_metrics": quality_metrics,
            "hyperparameters": hyperparameters_to_save,
            "prompt_template": prompt_template.__name__ if hasattr(prompt_template, '__name__') else str(prompt_template) if not use_multi_agent else f"multi_agent_{multi_agent_mode}",
            "prompt_full_text": full_prompt_example,
            "prompt_info": prompt_info,
            "parsing_errors": parsing_errors,
            "total_samples": len(results),
            "valid_json_count": len(results) - invalid_count,
            "invalid_json_count": invalid_count,
            "gemini_analysis": gemini_analysis
        }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        print(f"üíæ –°–û–•–†–ê–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í...")
        self._save_results(evaluation_result, results)
        
        print(f"\n{'='*80}")
        if interrupted:
            print(f"‚ö†Ô∏è  –û–¶–ï–ù–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê –° –ü–†–ï–†–´–í–ê–ù–ò–ï–ú")
        else:
            print(f"‚úÖ –û–¶–ï–ù–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê –£–°–ü–ï–®–ù–û!")
        print(f"{'='*80}\n")
        
        return evaluation_result
    
    def _save_results(self, evaluation_result: Dict[str, Any], results: List[Dict[str, Any]]):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ñ–∞–π–ª—ã"""
        timestamp = evaluation_result["timestamp"]
        model_name_safe = sanitize_filename(evaluation_result["model_name"])
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–æ–º —Ä–µ–∂–∏–º–µ –≤ –∏–º—è —Ñ–∞–π–ª–∞, –µ—Å–ª–∏ –æ–Ω –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è
        multi_agent_mode = evaluation_result.get("multi_agent_mode")
        multi_agent_suffix = f"_{multi_agent_mode}" if multi_agent_mode else ""
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        df_results = pd.DataFrame(results)
        csv_path = os.path.join(self.output_dir, f"results_{model_name_safe}{multi_agent_suffix}_{timestamp}.csv")
        df_results.to_csv(csv_path, index=False, encoding='utf-8-sig')
        print(f"üíæ –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {csv_path}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ JSON
        evaluation_result_for_json = copy.deepcopy(evaluation_result)
        quality_metrics_for_json = evaluation_result_for_json.get("quality_metrics")
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –æ—à–∏–±–∫–∏ –∏–∑ quality_metrics (–æ–Ω–∏ —É–∂–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ —Å–ª–æ–≤–∞—Ä–µ–π)
        all_quality_errors = []
        if quality_metrics_for_json:
            for group in ["–º–∞—Å—Å–æ–≤–∞—è –¥–æ–ª—è", "–ø—Ä–æ—á–µ–µ"]:
                if group in quality_metrics_for_json:
                    # –ë–µ—Ä–µ–º –≤—Å–µ –æ—à–∏–±–∫–∏ (–Ω–µ —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 10)
                    group_errors = quality_metrics_for_json[group].get("–≤—Å–µ_–æ—à–∏–±–∫–∏", [])
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –æ—à–∏–±–∫–∏ —É–∂–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ —Å–ª–æ–≤–∞—Ä–µ–π
                    for error in group_errors:
                        if isinstance(error, dict):
                            all_quality_errors.append(error)
                        else:
                            # –î–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏: –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å—Ç—Ä–æ–∫—É –≤ —Å–ª–æ–≤–∞—Ä—å
                            all_quality_errors.append({"error": str(error)})
                    # –£–¥–∞–ª—è–µ–º –ø–æ–ª–µ "–≤—Å–µ_–æ—à–∏–±–∫–∏" –∏ "–æ—à–∏–±–∫–∏" –ø–µ—Ä–µ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≤ JSON (—á—Ç–æ–±—ã –Ω–µ –¥—É–±–ª–∏—Ä–æ–≤–∞—Ç—å)
                    quality_metrics_for_json[group].pop("–≤—Å–µ_–æ—à–∏–±–∫–∏", None)
                    quality_metrics_for_json[group].pop("–æ—à–∏–±–∫–∏", None)
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –æ—à–∏–±–∫–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        parsing_errors_list = evaluation_result_for_json.get("parsing_errors", [])
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º parsing_errors –∏ quality_errors
        all_errors = parsing_errors_list + all_quality_errors
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –ø–æ —Ç–µ–∫—Å—Ç–∞–º
        errors_by_text = {}  # {text_index: {"text": str, "response": str, "errors": [str]}}
        
        for error in all_errors:
            if isinstance(error, dict):
                text_idx = error.get("text_index", 0)
                text = error.get("text", "")
                response = error.get("response", "")
                error_msg = error.get("error", "")
                
                if text_idx not in errors_by_text:
                    errors_by_text[text_idx] = {
                        "text_index": text_idx,
                        "text": text,
                        "response": response,
                        "errors": []
                    }
                
                # –î–æ–±–∞–≤–ª—è–µ–º –æ—à–∏–±–∫—É –≤ —Å–ø–∏—Å–æ–∫ –æ—à–∏–±–æ–∫ –¥–ª—è —ç—Ç–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
                if error_msg:
                    errors_by_text[text_idx]["errors"].append(error_msg)
                
                # –û–±–Ω–æ–≤–ª—è–µ–º text –∏ response, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å (–º–æ–≥—É—Ç –±—ã—Ç—å —Ä–∞–∑–Ω—ã–º–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –æ—à–∏–±–æ–∫ –æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞)
                if text and not errors_by_text[text_idx]["text"]:
                    errors_by_text[text_idx]["text"] = text
                if response and not errors_by_text[text_idx]["response"]:
                    errors_by_text[text_idx]["response"] = response
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å–ø–∏—Å–æ–∫ –∑–∞–ø–∏—Å–µ–π (–∫–∞–∂–¥–∞—è –∑–∞–ø–∏—Å—å - —Ç–µ–∫—Å—Ç —Å –µ–≥–æ –æ—à–∏–±–∫–∞–º–∏)
        errors_for_save = list(errors_by_text.values())
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ—à–∏–±–∫–∏ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        # –í—Å–µ –æ—à–∏–±–∫–∏ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–º –≤–∏–¥–µ: —Å–ø–∏—Å–æ–∫ –∑–∞–ø–∏—Å–µ–π {text_index, text, response, errors}
        evaluation_result_for_json["–æ—à–∏–±–∫–∏"] = errors_for_save
        
        metrics_path = os.path.join(self.output_dir, f"metrics_{model_name_safe}{multi_agent_suffix}_{timestamp}.json")
        with open(metrics_path, 'w', encoding='utf-8') as f:
            json.dump(evaluation_result_for_json, f, ensure_ascii=False, indent=2)
        print(f"üíæ –ú–µ—Ç—Ä–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {metrics_path}")
        print(f"   üìã –°–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {list(evaluation_result.get('hyperparameters', {}).keys())}")
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –æ–±—â–∏–π —Ñ–∞–π–ª —Å–æ –≤—Å–µ–º–∏ –ø—Ä–æ–≥–æ–Ω–∞–º–∏
        summary_path = os.path.join(self.output_dir, "evaluation_summary.jsonl")
        with open(summary_path, 'a', encoding='utf-8') as f:
            f.write(json.dumps(evaluation_result, ensure_ascii=False) + '\n')
        print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç –¥–æ–±–∞–≤–ª–µ–Ω –≤ –æ–±—â–∏–π —Ñ–∞–π–ª: {summary_path}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—à–∏–±–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª
        quality_metrics = evaluation_result.get("quality_metrics")
        if quality_metrics:
            errors_path = os.path.join(self.output_dir, f"quality_errors_{model_name_safe}{multi_agent_suffix}_{timestamp}.txt")
            with open(errors_path, 'w', encoding='utf-8') as f:
                f.write(f"–û—à–∏–±–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–ª—è –º–æ–¥–µ–ª–∏: {evaluation_result['model_name']}\n")
                f.write(f"–î–∞—Ç–∞: {timestamp}\n")
                f.write(f"{'='*80}\n\n")
                
                # –û—à–∏–±–∫–∏ –¥–ª—è –≥—Ä—É–ø–ø—ã "–º–∞—Å—Å–æ–≤–∞—è –¥–æ–ª—è" (–∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ_–æ—à–∏–±–∫–∏, –µ—Å–ª–∏ –µ—Å—Ç—å, –∏–Ω–∞—á–µ –æ—à–∏–±–∫–∏)
                mass_dolya = quality_metrics.get('–º–∞—Å—Å–æ–≤–∞—è –¥–æ–ª—è', {})
                mass_errors = mass_dolya.get('–≤—Å–µ_–æ—à–∏–±–∫–∏', mass_dolya.get('–æ—à–∏–±–∫–∏', []))
                if mass_errors:
                    f.write(f"–û–®–ò–ë–ö–ò –ö–ê–ß–ï–°–¢–í–ê: –ú–ê–°–°–û–í–ê–Ø –î–û–õ–Ø\n")
                    f.write(f"–í—Å–µ–≥–æ –æ—à–∏–±–æ–∫: {len(mass_errors)}\n")
                    f.write(f"{'‚îÄ'*80}\n")
                    for i, error in enumerate(mass_errors, 1):
                        f.write(f"{i}. {error}\n")
                    f.write(f"\n")
                else:
                    f.write(f"–û–®–ò–ë–ö–ò –ö–ê–ß–ï–°–¢–í–ê: –ú–ê–°–°–û–í–ê–Ø –î–û–õ–Ø\n")
                    f.write(f"–û—à–∏–±–æ–∫ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ.\n\n")
                
                # –û—à–∏–±–∫–∏ –¥–ª—è –≥—Ä—É–ø–ø—ã "–ø—Ä–æ—á–µ–µ" (–∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ_–æ—à–∏–±–∫–∏, –µ—Å–ª–∏ –µ—Å—Ç—å, –∏–Ω–∞—á–µ –æ—à–∏–±–∫–∏)
                prochee = quality_metrics.get('–ø—Ä–æ—á–µ–µ', {})
                prochee_errors = prochee.get('–≤—Å–µ_–æ—à–∏–±–∫–∏', prochee.get('–æ—à–∏–±–∫–∏', []))
                if prochee_errors:
                    f.write(f"–û–®–ò–ë–ö–ò –ö–ê–ß–ï–°–¢–í–ê: –ü–†–û–ß–ï–ï\n")
                    f.write(f"–í—Å–µ–≥–æ –æ—à–∏–±–æ–∫: {len(prochee_errors)}\n")
                    f.write(f"{'‚îÄ'*80}\n")
                    for i, error in enumerate(prochee_errors, 1):
                        f.write(f"{i}. {error}\n")
                    f.write(f"\n")
                else:
                    f.write(f"–û–®–ò–ë–ö–ò –ö–ê–ß–ï–°–¢–í–ê: –ü–†–û–ß–ï–ï\n")
                    f.write(f"–û—à–∏–±–æ–∫ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ.\n\n")
            
            print(f"üíæ –û—à–∏–±–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {errors_path}")
    
    @staticmethod
    def reevaluate_from_file(
        results_csv_path: str,
        dataset_path: str,
        output_dir: str = "results",
        model_name: str = None,
        use_gemini_analysis: bool = False,
        gemini_api_key: str = None
    ) -> Dict[str, Any]:
        """
        –ü–µ—Ä–µ–æ—Ü–µ–Ω–∏–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–≥–æ CSV —Ñ–∞–π–ª–∞ –±–µ–∑ –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ –º–æ–¥–µ–ª–∏.
        
        Args:
            results_csv_path: –ø—É—Ç—å –∫ CSV —Ñ–∞–π–ª—É —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, results_model_name_timestamp.csv)
            dataset_path: –ø—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É –¥–∞—Ç–∞—Å–µ—Ç—É –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è ground truth
            output_dir: –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            model_name: –∏–º—è –º–æ–¥–µ–ª–∏ (–µ—Å–ª–∏ None, –∏–∑–≤–ª–µ–∫–∞–µ—Ç—Å—è –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞)
        
        Returns:
            —Å–ª–æ–≤–∞—Ä—å —Å –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏
        """
        print(f"\n{'='*80}")
        print(f"üîÑ –ü–ï–†–ï–û–¶–ï–ù–ö–ê –†–ï–ó–£–õ–¨–¢–ê–¢–û–í –ò–ó –§–ê–ô–õ–ê")
        print(f"{'='*80}\n")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑ CSV
        print(f"üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏–∑: {results_csv_path}")
        if not os.path.exists(results_csv_path):
            raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {results_csv_path}")
        
        df_results = pd.read_csv(results_csv_path)
        print(f"   ‚Ä¢ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(df_results)}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
        required_columns = ['text', 'json_parsed']
        missing_columns = [col for col in required_columns if col not in df_results.columns]
        if missing_columns:
            raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {missing_columns}")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º ground truth –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞
        print(f"üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ ground truth –∏–∑: {dataset_path}")
        df_full = pd.read_excel(dataset_path)
        
        if "json_parsed" not in df_full.columns:
            raise ValueError("–í –¥–∞—Ç–∞—Å–µ—Ç–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–æ–ª–æ–Ω–∫–∞ 'json_parsed' —Å ground truth")
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º ground truth
        ground_truths = []
        for idx, row in df_full.iterrows():
            gt = row.get("json_parsed", {})
            if isinstance(gt, str):
                try:
                    gt = json.loads(gt)
                except:
                    gt = parse_json_safe(gt)
            ground_truths.append(gt if isinstance(gt, dict) else {})
        
        print(f"   ‚Ä¢ –ó–∞–≥—Ä—É–∂–µ–Ω–æ ground truth –∑–∞–ø–∏—Å–µ–π: {len(ground_truths)}")
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        # –ï—Å–ª–∏ json_parsed –ø—É—Å—Ç–æ–π –∏–ª–∏ –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π, –ø—ã—Ç–∞–µ–º—Å—è –ø–µ—Ä–µ–ø–∞—Ä—Å–∏—Ç—å –∏–∑ –∫–æ–ª–æ–Ω–∫–∏ json
        predictions = []
        reparse_count = 0
        for idx, row in df_results.iterrows():
            pred = row.get("json_parsed", {})
            is_valid = row.get("is_valid", False)
            
            # –ï—Å–ª–∏ json_parsed –ø—É—Å—Ç–æ–π –∏–ª–∏ –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π, –ø—ã—Ç–∞–µ–º—Å—è –ø–µ—Ä–µ–ø–∞—Ä—Å–∏—Ç—å –∏–∑ –∫–æ–ª–æ–Ω–∫–∏ json
            pred_is_valid = pred and isinstance(pred, dict) and len(pred) > 0
            if not pred_is_valid or not is_valid:
                json_str = row.get("json", "")
                if json_str:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞
                    extracted_json = extract_json_from_response(str(json_str))
                    new_pred = parse_json_safe(extracted_json)
                    if new_pred and isinstance(new_pred, dict) and len(new_pred) > 0:
                        pred = new_pred
                        reparse_count += 1
                    elif not new_pred:
                        # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å —á–µ—Ä–µ–∑ extract_json_from_response, –ø—Ä–æ–±—É–µ–º parse_json_safe –Ω–∞–ø—Ä—è–º—É—é
                        new_pred = parse_json_safe(str(json_str))
                        if new_pred and isinstance(new_pred, dict) and len(new_pred) > 0:
                            pred = new_pred
                            reparse_count += 1
            
            # –ï—Å–ª–∏ pred –≤—Å–µ –µ—â–µ —Å—Ç—Ä–æ–∫–∞, –ø—ã—Ç–∞–µ–º—Å—è –µ—ë —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å
            if isinstance(pred, str):
                try:
                    pred = json.loads(pred)
                except:
                    pred = parse_json_safe(pred)
            
            predictions.append(pred if isinstance(pred, dict) else {})
        
        if reparse_count > 0:
            print(f"   ‚Ä¢ –ü–µ—Ä–µ–ø–∞—Ä—Å–µ–Ω–æ {reparse_count} JSON –∏–∑ –∫–æ–ª–æ–Ω–∫–∏ json —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞
        if len(predictions) != len(ground_truths):
            print(f"‚ö†Ô∏è  –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π ({len(predictions)}) –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º ground truth ({len(ground_truths)})")
            min_len = min(len(predictions), len(ground_truths))
            predictions = predictions[:min_len]
            ground_truths = ground_truths[:min_len]
            print(f"   ‚Ä¢ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è {min_len} –∑–∞–ø–∏—Å–µ–π")
        
        # –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        print(f"\nüìä –í–´–ß–ò–°–õ–ï–ù–ò–ï –ú–ï–¢–†–ò–ö –ö–ê–ß–ï–°–¢–í–ê...")
        try:
            # –í reevaluate –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–∞ –∫ —Ç–µ–∫—Å—Ç–∞–º –∏ –æ—Ç–≤–µ—Ç–∞–º, –ø–µ—Ä–µ–¥–∞–µ–º None
            quality_metrics = calculate_quality_metrics(predictions, ground_truths, texts=None, responses=None)
            print(f"‚úÖ –ú–µ—Ç—Ä–∏–∫–∏ —É—Å–ø–µ—à–Ω–æ –≤—ã—á–∏—Å–ª–µ–Ω—ã")
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–∏ –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞: {e}")
            import traceback
            traceback.print_exc()
            quality_metrics = None
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –ø–∞—Ä—Å–∏–Ω–≥—É
        valid_count = sum(1 for p in predictions if p and isinstance(p, dict))
        invalid_count = len(predictions) - valid_count
        parsing_error_rate = invalid_count / len(predictions) if predictions else 0.0
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º parsing errors –∏–∑ CSV, –µ—Å–ª–∏ –µ—Å—Ç—å (—Ç–æ–ª—å–∫–æ –¥–ª—è —Ç–µ—Ö, —á—Ç–æ –≤—Å–µ –µ—â–µ –Ω–µ–≤–∞–ª–∏–¥–Ω—ã –ø–æ—Å–ª–µ –ø–µ—Ä–µ–ø–∞—Ä—Å–∏–Ω–≥–∞)
        parsing_errors = []
        if "json" in df_results.columns:
            for idx, (_, row) in enumerate(df_results.iterrows()):
                pred = predictions[idx] if idx < len(predictions) else {}
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –≤–∞–ª–∏–¥–Ω—ã–º –ø–æ—Å–ª–µ –ø–µ—Ä–µ–ø–∞—Ä—Å–∏–Ω–≥–∞
                if not pred or not isinstance(pred, dict) or len(pred) == 0:
                    json_str = row.get("json", "")
                    if json_str:
                        # –û–±—Ä–µ–∑–∞–µ–º –¥–ª–∏–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –∫–æ–º–ø–∞–∫—Ç–Ω–æ—Å—Ç–∏
                        json_display = str(json_str)[:500] if len(str(json_str)) > 500 else str(json_str)
                        parsing_errors.append(f"–¢–µ–∫—Å—Ç #{idx}: –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π JSON. –û—Ç–≤–µ—Ç: {json_display}")
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º—è –º–æ–¥–µ–ª–∏ –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞, –µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–æ
        if model_name is None:
            filename = os.path.basename(results_csv_path)
            # –§–æ—Ä–º–∞—Ç: results_model_name_timestamp.csv
            parts = filename.replace("results_", "").replace(".csv", "").split("_")
            if len(parts) >= 2:
                # –ë–µ—Ä–µ–º –≤—Å–µ —á–∞—Å—Ç–∏ –∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–µ–π (timestamp)
                model_name = "_".join(parts[:-1])
            else:
                model_name = "unknown"
        
        # –ê–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ Gemini API (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω)
        gemini_analysis = None
        if use_gemini_analysis and analyze_errors_with_gemini is not None:
            if gemini_api_key is None:
                gemini_api_key = os.environ.get("GEMINI_API_KEY")
            
            if gemini_api_key:
                print(f"\nü§ñ –ó–ê–ü–£–°–ö –ê–ù–ê–õ–ò–ó–ê –ß–ï–†–ï–ó GEMINI API...")
                try:
                    # –î–ª—è reevaluate –Ω–∞–º –Ω—É–∂–Ω—ã –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã - –ø—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ –º–µ—Ç—Ä–∏–∫, –µ—Å–ª–∏ –µ—Å—Ç—å
                    # –ò–ª–∏ —Å–æ–∑–¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä
                    hyperparameters = {"reevaluated": True}
                    
                    # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –º–µ—Ç—Ä–∏–∫, –µ—Å–ª–∏ –æ–Ω —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
                    metrics_file_pattern = f"metrics_{sanitize_filename(model_name)}_*.json"
                    metrics_files = glob.glob(os.path.join(os.path.dirname(results_csv_path), metrics_file_pattern))
                    if metrics_files:
                        # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ñ–∞–π–ª –º–µ—Ç—Ä–∏–∫
                        try:
                            with open(metrics_files[-1], 'r', encoding='utf-8') as f:
                                existing_metrics = json.load(f)
                                hyperparameters = existing_metrics.get("hyperparameters", hyperparameters)
                        except:
                            pass
                    
                    gemini_analysis = analyze_errors_with_gemini(
                        model_name=model_name,
                        parsing_errors=parsing_errors,
                        quality_metrics=quality_metrics or {},
                        hyperparameters=hyperparameters,
                        prompt_full_text=None,  # –î–ª—è reevaluate –ø—Ä–æ–º–ø—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
                        gemini_api_key=gemini_api_key
                    )
                    
                    if gemini_analysis.get("status") == "success":
                        print(f"   ‚úÖ –ê–Ω–∞–ª–∏–∑ –æ—Ç Gemini –ø–æ–ª—É—á–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
                        analysis_text = gemini_analysis.get("analysis", "")
                        if analysis_text:
                            print(f"\n   {'‚îÄ'*76}")
                            print(f"   üìù –ê–ù–ê–õ–ò–ó –ò –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –û–¢ GEMINI:")
                            print(f"   {'‚îÄ'*76}")
                            # –í—ã–≤–æ–¥–∏–º –∞–Ω–∞–ª–∏–∑ —Å –æ—Ç—Å—Ç—É–ø–∞–º–∏ –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
                            analysis_lines = analysis_text.split('\n')
                            for line in analysis_lines[:50]:  # –ü–µ—Ä–≤—ã–µ 50 —Å—Ç—Ä–æ–∫
                                print(f"   {line}")
                            if len(analysis_lines) > 50:
                                print(f"   ... (–µ—â—ë {len(analysis_lines) - 50} —Å—Ç—Ä–æ–∫, –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ –æ—Ç—á—ë—Ç–µ)")
                            print(f"   {'‚îÄ'*76}")
                    else:
                        print(f"   ‚ö†Ô∏è –ê–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ Gemini –Ω–µ —É–¥–∞–ª—Å—è: {gemini_analysis.get('message', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}")
                except Exception as e:
                    print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —á–µ—Ä–µ–∑ Gemini: {e}")
                    gemini_analysis = {
                        "status": "error",
                        "message": str(e)
                    }
            else:
                print(f"   ‚ö†Ô∏è GEMINI_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ Gemini")
        elif use_gemini_analysis and analyze_errors_with_gemini is None:
            print(f"   ‚ö†Ô∏è –ú–æ–¥—É–ª—å gemini_analyzer –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ Gemini")
        print()
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        evaluation_result = {
            "timestamp": timestamp,
            "model_name": model_name,
            "reevaluated_from": results_csv_path,
            "parsing_error_rate": parsing_error_rate,
            "parsing_errors_count": len(parsing_errors),
            "quality_metrics": quality_metrics,
            "parsing_errors": parsing_errors,
            "total_samples": len(predictions),
            "valid_json_count": valid_count,
            "invalid_json_count": invalid_count,
            "gemini_analysis": gemini_analysis
        }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        print(f"\nüíæ –°–û–•–†–ê–ù–ï–ù–ò–ï –û–ë–ù–û–í–õ–ï–ù–ù–´–• –†–ï–ó–£–õ–¨–¢–ê–¢–û–í...")
        os.makedirs(output_dir, exist_ok=True)
        
        model_name_safe = sanitize_filename(model_name)
        
        # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª –º–µ—Ç—Ä–∏–∫ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è multi_agent_mode
        multi_agent_mode = None
        metrics_file_pattern = os.path.join(output_dir, f"metrics_{model_name_safe}_*.json")
        metrics_files = glob.glob(metrics_file_pattern)
        original_metrics_files = [f for f in metrics_files if "_reevaluated" not in f]
        if original_metrics_files:
            try:
                with open(original_metrics_files[-1], 'r', encoding='utf-8') as f:
                    original_metrics = json.load(f)
                multi_agent_mode = original_metrics.get("multi_agent_mode")
            except Exception:
                pass  # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å, –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–æ–º —Ä–µ–∂–∏–º–µ –≤ –∏–º—è —Ñ–∞–π–ª–∞, –µ—Å–ª–∏ –æ–Ω –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è
        multi_agent_suffix = f"_{multi_agent_mode}" if multi_agent_mode else ""
        metrics_path = os.path.join(output_dir, f"metrics_{model_name_safe}{multi_agent_suffix}_{timestamp}_reevaluated.json")
        
        # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ JSON –±–µ–∑ –ø–æ–ª—è "–≤—Å–µ_–æ—à–∏–±–∫–∏" (—á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–≥—Ä—É–∂–∞—Ç—å —Ñ–∞–π–ª)
        evaluation_result_for_json = copy.deepcopy(evaluation_result)
        quality_metrics_for_json = evaluation_result_for_json.get("quality_metrics")
        if quality_metrics_for_json:
            for group in ["–º–∞—Å—Å–æ–≤–∞—è –¥–æ–ª—è", "–ø—Ä–æ—á–µ–µ"]:
                if group in quality_metrics_for_json:
                    # –£–¥–∞–ª—è–µ–º –ø–æ–ª–µ "–≤—Å–µ_–æ—à–∏–±–∫–∏" –ø–µ—Ä–µ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≤ JSON
                    quality_metrics_for_json[group].pop("–≤—Å–µ_–æ—à–∏–±–∫–∏", None)
        
        with open(metrics_path, 'w', encoding='utf-8') as f:
            json.dump(evaluation_result_for_json, f, ensure_ascii=False, indent=2)
        print(f"üíæ –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {metrics_path}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—à–∏–±–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª
        if quality_metrics:
            errors_path = os.path.join(output_dir, f"quality_errors_{model_name_safe}{multi_agent_suffix}_{timestamp}_reevaluated.txt")
            with open(errors_path, 'w', encoding='utf-8') as f:
                f.write(f"–û—à–∏–±–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–ª—è –º–æ–¥–µ–ª–∏: {model_name}\n")
                f.write(f"–î–∞—Ç–∞: {timestamp}\n")
                f.write(f"–ü–µ—Ä–µ–æ—Ü–µ–Ω–µ–Ω–æ –∏–∑: {results_csv_path}\n")
                f.write(f"{'='*80}\n\n")
                
                # –û—à–∏–±–∫–∏ –¥–ª—è –≥—Ä—É–ø–ø—ã "–º–∞—Å—Å–æ–≤–∞—è –¥–æ–ª—è" (–∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ_–æ—à–∏–±–∫–∏, –µ—Å–ª–∏ –µ—Å—Ç—å, –∏–Ω–∞—á–µ –æ—à–∏–±–∫–∏)
                mass_dolya = quality_metrics.get('–º–∞—Å—Å–æ–≤–∞—è –¥–æ–ª—è', {})
                mass_errors = mass_dolya.get('–≤—Å–µ_–æ—à–∏–±–∫–∏', mass_dolya.get('–æ—à–∏–±–∫–∏', []))
                if mass_errors:
                    f.write(f"–û–®–ò–ë–ö–ò –ö–ê–ß–ï–°–¢–í–ê: –ú–ê–°–°–û–í–ê–Ø –î–û–õ–Ø\n")
                    f.write(f"–í—Å–µ–≥–æ –æ—à–∏–±–æ–∫: {len(mass_errors)}\n")
                    f.write(f"{'‚îÄ'*80}\n")
                    for i, error in enumerate(mass_errors, 1):
                        f.write(f"{i}. {error}\n")
                    f.write(f"\n")
                else:
                    f.write(f"–û–®–ò–ë–ö–ò –ö–ê–ß–ï–°–¢–í–ê: –ú–ê–°–°–û–í–ê–Ø –î–û–õ–Ø\n")
                    f.write(f"–û—à–∏–±–æ–∫ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ.\n\n")
                
                # –û—à–∏–±–∫–∏ –¥–ª—è –≥—Ä—É–ø–ø—ã "–ø—Ä–æ—á–µ–µ" (–∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ_–æ—à–∏–±–∫–∏, –µ—Å–ª–∏ –µ—Å—Ç—å, –∏–Ω–∞—á–µ –æ—à–∏–±–∫–∏)
                prochee = quality_metrics.get('–ø—Ä–æ—á–µ–µ', {})
                prochee_errors = prochee.get('–≤—Å–µ_–æ—à–∏–±–∫–∏', prochee.get('–æ—à–∏–±–∫–∏', []))
                if prochee_errors:
                    f.write(f"–û–®–ò–ë–ö–ò –ö–ê–ß–ï–°–¢–í–ê: –ü–†–û–ß–ï–ï\n")
                    f.write(f"–í—Å–µ–≥–æ –æ—à–∏–±–æ–∫: {len(prochee_errors)}\n")
                    f.write(f"{'‚îÄ'*80}\n")
                    for i, error in enumerate(prochee_errors, 1):
                        f.write(f"{i}. {error}\n")
                    f.write(f"\n")
                else:
                    f.write(f"–û–®–ò–ë–ö–ò –ö–ê–ß–ï–°–¢–í–ê: –ü–†–û–ß–ï–ï\n")
                    f.write(f"–û—à–∏–±–æ–∫ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ.\n\n")
            
            print(f"üíæ –û—à–∏–±–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {errors_path}")
        
        # –í—ã–≤–æ–¥–∏–º —Å–≤–æ–¥–∫—É
        print(f"\n{'='*80}")
        print(f"‚úÖ –ü–ï–†–ï–û–¶–ï–ù–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê!")
        print(f"{'='*80}")
        print(f"üìå –ò—Ç–æ–≥–æ–≤–∞—è —Å–≤–æ–¥–∫–∞:")
        print(f"   ‚Ä¢ –ú–æ–¥–µ–ª—å: {model_name}")
        print(f"   ‚Ä¢ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ç–µ–∫—Å—Ç–æ–≤: {len(predictions)}")
        print(f"   ‚Ä¢ –û—à–∏–±–∫–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞: {parsing_error_rate:.2%} ({invalid_count}/{len(predictions)})")
        if quality_metrics:
            mass_acc = quality_metrics.get('–º–∞—Å—Å–æ–≤–∞—è –¥–æ–ª—è', {}).get('accuracy', 0)
            prochee_acc = quality_metrics.get('–ø—Ä–æ—á–µ–µ', {}).get('accuracy', 0)
            mass_f1 = quality_metrics.get('–º–∞—Å—Å–æ–≤–∞—è –¥–æ–ª—è', {}).get('f1', 0)
            prochee_f1 = quality_metrics.get('–ø—Ä–æ—á–µ–µ', {}).get('f1', 0)
            print(f"   ‚Ä¢ –ö–∞—á–µ—Å—Ç–≤–æ '–º–∞—Å—Å–æ–≤–∞—è –¥–æ–ª—è': Accuracy={mass_acc:.2%}, F1={mass_f1:.2%}")
            print(f"   ‚Ä¢ –ö–∞—á–µ—Å—Ç–≤–æ '–ø—Ä–æ—á–µ–µ': Accuracy={prochee_acc:.2%}, F1={prochee_f1:.2%}")
        print(f"{'='*80}\n")
        
        return evaluation_result

